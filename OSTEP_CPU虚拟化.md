# OSTEP

## Ch4 抽象: 进程

实现 CPU 的虚拟化, 要实现得好, 操作系统就需要一些低级机制以及一些高级智能. 

低级机制称为`机制`(mechanism). 机制是一些低级方法或协议, 实现了所需的功能. 
例如, 我们稍后将学习如何实现上下文切换(context switch).

>时分共享(time sharing)是操作系统共享资源所使用的最基本的技术之一. 通过允许资源由一个实体使用一小段时间, 然后由另一个实体使用一小段时间, 如此下去, 所谓的资源(例如, CPU 或网络链接)可以被许多人共享. 时分共享的自然对应技术是空分共享, 资源在空间上被划分给希望使用它的人. 例如, 磁盘空间自然是一个空分共享资源, 因为一旦将块分配给文件, 在用户删除文件之前, 不可能将它分配给其他文件.

在`机制`之上, 操作系统中有一些`智能`以`策略(policy)`的形式存在. 

策略是在操作系统内做出某种决定的算法. 
操作系统中的调度策略(scheduling policy)会做出这样的决定, 可能利用历史信息(例如, 哪个程序在最后一分钟运行得更多?)、工作负载知识(例如, 运行什么类型的程序?)以及性能指标 (例如, 系统是否针对交互式性能或吞吐量进行优化?)来做出决定. 

### 4.1 抽象: 进程

操作系统为正在运行的程序提供的抽象, 就是所谓的进程(process). 
一个进程只是一个正在运行的程序. 在任何时刻, 我们都可以清点它在执行过程中访问或影响的系统的不同部分, 从而概括一个进程. 

进程的机器状态有一个明显组成部分, 就是它的内存. 指令存在内存中. 正在运行的
程序读取和写入的数据也在内存中. 因此进程可以访问的内存(称为地址空间, address space)是该进程的一部分. 

进程的机器状态的另一部分是寄存器. 许多指令明确地读取或更新寄存器, 因此显然, 
它们对于执行该进程很重要. 
有一些非常特殊的寄存器构成了该机器状态的一部分. 例如, 程序计数器(Program Counter, PC)(有时称为指令指针, Instruction Pointer 或 IP)告诉我们程序当前
正在执行哪个指令; 类似地, 栈指针(stack pointer)和相关的帧指针(frame pointer)用于管理函数参数栈、局部变量和返回地址. 

程序也经常访问持久存储设备. 此类 I/O 信息可能包含当前打开的文件列表. 

### 4.2 进程API

所有现代操作系统都以某种形式提供这些 API. 
- 创建(create): 操作系统必须包含一些创建新进程的方法. 在 shell 中键入命令或双击应用程序图标时, 会调用操作系统来创建新进程, 运行指定的程序. 
- 销毁(destroy): 由于存在创建进程的接口, 因此系统还提供了一个强制销毁进程的接口. 当然, 很多进程会在运行完成后自行退出. 但是, 如果它们不退出, 用户可能希望终止它们, 因此停止失控进程的接口非常有用. 
- 等待(wait): 有时等待进程停止运行是有用的, 因此经常提供某种等待接口. 
- 其他控制(miscellaneous control): 除了杀死或等待进程外, 有时还可能有其他控制. 例如, 大多数操作系统提供某种方法来暂停进程(停止运行一段时间), 然后恢复(继续运行). 
- 状态(statu): 通常也有一些接口可以获得有关进程的状态信息, 例如运行了多长时间, 或者处于什么状态. 

### 4.3 进程创建细节

程序如何转化为进程,  具体来说, 操作系统如何启动并运行一个程序?进程创建实际如何进行?

操作系统运行程序必须做的第一件事是`将代码和所有静态数据`(例如初始化变量)`加载(load)到内存中, 加载到进程的地址空间中`. 程序最初以某种可执行格式驻留在磁盘上
(disk或者SSD上). 因此, 将程序和静态数据加载到内存中的过程, 需要操作系统从磁盘读取这些字节, 并将它们放在内存中的某处.
![](assets/Pasted%20image%2020230324174335.png)

在早期的(或简单的)操作系统中, 加载过程尽早(eagerly)完成, 即在运行程序之
前`全部`完成. 现代操作系统惰性(lazily)执行该过程, 即仅在程序执行期间`需要`加载的代码或数据片段, 才会加载. 要真正理解代码和数据的惰性加载是如何工作的, 必须更多地
了解分页和交换的机制, 这是我们将来讨论内存虚拟化时要涉及的主题. 现在, 只要记住
在运行任何程序之前, 操作系统显然必须做一些工作, 才能将重要的程序字节从磁盘读入
内存. 

将`代码和静态数据加载到内存后`, 操作系统在运行此进程之前还需要执行其他一些操作. 必须`为程序的运行时栈(run-time stack 或 stack)分配一些内存`. 你可能已经知道, C程序使用栈存放局部变量、函数参数和返回地址. 操作系统分配这些内存, 并提供给进程. 操作系统也可能会用参数初始化栈. 具体来说, 它会将参数填入 main()函数, 即 argc 和 argv数组. 

`操作系统也可能为程序的堆(heap)分配一些内存`. 在 C 程序中, 堆用于显式请求的
动态分配数据. 程序通过调用 malloc()来请求这样的空间, 并通过调用 free()来明确地释放
它. 数据结构(如链表、散列表、树等数据结构)需要堆. 起初堆会很小. 随着程序运行, 通过 malloc()库 API 请求更多内存, 操作系统可能会参与分配更多内存给进程, 以满足这些调用. 

操作系统还将`执行一些其他初始化任务`, 特别是与输入/输出(I/O)相关的任务. 例如, 
在 UNIX 系统中, 默认情况下每个进程都有 3 个打开的文件描述符(file descriptor), 用于标准输入、输出和错误. 这些描述符让程序轻松读取来自终端的输入以及打印输出到屏幕. 在本书的第 3 部分关于持久性(persistence)的知识中, 我们将详细了解 I/O、文件描述符等. 

`通过将代码和静态数据加载到内存中, 通过创建和初始化栈以及执行与 I/O 设置相关的其他工作`, OS 现在(终于)为程序执行搭好了舞台. 然后它有最后一项任务: `启动程序, 在入口处运行, 即 main()`. 通过跳转到 main()例程, OS 将 CPU的控制权转移到新创建的进程中, 从而程序开始执行. 

>加载可执行文件的各个段到进程的内存地址空间-> 创建和初始化栈内存,  可能的堆内存-> 其他初始化(I/O等任务)-> 调用main函数-> OS把CPU控制器转移到新建的进程. 

### 4.4 进程状态

进程在给定时间可能处于的不同状态(state).

- 运行(running): 在运行状态下,  进程正在处理器上运行. 它正在占用CPU, 执行指令. 
- 就绪(ready): 在就绪状态下, 进程已准备好运行, 但由于某种原因, 操作系统选择不在此时运行. 
- 阻塞(blocked): 在阻塞状态下, 一个进程执行了某种操作, `直到发生其他事件时`才会`准备运行`. 一个常见的例子是, 当进程向磁盘发起 I/O 请求时, 它会被阻塞, 因此其他进程可以使用处理器. 
![](assets/Pasted%20image%2020230324180414.png)
根据操作系统的载量, 让进程在就绪状态和运行状态之间转换. 从就绪到运行意味着该进程已经被调度(scheduled). 从运行转移到就绪意味着该进程已经取消调度(descheduled). 一旦进程被阻塞(例如,  通过发起 I/O 操作),  OS将保持进程的这种状态,  直到发生某种事件(例如,  I/O完成). 此时,  进程再次转入就绪状态(也可能立即再次运行,  如果操作系统这样决定).

### 4.5 数据结构

操作系统是一个程序, 和其他程序一样, 它有一些关键的数据结构来跟踪各种相关的信息. 

为了跟踪每个进程的状态, 操作系统可能会为`所有就绪的进程`保留某种`进程列表`(process list). 以及跟踪`当前正在运行的进程的一些附加信息`. 操作系统还必须以某种方式跟踪被阻塞的进程. 当 I/O 事件完成时, 操作系统应确保唤醒正确的进程, 让它准备好再次运行. 

对于停止的进程, 寄存器上下文将保存其寄存器的内容. 当一个进程停止时, 它的寄存器将被保存到这个`内存位置`. 
通过恢复这些寄存器(将它们的值放回实际的物理寄存器中), 操作系统可以恢复运行该进
程. 我们将在后面的章节中更多地了解这种技术,  它被称为上下文切换(context switch). 

除了运行、就绪和阻塞之外, 还有其他一些进程可以处于的状态. 有时候系统会有一个初始(initial)状态, 表示`进程在创建时处于的状态`. 另外, 一个进程可以处于已退出但尚未清理的最终(final)状态(在基于 UNIX 的系统中, 这称为`僵尸状态`). 这个最终状态非常有用, 因为它允许其他进程(通常是创建进程的父进程)检查进程的返回代码, 并查看刚刚完成的进程是否成功执行(通常, 在基于 UNIX 的系统中, 程序成功完成任务时返回零, 否则返回非零). 完成后, 父进程将进行最后一次调用(例如, wait()), 以等待子进程的完成, 并告诉操作系统它可以清理这个正在结束的进程的所有相关数据结构. 

## Ch5 插叙:  进程API

### 5.1 fork()系统调用

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int
main(int argc,  char *argv[])
{
    printf("hello world (pid: %d)\n",  (int) getpid()); 
    int rc = fork(); 
    if (rc < 0) {
        // fork failed;  exit
        fprintf(stderr,  "fork failed\n"); 
        exit(1); 
    } else if (rc == 0) {
        // child (new process)
        printf("hello,  I am child (pid: %d)\n",  (int) getpid()); 
    } else {
        // parent goes down this path (original process)
        printf("hello,  I am parent of %d (pid: %d)\n", 
	       rc,  (int) getpid()); 
    }
    return 0; 
}
```
fork() 之后,   出现父子两个进程,  子进程COPY父进程,  子进程在自己的进程里 rc是0, 所以子进程进入(rc == 0)分支运行,  父进程得到子进程的PID,  是大于0的,  所以进入else分支执行. 
所以,  上面的代码运行结果是打印 hello world,  打印 i am parent,  打印 i am child. 
至于父进程先运行,  还是子进程先运行,  看内核的调度算法.

### 5.1 wait()系统调用

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int
main(int argc,  char *argv[])
{
    printf("hello world (pid: %d)\n",  (int) getpid()); 
    int rc = fork(); 
    if (rc < 0) {
        // fork failed;  exit
        fprintf(stderr,  "fork failed\n"); 
        exit(1); 
    } else if (rc == 0) {
        // child (new process)
        printf("hello,  I am child (pid: %d)\n",  (int) getpid()); 
	sleep(1); 
    } else {
        // parent goes down this path (original process)
        int wc = wait(NULL); 
        printf("hello,  I am parent of %d (wc: %d) (pid: %d)\n", 
	       rc,  wc,  (int) getpid()); 
    }
    return 0; 
}
```
父进程调用 wait(), 延迟自己的执行, 直到子进程执行完毕. 当子进程结束谁, wait()才返回父进程. 因此输出结果也变得确定了.
上面代码,  会先打印前hello world,  再打印 i am child,  打印完child,  停顿一下,  父进程再打印i am parent.

### 5.3 exec()系统调用

这个系统调用可以让子进程执行与父进程我同的程序.
```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <sys/wait.h>

int
main(int argc,  char *argv[])
{
    printf("hello world (pid: %d)\n",  (int) getpid()); 
    int rc = fork(); 
    if (rc < 0) {
        // fork failed;  exit
        fprintf(stderr,  "fork failed\n"); 
        exit(1); 
    } else if (rc == 0) {
        // child (new process)
        printf("hello,  I am child (pid: %d)\n",  (int) getpid()); 
        char *myargs[3]; 
        myargs[0] = strdup("wc");    // program:  "wc" (word count)
        myargs[1] = strdup("p3.c");  // argument:  file to count
        myargs[2] = NULL;            // marks end of array
        execvp(myargs[0],  myargs);   // runs word count
        printf("this shouldn't print out"); 
    } else {
        // parent goes down this path (original process)
        int wc = wait(NULL); 
        printf("hello,  I am parent of %d (wc: %d) (pid: %d)\n", 
	       rc,  wc,  (int) getpid()); 
    }
    return 0; 
}
```
子进程调用 execvp()来运行字符计数程序 wc. 事实上, 它针对源代码文件 p3.c 运行 wc, 从而告诉我我该文件有多少行、多少单词, 以及多少字节. 

给定可执行程序的名称(如 wc)及需要的参数(如 p3.c)后, `exec()会从可执行程序中加载代码和静态数据, 并用它覆写自己的代码段(以及静态数据), 堆、栈及其他内存空间也会被重新初始化. `然后操作系统就执行该程序, 将参数通过 argv 传递给该进程. 因此, 它`并没有创建新进程`, 而是`直接将当前运行的程序(以前的 p3)替换为不同的运行程(wc)`. 子进程执行 exec()之后, 几乎就像p3.c 从未运行过一样. 对 exec()的成功调用永远不会返回. 

### 5.4 为何这样设计API

为何设计如此奇怪的接口, 来完成简单的、创建新进程的任务?事实证明, 这种分离 fork()及 exec()的做法在构建 UNIX shell 的时候非常有用, 因为这给了 shell 在 fork 之后 exec 之前运行代码的机会, 这些代码可以在运行新程序前改变环境, 从而让一系列有趣的功能很容易实现. 

shell 也是一个用户程序, 它首先显示一个提示符(prompt), 然后等待用户输入. 你可以向它输入一个命令(一个可执行程序的名称及需要的参数),  大多数情况下, shell 可以在文件系统中找到这个可执行程序, 调用 fork()创建新进程, 并调用 exec()家族的函数来执行这个可执行程序,  调用 wait()等待该命令完成. 子进程执行结束后, shell 从 wait()返回并再次输出一个提示符, 等待用户输入下一条命令.
fork()和 exec()的分离, 让 shell 可以方便地实现很多有用的功能. 比如: 
`$ wc p3.c > newfile.txt`
上面的例子中, wc 的输出结果被重定向(redirect)到文件 newfile.txt 中(通过newfile.txt之前的大于号来指明重定向). shell 实现结果重定向的方式也很简单, 当完成子进程的创建后, `shell 在调用 exec()之前先关闭了标准输出(standard output)`,  打开了文件newfile.txt.
这样,  即将运行的程序 wc 的输出结果就被发送到该文件,  而不是打印在屏幕上.

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <fcntl.h>
#include <assert.h>
#include <sys/wait.h>

int
main(int argc,  char *argv[])
{
    pid_t rc ; 
    if ((rc = fork()) < 0) {
        // fork failed;  exit
        fprintf(stderr,  "fork failed\n"); 
        exit(1); 
    } else if (rc == 0) {
	// child:  redirect standard output to a file
	close(STDOUT_FILENO);  
	open("./p4.output",  O_CREAT|O_WRONLY|O_TRUNC,  S_IRWXU); 

	// now exec "wc"...
        char *myargs[3]; 
        myargs[0] = strdup("wc");    // program:  "wc" (word count)
        myargs[1] = strdup("p4.c");  // argument:  file to count
        myargs[2] = NULL;            // marks end of array
        execvp(myargs[0],  myargs);   // runs word count
    } else {
        // parent goes down this path (original process)
        int wc = wait(NULL); 
	    assert(wc >= 0); 
    }
    return 0; 
}
```

**`重定向的工作原理, 是基于对操作系统管理文件描述符方式的假设. 具体来说, UNIX 系统从打开文件描述符的0开始寻找可以使用的文件描述符. `**
上面的例子中, STDOUT_FILENO 将成为第一个可用的文件描述符, 因此在 open()被调用时, 得到赋值. 然后子进程向标准输出文件描述符的写入(例如通过 printf()这样的函数), 都会被透明地转向新打开的文件, 而不是屏幕. 

UNIX 管道也是用类似的方式实现的,  但用的是 pipe()系统调用. 在这种情况下,  一个进程的输出被链接到了一个内核管道(pipe)上(队列), 另一个进程的输入也被连接到了同一个管道上. 因此, 前一个进程的输出无缝地作为后一个进程的输入, 许多命令可以用这种方式串联在一起, 共同完成某项任务. 比如通过将 grep、wc 命令用管道连接可以完成从一个文件中查找某个词, 并统计其出现次数的功能: `grep -o foo file | wc -l` .

>补充: RTFM —— 阅读 man 手册

### 5.5 其他 API

除了上面提到的 fork()、exec()和 wait()之外, 谁 UNIX 中还有其他许多与进程交互的方式. 比如可以通过 kill()系统调用向进程发送信号(signal), 包括要求进程睡眠、终止或其他有用的指令. 实实上, 整个信号子系统提供了一套丰富的向进程传递外部事件的途径, 包括接受和执行这些信号. 

此外还有许多非常有用的命令行工具. 比如通过 ps 命令来查看当前谁运行的进程, 阅读 man 手册来了解 ps 命令所接受的参数. 工具 top 也很有用, 它展示当前系统中进程消耗CPU 或其他资源的情况. 有趣的是, 你常常会发现 top 命令自己就是最占用资源的, 它或许有一点自大狂. 此外还有许多 CPU 检测工具, 让你方便快速地了解系统负载. 比如, 我我总是让 MenuMeters(来自 Raging Menace 公司)运行谁 Mac 计算机的工具栏上, 这样就能随谁了解当前的 CPU 利用率. 一般来说, 对现状了解得越多越好. 

## Ch6 机制:  受限直接执行

为了虚拟化 CPU, 操作系统需要以某种方式让许多任务共享物理 CPU, 让它们看起来像是同时运行. 基本思想很简单: 运行一个进程一段时间, 然后运行另一个进程, 如此轮换. 通过以这种方式`时分共享(time sharing)`CPU, 就实现了虚拟化. 

然而会出现以下几个问题:  
第一个是`性能`: 如何在不增加系统开销的情况下实现虚拟化?
第二个是`控制权`: 如何有效地运行进程,  同时保留对 CPU 的控制?控制权对于操作系统尤为重要,  因为操作系统负责资源管理. 如果没有控制权,  一个进程可以简单地无限制运行并接管机器,  或访问没有权限的信息. 因此, 在保持控制权的同时获得高性能, 这是构建操作系统的主要挑战之一.

> 操作系统必须以高性能的方式虚拟化 CPU, 同时保持对系统的控制. 为此, 需要`硬件`和`操作系统`支持. 操作系统通常会明智地利用硬件支持, 以便高效地实现其工作. 

### 6.1 基本技巧: 受限直接执行

为了使程序尽可能快地运行, 操作系统开发人员想出了一种技术——我们称之为受限的直接执行(limited direct execution).
直接执行:  直接在CPU上运行程序. 因此, 当 OS 希望启动程序运行时, 它会在进程列表中为其创建一个进程条目, 为其分配一些内存, 将程序代码(从磁盘)加载到内存中, 找到入口点(main()函数或类似的), 跳转到那里, 并开始运行用户的代码. 
![](assets/Pasted%20image%2020230326201006.png)
表 6.1 展示了不受限时,  基本的直接执行协议,  使用正常的调用并返回跳转到程序的 main(), 并在稍后回到内核. 

不受限直接运行的问题在于:  
- 如果我们只运行一个程序, 操系统怎么能确保程序不做任何我们不希作望它做的事, 同时仍然高效地运行它?
- 当我们运行一个进程时, 操作系统如何让它停下来并切换到另一个进程, 从而实现虚拟化 CPU 所需的时分共享?

> 如果对运行程序没有限制, 操作系统将无法控制任何事情, 因此会成为“仅仅是一个库”.

### 6.2 问题 1: 受限制的操作

直接执行的明显优势是快速. 该程序直接在硬件 CPU 上运行,  因此执行速度与预期的一样快. 
问题在于,  如果进程希望执行某种受限操作(如向磁盘发出 I/O 请求或获得更多系统资源(如 CPU 或内存)), 该怎么办?

>提示: 采用受保护的控制权转移
  `硬件`通过`提供不同的执行模式`来协助操作系统. 在用户模式(user mode)下, 应用程序不能完全访问硬件资源. 在内核模式(kernel mode)下, 操作系统可以访问机器的全部资源. 还提供了陷入(trap)内核和从陷阱返回(return-from-trap)到用户模式程序的特别说明, 以及一些指令, 让操作系统告诉硬件陷阱表(trap table)在内存中的位置. (X86 ARM的硬件不同)

用户模式(用户态) 下,  运行的程序会有限制. 如在用户模式下运行时, 进程不能发出 I/O 请求.
内核模式(内核态)下,  由于OS是硬件唯一信任的软件,  所以内核态有权限做用户态不能做的事. 操作系统(或内核)就以这种模式运行.

用户态的程序如何,  做只有内核态才能做的操作呢? 为了实现这一点, 几乎所有的现代`硬件`都提供了用户程序执行`系统调用`的能力.

`系统调用`是在Atlas等古老机器上开创的, 它允许内核小心地向用户程序提供某些关键功能, 例如访问文件系统、创建和销毁进程、与其他进程通信, 以及分配更多内存. 大多数操作系统提供几百个调用(POSIX 标准). 早期的 UNIX 系统公开了更简洁的子集, 大约 20 个调用. 

要执行系统调用, 程序必须执行特殊的`陷阱(trap)`指令. 该指令同时跳入内核并将`特权级`别提升到内核模式. 一旦进入内核, 系统就可以执行任何需要的特权操作(如果允许), 从而为调用进程执行所需的工作. 
完成后, 操作系统调用一个特殊的从陷阱返回(return-from-trap)指令, 如你期望的那样, 该指令返回到发起调用的用户程序中, 同时将特权级别降低, 回到用户模式. 

> linux 0.11的实现 就是以INT 80 这个软中断来实现系统调用的.

执行陷阱时, 硬件需要小心, 因为它必须确保存储足够的调用者寄存器, 以便在操作系统发出从陷阱返回指令时能够正确返回.

> 在 x86 上, 处理器会将用户态程序的程序计数器、标志和其他一些寄存器压到到每个进程的内核栈(kernel stack)上. 从内核态返回用户态时,  将从栈弹出这些值, 并恢复执行用户模式程序.  ARM等其他架构具体实现不同,  但理念是一样的.

- 系统调用与过程调用(函数调用)
	系统调用的确很像函数调用,  但不同的是有些操作,  是由C库实现系统调用的. C 库中进行系统调用的部分是用汇编写的. 因为它们需要按照硬件CPU的体系结构来写, 以便正确处理参数和返回值, 以及执行硬件特定的trap指令. 

通过系统调用,  陷入内核态时,  根据传进来的参数(用寄存器传的),   会去调用 内核启动时初始化的系统调用表,  找到要执行的函数.(boot载入OS内核就把特权级转到内核态了,  所以有权限.)
操作系统做的第一件事, 就是告诉硬件在发生某些异常事件时要运行哪些代码.(初始化中断向量表). 比如发生硬盘中断,  键盘中断或程序进行系统调用等,  应该运行那些代码?
操作系统通常通过某种特殊的指令, 通知硬件这些陷阱处理程序的位置. 一旦硬件被通知, 它就会记住这些处理程序的位置, 直到下一次重新启动机器, 并且硬件知道在发生系统调用和其他异常事件时要做什么(即跳转到哪段代码). 
用一张表来表示从上到下的时间线,  假设每个进程都有一个内核栈, 在进入内核和离开内核时, 寄存器(包括通用寄存器和程序计数器)分别被保存和恢复. 
![](assets/Pasted%20image%2020230326210122.png)
上面,  LDE协议有两个阶段: 
第一个阶段(在系统引导时), 内核初始化陷阱表, 并且 CPU 记住它的位置以供随后使用. 内核通过特权指令来执行此操作.
第二个阶段(运行进程时), 在使用从陷阱返回指令开始执行进程之前, 内核设置了一些内容(例
如, 在进程列表中分配一个节点, 分配内存). 这会将 CPU 切换到用户模式并开始运行该进程. 
当进程希望发出系统调用时, 它会重新陷入操作系统, 然后再次通过从陷阱返回, 将控制权还给
进程. 该进程然后完成它的工作, 并从 main()返回. 这通常会返回到一些存根代码, 它将正确退
出该程序(例如, 通过调用 exit()系统调用, 这将陷入 OS 中). 此时, OS 清理干净, 任务完成了. 

### 6.3 问题 2: 在进程之间切换

如果一个用户的进程在 CPU 上运行, 这就意味着操作系统没有运行. 
关键问题就来了:  操作系统如何重新获得 CPU 的控制权(regain control), 以便它可以在进程之间切换?

- 协作方式: 等待系统调用

这是过去某些系统采用的一种方式. 运行时间过长的进程被假定会定期放弃 CPU, 以便操作系统可以决定运行其他任务. 进程通过进行系统调用, 将 CPU 的控制权转移给操作系统.
例如打开文件并随后读取文件, 或者向另一台机器发送消息或创建新进程. 像这样的系统通常包括一个显式的 `yield` 系统调用, 它什么都不干, 只是将控制权交给操作系统, 以便系统可以运行其他进程. 

如果应用程序执行了某些非法操作(即异常), 也会将控制转移给操作系统. 例如, 如果应用程序以 0 为除数, 或者尝试访问应该无法访问的内存, 就会陷入(trap)操作系统. 操作系统将再次控制 CPU(并可能终止违规进程). 

因此, 在协作调度系统中, OS 通过等待系统调用, 或某种非法操作发生, 从而重新获得CPU的控制权. 
问题来了,  如果不系统调用,  从而把CPU资源返回给OS的话,  就完蛋了.

- 非协作方式:  操作系统进行控制

若是没有硬件的额外帮助, 如果进程拒绝进行系统调用(也不出错), 从而将控制权交还给操作系统, 那么操作系统无法做任何事情. 
在协作方式中, 当进程陷入无限循环时, 唯一的办法就是——重启大法. 

关键问题来了: 如何在没有协作的情况下获得控制权. 假设进程不协作, 操作系统如何获得CPU的控制权?操作系统怎么来确保流氓进程不会永远占用机器?

答案是,  *时钟中断(timer interrupt)*. 
*时钟设备*可以编程为每隔几毫秒产生一次中断. 产生中断时, 当前正在运行的进程停止, 操作系统中`预先配置`的中断处理程序(interrupt handler)会运行. 此时, 操作系统重新获得 CPU 的控制权, 因此可以做它想做的事: 停止当前进程, 并启动另一个进程. 

>即使进程以非协作的方式运行, 添加时钟中断(timer interrupt)也让操作系统能够在 CPU 上重新运行. 因此, 该`硬件功能`对于帮助操作系统维持机器的控制权至关重要. 

操作系统必须通知硬件哪些代码在发生时钟中断时运行. 因此, 在启动时, 操作系统就是这样做的. 其次, 在启动过程中, 操作系统也必须`启动时钟`, 这当然是一项特权操作. 

`硬件`在发生中断时有一定的责任, 尤其是在中断发生时, 要为正在运行的程序保存足够的状态, 以便随后从陷阱返回指令能够正确恢复正在运行的程序. 这一组操作与硬件在显式系统调用陷入内核时的行为非常相似, 其中各种寄存器因此被保存(进入内核栈), 因此从陷阱返回指令可以容易地恢复. 

- 保存和恢复上下文

既然操作系统已经重新获得了控制权, 无论是通过系统调用协作, 还是通过时钟中断更强制执行, 都必须决定: 是继续运行当前正在运行的进程, 还是切换到另一个进程. 这个决定是由调度程序(scheduler)做出的, 它是操作系统的一部分. 

若是决定进行切换, OS 就会执行一些底层代码, 即所谓的上下文切换(context switch), 即为当前正在执行的进程保存一些寄存器的值(例如, 到它的内核栈), 并为即将执行的进程恢复一些寄存器的值(从它的内核栈). 
这样一来, 操作系统就可以确保最后执行从陷阱返回指令时, 不是返回到之前运行的进程, 而是继续执行另一个进程.

为了保存当前正在运行的进程的上下文, 操作系统会执行一些底层汇编代码来保存通用寄存器、程序计数器, 以及当前正在运行的进程的内核栈指针, 然后恢复寄存器、程序计数器, 并切换内核栈, 供即将运行的进程使用. 
通过切换栈, 内核在`进入切换代码调用时`, 是一个进程(被中断的进程)的上下文, 在`返回时`, 是另一进程(即将执行的进程)的上下文. 当操作系统最终执行从陷阱返回指令时, 即将执行的进程变成了当前运行的进程. 至此上下文切换完成. 

![](assets/Pasted%20image%2020230326213609.png)
上面时间线表示了进程A,  切到进程B的过程. 时钟中断触发,  进程A的现场被压在内核栈中,  然后调用switch(),  把进程A的现场保存在内核PCB结构体变量中,  同时把B从PCB变量恢复到寄存器,  恢复B进程的现场. 跳转运行.
有两种类型的寄存器保存/恢复. 
第一种是发生时钟中断的时候. 在这种情况下, 运行进程的用户寄存器由硬件隐式保存, 使用该进程的内核栈. 
第二种是当操作系统决定从 A 切换到 B. 在这种情况下, 内核寄存器被软件(即 OS)明确地保存, 但这次被存储在该进程的进程结构的内存中. 后一个操作让系统从好像刚刚由 A 陷入内核, 变成好像刚刚由 B 陷入内核. 

```asm
# void swtch(struct context **old,  struct context *new); 
#
# Save current register context in old
# and then load register context from new.
.globl swtch
swtch: 
# Save old registers
movl 4(%esp),  %eax # put old ptr into eax
popl 0(%eax) # save the old IP
movl %esp,  4(%eax) # and stack
movl %ebx,  8(%eax) # and other registers
movl %ecx,  12(%eax)
movl %edx,  16(%eax)
movl %esi,  20(%eax)
movl %edi,  24(%eax)
movl %ebp,  28(%eax)

# Load new registers
movl 4(%esp),  %eax # put new ptr into eax
movl 28(%eax),  %ebp # restore other registers
movl 24(%eax),  %edi
movl 20(%eax),  %esi
movl 16(%eax),  %edx
movl 12(%eax),  %ecx
movl 8(%eax),  %ebx
movl 4(%eax),  %esp # stack is switched here
pushl 0(%eax) # return addr put in place
ret # finally return into new ctxt
```
这段汇编就是x86体系,  xv6内核切换上下文的.

### 6.4 小结

虚拟化CPU就是让多个进程任务交替执行, 分时共享CPU资源.

受限直接执行: 
基本思路很简单: 就让你想运行的程序在 CPU 上运行(创进程, 给内存, 初始化,加载跳转), 但首先确保设置好硬件, 以便在没有操作系统帮助的情况下限制进程可以执行的操作.

受限, 就是分内核态和用户态,  用户态的特权级有限. 内核态的特权级最高. 有些敏感操作只有内核态能做, 用户态做不了. 用户态到内核态,  就用系统调用,  或者其他方式触发.

进程间切换:
OS内核从用户态进程获得CPU资源的方法:  
协作方式--由进程系统调用, 让出CPU资源; 
非协作方式--进程耍流氓不释放CPU资源时, 由时钟中断强行切换(需要硬件的支持).

(进程/线程)上下文切换, 由用户态到内核态, 当前的PCB/TCB保存, 下一个进程/线程的PCB/PCB恢复到现场, 然后跳转执行.

## Ch7 进程调度 介绍

关键问题：如何开发调度策略

### 7.1 工作负载假设

探讨可能的策略范围之前, 先做一些简化假设, 是与系统中运行的进程有关的，有时候统称为工作负载（workload）. `确定工作负载`是构建调度策略的关键部分. 工作负载了解得越多，你的策略就越优化。
对操作系统中运行的进程（有时也叫工作任务）做出如下的假设：
1．每一个工作运行相同的时间。
2．所有的工作同时到达。
3．一旦开始，每个工作保持运行直到完成。
4．所有的工作只是用 CPU（即它们不执行 IO 操作）。
5．每个工作的运行时间是已知的。

### 7.2 调度指标

除了做出工作负载假设之外，还需要一个东西能让我们比较不同的调度策略：调度指标.
这里, 我们只用一个指标：周转时间（turnaround time）. 它是一个性能（performance）指标.
任务的`周转时间`定义为`任务完成时间`减去`任务到达系统的时间`. T周转时间= T完成时间-T到达时间.
因为我们假设所有的任务在同一时间到达，那么T到达时间=0，因此 T周转时间= T完成时间.

另一个有趣的指标是公平（fairness）. 性能和公平在调度系统中往往是矛盾的. 例如，调度程序可以优化性能，但代价是以阻止一些任务运行，这就不那么公平了.

看几种常见的调度思路:

### 7.3 先进先出（FIFO）

也称为先到先服务（First Come First Served 或 FCFS）. 它很简单，而且易于实现.
但假如各个任务工作时长不同, A进程需要100秒, B和C运行10秒, 系统的平均周转时间是比较高的：令人不快的 110s（（100 + 110 + 120)/3 = 110）。

这个问题通常被称为护航效应. 一些耗时较少的潜在资源消费者被排在重量级的资源消费者之后, 短作业在长作业后面等待时间太长.


### 7.4 最短任务优先（SJF）

Shortest Job First，SJF. 先运行最短的任务，然后是次短的任务，如此下去。

> 抢占式调度程序
> 非抢占式的系统会将每项任务做完，再考虑是否运行新工作. 而抢占式调度, 会停止一个进程以运行另一个进程.

针对7.1的假设, 做出改变, 现在假设工作可以随时到达，而不是同时到达。这导致了什么问题？
答案是, 会遭遇同样的护航问题. 假设A是长作业需要10S, B是短作业需要2S, C也是短作业需要1S. 
A和B先到, 所以先运行B, 在运行B期间, C来了, 那C插在A的前面了. 假如一直有短作业到达呢? A就一直干瞪眼等待了.
即使 B 和 C 在 A 之后不久到达，由于是非抢占式, 它们仍然被迫等到 A 完成. 

### 7.5 最短完成时间优先（STCF）

为了解决这个问题，需要放宽假设条件(工作必须保持运行直到完成). 我们还需要调度程序本身的一些机制。SJF 是一种非抢占式（non-preemptive）调度程序，因此存在上述问题.

向 SJF 添加抢占，称为最短完成时间优先(Shortest Time-to-Completion First，STCF)或抢占式最短作业优先(Preemptive Shortest JobFirst , PSJF) 调度程序.

每当新工作进入系统时，它就会确定剩余工作和新工作中，谁的剩余时间最少，然后调度该工作。
STCF 将抢占 A 并运行 B 和 C 以完成。只有在它们完成后，才能调度 A 的剩余时间。

### 7.6 新度量指标：响应时间

果我们知道任务长度，而且任务只使用 CPU，而我们唯一的衡量是周转时间，STCF 将是一个很好的策略.
现在, 用户将会坐在终端前面，同时也要求系统的交互性好。因此，一个新的度量标准诞生了：响应时间（response time）。
响应时间定义为从任务到达系统到首次运行的时间. T响应时间= T首次运行-T到达时间.

例如，如果我们有上面的调度（A 在时间 0 到达，B 和 C 在时间 10 达到），每个作业的响应时间如下：作业 A 为 0，B 为 0，C 为 10（平均：3.33）。
你也不想你在终端输入内容, 等好几秒才能看到结果吧. 这是用户无法接受的.

- ⾼响应⽐优先调度算法

前⾯的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和⻓作业.
⾼响应⽐优先（Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和⻓作业。
每次进⾏进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最⾼的进程投⼊运⾏，「响应⽐优先级」的计算公式：
![](assets/Pasted%20image%2020230327133155.png)
从上⾯的公式，可以发现：
如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应⽐」就越⾼，这样短作业的进程容易被选中运⾏；
如果两个进程「要求的服务时间」相同时，「等待时间」越⻓，「响应⽐」就越⾼，这就兼顾到了⻓作业进程，因为进程的响应⽐可以随时间等待的增加⽽提⾼，当其等待时间⾜够⻓时，其响应⽐便可以升到很⾼，从⽽获得运⾏的机会；

### 7.7 轮转

如何构建对`响应时间敏感`的调度程序？
轮转（Round-Robin，RR）调度. 
基本思想很简单：RR 在一个时间片（time slice，有时称为调度量子，scheduling quantum）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。反复执行，直到所有任务完成.

>注意，时间片长度必须是时钟中断周期的倍数。因此，如果时钟中断是每 10ms 中断一次，则时间片可以是 10ms、20ms 或 10ms 的任何其他倍数。

所以, A进程运行一小会, 就切换B运行, 然后切换C运行, 再切换A. 这样循环, 直接到某个进程完成.
上下文切换是有系统开销的, 所以时间片长度对于 RR 是至关重要的.
因此，系统设计者需要权衡时间片的长度，使其足够长，以便摊销（amortize）上下文切换成本，而又不会使系统不及时响应。

>当系统某些操作有固定成本时，通常会使用摊销技术（amortization）。通过减少成本的频度（即执行较少次的操作），系统的总成本就会降低。

例如，如果时间片设置为 10ms，并且上下文切换时间为 1ms，那么浪费大约 10%的时间用于上下文切换。如果要摊销这个成本，可以把时间片增加到 100ms。在这种情况下，不到 1%的时间用于上下文切换，因此时间片带来的成本就被摊销了。

注意，上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作。程序运行时，它们在CPU 高要缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态。
切换到另一个工作会导致此状态被刷新，且与当前运行的作业相关的新状态被引入，这会显著地提高开销成本.

如果光看响应时间, 时间片轮转, 确实挺好.
但是别忘了, 还有周转时间呢. 
假设 3 个任务 A、B 和 C 在系统中同时到达，并且它们都希望运行 5s.
![](assets/Pasted%20image%2020230327135105.png)
RR 的平均响应时间是：(0+1+2)/3 = 1; SJF 算法平均响应时间是：(0+5+10)/3 = 5.
然而, A 在 13 完成，B 在14，C 在 15，平均14。这就不太行了. 周转太长.

因为周转时间只关心作业何时完成, 并不管用户的体验. 而时间片轮转就是注重用户的交互体验的, 为了让响应时间变短.

这就是鱼和熊掌, 响应与周转, 总要有个取舍.
要任务尽快完成, 就要以响应为代价.(这就是RTOS的由来), 而要用户体验好, 响应快, 就要以周转时间为代价(面向个人使用者的OS).

目前讨论到的调度思路, 第一种类型（SJF、STCF）优化周转时间，但对响应时间不利。第二种类型（RR）优化响应时间，但对周转时间不利。

对7.1我们还有两个假设需要放宽:假设 4(作业没有 I/O)和假设 5(每个作业的运行时间是已知的).

### 7.8 结合 I/O

我们将放宽假设 4：当然所有程序都执行 I/O
调度程序显然要在工作发起 I/O 请求时做出决定，因为当前正在运行的作业在 I/O 期间不会使用 CPU，它被阻塞等待 I/O 完成。
如果将 I/O 发送到硬盘驱动器，则进程可能会被阻塞几毫秒或更长时间，具体取决于驱动器当前的 I/O 负载。因此，这时调度程序应该在 CPU上安排另一项工作。
调度程序还必须在 I/O 完成时做出决定。发生这种情况时，会产生中断，操作系统运行并将发出 I/O 的进程从阻塞状态移回就绪状态。当然，它甚至可以决定在那个时候运行该项工作。操作系统应该如何处理每项工作？

假设有两项工作 A 和 B，每项工作需要 50ms 的 CPU时间。但是，有一个明显的区别：A 运行 10ms，然后发出 I/O 请求（假设 I/O 每个都需要10ms），而 B 只是使用 CPU 50ms，不执行 I/O。调度程序先运行 A，然后运行 B.
![](assets/Pasted%20image%2020230327141556.png)
重叠（overlap）操作可以最大限度地提高系统的利用率。重叠在许多不同的领域很有用，包括执行磁盘 I/O 或将消息发送到远程机器时。在任何一种情况下，开始操作然后切换到其他工作都是一个好主意，这也提高了系统的整体利用率和效率。

### 7.9 无法预知

事实上，在一个通用的操作系统中（比如我们所关心的操作系统），操作系统通常对每个作业的长度知之甚少。因此，我们如何建立一个没有这种先验知识的 SJF/STCF？更进一步，我们如何能够将已经看到的一些想法与 RR 调度程序结合起来，以便响应时间也变得相当不错？

### 7.10 小结

这章讨论两类方法。第一类是运行最短的工作，从而优化周转时间。第二类是交替运行所有工作，从而优化响应时间。但很难做到“鱼与熊掌兼得”，这是系统中常见的、固有的折中。我们也看到了如何将 I/O 结合到场景中，但仍未解决操作系统根本无法看到未来的问题。稍后，我们将看到如何通过构建一个调度程序，利用最近的历史预测未来，从而解决这个问题。这个调度程序称为多级反馈队列，是第 8 章的主题。

习题: 随着量子长度的增加，RR 的响应时间会怎样？你能写出一个方程，计算给定 N 个
工作时，最坏情况的响应时间吗？
![](assets/Pasted%20image%2020230327165601.png)

## Ch 8 调度: 多级反馈队列


多级反馈队列(Multi-level Feedback Queue，MLFQ). 1962 年，Corbato 首次提出多级反馈队列，应用于兼容时分共享系统（CTSS）.该调度程序经过多年的一系列优化，出现在许多现代操作系统中。

多级反馈队列需要解决两方面的问题: 
首先，它要优化周转时间。
其次，MLFQ 希望给交互用户（如用户坐在屏幕前，等着进程结束）很好的交互体验，因此需要降低响应时间。
然而，像时间片轮转这样的算法虽然降低了响应时间，周转时间却很差。
问题是：通常我们对进程一无所知，应该如何构建调度程序来实现这些目标？调度程序如何在运行过程中学习进程的特征，从而做出更好的调度决策？

> 多级反馈队列是用历史经验预测未来的一个典型的例子，操作系统中有很多地方采用了这种技术(同样存在于计算机科学领域的很多其他地方，比如硬件的分支预测及缓存算法）。如果工作有明显的阶段性行为，因此可以预测，那么这种方式会很有效。当然，必须十分小心地使用这种技术，因为它可能出错，让系统做出比一无所知的时候更糟的决定。

### 8.1 MLFQ: 基本规则

MLFQ 中有许多独立的队列(queue), 每个队列有不同的优先级(priority level). 任何时刻，一个工作只能存在于一个队列中。MLFQ 总是优先执行较高优先级的工作（即在较高级队列中的工作).

每个队列中可能会有多个工作，因此具有同样的优先级。在这种情况下，我们就对这些工作采用时间片轮转调度。

MLFQ 的两条基本规则:
- 规则 1：如果 A 的优先级 > B 的优先级，运行 A（不运行 B）.
- 规则 2：如果 A 的优先级 = B 的优先级，轮转运行A 和 B。

![](assets/Pasted%20image%2020230327171527.png)
上图是某时刻, 不同优先级的就绪队列的情况.

### 8.2 尝试 1：如何改变优先级

我们第一次尝试优先级调整算法:
- 规则 3：工作进入系统时，放在最高优先级（最上层队列）。
- 规则 4a：工作用完整个时间片后，降低其优先级（移入下一个队列）。
- 规则 4b：如果工作在其时间片以内主动释放 CPU(如阻塞)，则优先级不变。

![](assets/Pasted%20image%2020230327172954.png)

至此，我们有了基本的 MLFQ。它看起来似乎相当不错，长工作之间可以公平地分享CPU，又能给短工作或交互型工作很好的响应时间。 然而，这种算法有一些非常严重的缺点。

首先, 会有饥饿(starvation)问题. 如果系统有“太多”交互型工作, 就会不断占用CPU, 导致长工作永远无法得到CPU(它们饿死了). 即使在这种情况下, 我们希望这些长工作也能有所进展.

其次，聪明的用户会重写程序，愚弄调度程序(game the scheduler)。愚弄调度程序指的是用一些卑鄙的手段欺骗调度程序，让它给你远超公平的资源。
上述算法对如下的攻击束手无策：进程在时间片用完之前，调用一个 I/O 操作(比如访问一个无关的文件)，从而主动释放 CPU。如此便可以保持在高优先级，占用更多的 CPU 时间。做得好时(比如，每运行 99%的时间片时间就主动放弃一次 CPU), 工作可以几乎独占 CPU。

最后，一个程序可能在不同时间表现不同。一个计算密集的进程可能在某段时间表现为一个交互型的进程。用我们目前的方法，它不会享受系统中其他交互型工作的待遇。

### 8.3 尝试 2：提升优先级

- 规则 5：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。

新规则一下解决了两个问题。首先，进程不会饿死——在最高优先级队列中，它会以轮转的方式，与其他高优先级工作分享 CPU，从而最终获得执行。其次，如果一个 CPU 密集型工作变成了交互型，当它优先级提升时，调度程序会正确对待它。

![](assets/Pasted%20image%2020230327173625.png)

S 的值应该如何设置？如果 S 设置得太高，长工作会饥饿；如果设置得太低，交互型工作又得不到合适的 CPU 时间比例。

### 8.4 尝试 3：更好的计时方式

现在还有一个问题要解决：如何阻止调度程序被愚弄？ 元凶是规则4a 和 4b. 导致工作在时间片以内释放 CPU，就保留它的优先级。
解决方案, 是为 MLFQ 的每层队列提供更完善的 CPU 计时方式(accounting). 调度程序应该记录一个进程在某一层中消耗的总时间, 而不是在调度时重新计时. 只要进程用完了自己的配额, 就将它降到低一优先级的队列中去. 不论它是一次用完的, 还是拆成很多次用完. 因此, 我们重写规则 4a 和 4b.

- 规则 4：一旦工作用完了其在某一层中的时间配额(无论中间主动放弃了多少次CPU), 就降低其优先级(移入低一级队列).

### 8.5 MLFQ 调优及其他问题

关于 MLFQ 调度算法还有一些问题。其中一个大问题是如何配置一个调度程序，例如，配置多少队列？每一层队列的时间片配置多大？为了避免饥饿问题以及进程行为改变，应该多久提升一次进程的优先级？这些问题都没有显而易见的答案，因此只有利用对工作负载的经验，以及后续对调度程序的调优，才会导致令人满意的平衡。

> 通常我们会有一个写满各种参数值默认值的配置文件, 使得系统管理员可以方便地进行修改调整. 然而, 大多数使用者并不会去修改这些默认值, 这时就寄希望于默认值合适了. 这个提示是由资深的 OS 教授 John Ousterhout 提出的, 因此称为Ousterhout 定律(Ousterhout’s Law).

Solaris 的 MLFQ 实现(时分调度类 TS)很容易配置。它提供了一组表来决定进程在其生命周期中如何调整优先级，每层的时间片多大，以及多久提升一个工作的优先级。管理员可以通过这些表，让调度程序的行为方式不同。该表默认有 60 层队列，时间片长度从 20ms（最高优先级），到几百 ms（最低优先级），每一秒左右提升一次进程的优先级。
![](assets/Pasted%20image%2020230327175033.png)

### 8.6 MLFQ：小结
- 规则 1：如果 A 的优先级 > B 的优先级，运行 A（不运行 B）。
- 规则 2：如果 A 的优先级 = B 的优先级，轮转运行 A 和 B。
- 规则 3：工作进入系统时，放在最高优先级（最上层队列）。
- 规则 4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）。
- 规则 5：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。MLFQ 有趣的原因是：它不需要对工作的运行方式有先验知识，而是通过观察工作

MLFQ 有趣的原因是：它不需要对工作的运行方式有先验知识，而是通过观察工作的运行来给出对应的优先级。通过这种方式，MLFQ 可以同时满足各种工作的需求：对于短时间运行的交互型工作，获得类似于 SJF/STCF 的很好的全局性能，同时对长时间运行的CPU 密集型负载也可以公平地、不断地稳步向前。因此，许多系统使用某种类型的 MLFQ作为自己的基础调度程序，包括类 BSD UNIX系统、Solaris以及 WindowsNT 和其后的 Window 系列操作系统。

![](assets/Pasted%20image%2020230327175119.png)
多级反馈队列（Multilevel Feedback Queue）调度算法是「时间⽚轮转算法」和「最⾼优先级算法」的综合和发展。

「多级」表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短。
「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列；

工作方式:
- 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短；
- 新的进程会被放⼊到第⼀级队列的末尾，按先来先服务的原则排队等待被调度，如果在第⼀级队列规定的时间⽚没运⾏完成，则将其转⼊到第⼆级队列的末尾，以此类推，直⾄完成;
- 当较⾼优先级的队列为空，才调度较低优先级的队列中的进程运⾏。如果进程运⾏时，有新进程进⼊较⾼优先级的队列，则停⽌当前运⾏的进程并将其移⼊到原队列末尾，接着让较⾼优先级的进程运⾏；

可以发现，对于短作业可能可以在第⼀级队列很快被处理完。对于⻓作业，如果在第⼀级队列处理不完，可以移⼊下次队列等待被执⾏，虽然等待的时间变⻓了，但是运⾏时间也会更⻓了，所以该算法很好的兼顾了⻓短作业，同时有较好的响应时间。

## Ch9 调度: 比例份额

在本章中, 我们来看一个不同类型的调度程序——比例份额(proportional-share)调度程序, 有时也称为公平份额(fair-share)调度程序. 比例份额算法基于一个简单的想法: 调度程序的最终目标, 是确保每个工作获得一定比例的CPU时间, 而不是优化周转时间和响应时间.

比例份额调度程序有一个非常优秀的现代例子, 由 Waldspurger 和 Weihl 发现, 名为`彩票调度(lottery scheduling)`. 但这个想法其实出现得更早. 基本思想很简单: 每隔一段时间, 都会举行一次彩票抽奖, 以确定接下来应该运行哪个进程. 越是应该频繁运行的进程, 越是应该拥有更多地赢得彩票的机会. 

>关键问题：如何按比例分配 CPU
>如何设计调度程序来按比例分配 CPU？其关键的机制是什么？效率如何？

### 9.1 基本概念: 彩票数表示份额

彩票调度背后是一个非常基本的概念: 彩票数(ticket)代表了进程(或用户或其他)占有某个资源的份额. 一个进程拥有的彩票数占总彩票数的百分比, 就是它占有资源的份额. 

假设有两个进程 A 和 B，A 拥有 75 张彩票，B 拥有 25 张。因此我们希望 A 占用 75%的 CPU 时间，而 B 占用 25%。

通过不断定时地(比如, 每个时间片)抽取彩票, 彩票调度从概率上(但不是确定的)获得这种份额比例. 

彩票调度最精彩的地方在于利用了随机性(randomness). 当你需要做出决定时，采用随机的方式常常是既可靠又简单的选择.

随机方法相对于传统的决策方式，至少有 3 点优势:
第一，随机方法常常可以避免奇怪的边角情况，较传统的算法可能在处理这些情况时遇到麻烦例如内存LRU 替换策略. 虽然 LRU 通常是很好的替换算法，但在有重复序列的负载时表现非常差。但随机方法就没有这种最差情况.

第二，随机方法很轻量，几乎不需要记录任何状态。在传统的公平份额调度算法中，记录每个进程已经获得了多少的 CPU 时间，需要对每个进程计时，这必须在每次运行结束后更新。而采用随机方式后每个进程只需要非常少的状态(即每个进程拥有的彩票号码).

第三，随机方法很快. 只要能很快地产生随机数, 做出决策就很快. 因此, 随机方式在对运行速度要求高的场景非常适用. 当然, 越是需要快的计算速度, 随机就会越倾向于伪随机.
![](assets/Pasted%20image%2020230327185423.png)

彩票(步长)调度的设计中, 最强大(且最基本)的机制是彩票. 在这些例子中, 彩票用于表示一个进程占有 CPU 的份额, 但也可以用在更多的地方. 比如在虚拟机管理程序的虚存管理的最新研究工作中, Waldspurger提出了用彩票来表示用户占用操作系统内存份额的方法.
因此，如果你需要通过什么机制来表示所有权比例, 这个概念可能就是彩票.

### 9.2 彩票机制

彩票调度还提供了一些机制, 以不同且有效的方式来调度彩票. 一种方式是利用彩票货币(ticket currency)的概念. 这种方式允许拥有一组彩票的用户以他们喜欢的某种货币, 将彩票分给自己的不同工作. 之后操作系统再自动将这种货币兑换为正确的全局彩票. 

省略.......

### 9.7 小结

本章介绍了比例份额调度的概念，并简单讨论了两种实现：彩票调度和步长调度。彩票调度通过随机值，聪明地做到了按比例分配。步长调度算法能够确定的获得需要的比例。虽然两者都很有趣，但由于一些原因，`并没有`作为 CPU 调度程序被广泛使用。一个原因是这两种方式都不能很好地适合 I/O. 另一个原因是其中最难的票数分配问题并没有确定的解决方式，例如，如何知道浏览器进程应该拥有多少票数？通用调度程序（像前面讨论的 MLFQ 及其他类似的 Linux 调度程序）做得更好，因此得到了广泛的应用。

比例份额调度程序只有在这些问题可以相对容易解决的领域更有用（例如容易确定份额比例）。例如在虚拟（virtualized）数据中心中，你可能会希望分配 1/4 的 CPU 周期给 Windows 虚拟机，剩余的给 Linux 系统，比例分配的方式可以更简单高效。

所以这章了解一下.

## Ch10 多处理器的调度(高级)

本章将介绍多处理器调度（multiprocessor scheduling）的基础知识。由于本章内容相对较深，建议认真学习`并发`相关的内容后再读。

多核处理器(multicore)将多个 CPU核组装在一块芯片上. 由于计算机的架构师们当时难以让单核 CPU 更快, 同时又不增加太多功耗, 所以这种多核 CPU 很快就变得流行. (单核CPU遇到了瓶颈).

当然，多核 CPU 带来了许多困难. 
主要困难是典型的应用程序(例如你写的很多C程序)都只使用一个 CPU, 增加了更多的 CPU 并没有让这类程序运行得更快.为了解决这个问题, 不得不重写这些应用程序, 使之能`并行(parallel)执行`，也许使用多线程. 多线程应用可以将工作分散到多个 CPU 上, 因此 CPU资源越多就运行越快. 

除了应用程序, 操作系统遇到的一个新的问题是, 多处理器调度(multiprocessor scheduling).
我们讨论了许多单处理器调度的原则，那么如何将这些想法扩展到多处理器上呢？还有什么新的问题需要解决？

关键问题：如何在多处理器上调度工作
操作系统应该如何在多 CPU 上调度工作？会遇到什么新问题？已有的技术依旧适用吗？是否需要
新的思路？

### 10.1 背景：多处理器架构

为了理解多处理器调度带来的新问题，必须先知道它与单 CPU 之间的基本区别。区别的核心在于对硬件缓存(cache)的使用, 以及多处理器之间共享数据的方式. 

在单 CPU 系统中，存在多级的硬件缓存(hardware cache). 缓存是基于局部性（locality）的概念，局部性有两种，即时间局部性和空间局部性。时间局部性是指当一个数据被访问后，它很有可能会在不久的将来被再次访问;  空间局部性指的是，当程序访问地址为 x 的数据时，很有可能会紧接着访问 x 周围的数据，比如遍历数组或指令的顺序执行.

如果系统有多个处理器，并共享同一个内存，如图 10.2 所示，会怎样呢？
![](assets/Pasted%20image%2020230327193750.png)
多 CPU 的情况下缓存要复杂得多. 
假设一个运行在CPU 1上的程序从内存地址 A 读取数据. 由于不在CPU 1的缓存中, 所以系统直接访问内存, 得到值D. 程序然后修改了地址A处的值, 只是将它的缓存更新为新值D'. 将数据写回内存比较慢, 因此系统(通常)会稍后再做. 假设这时操作系统中断了该程序的运行, 并将其交给 CPU 2, 重新读取地址A的数据, 由于 CPU 2的缓存中并没有该数据, 所以会直接从内存中读取, 得到了旧值 D, 而不是正确的值 D'. 
这一普遍的问题称为缓存一致性(cache coherence)问题.

硬件提供了这个问题的基本解决方案：通过监控内存访问，硬件可以保证获得正确的数据，并保证共享内存的唯一性。在基于总线的系统中，一种方式是使用总线窥探（bus snooping）. 每个缓存都通过监听链接所有缓存和内存的总线, 来发现内存访问. 如果CPU发现对它放在缓存中的数据的更新, 会作废(invalidate)本地副本(从缓存中移除), 或更新(update)它(修改为新值). 回写缓存, 如上面提到的, 让事情更复杂(由于对内存的写入稍后才会看到), 你可以想想基本方案如何工作.

### 10.2 别忘了同步

既然缓存已经做了这么多工作来提供一致性，应用程序(或操作系统)还需要关心共享数据的访问吗？依然需要！
跨 CPU 访问(尤其是写入)共享数据或数据结构时, 需要使用互斥原语(比如锁),才能保证正确性（其他方法, 如使用无锁(lock-free)数据结构, 很复杂, 偶尔才使用.)

即使用了锁, 保证了代码如预期, 依然会有问题, 尤其是性能方面. 具体来说，随着 CPU数量的增加，访问同步共享的数据结构会变得很慢。

### 10.3 最后一个问题：缓存亲和度

在设计多处理器调度时遇到的最后一个问题, 是所谓的缓存亲和度(cache affinity). 这个概念很简单：一个进程在某个 CPU 上运行时，会在该 CPU 的缓存中维护许多状态。下次该进程在相同CPU 上运行时, 由于缓存中的数据而执行得更快. 相反, 在不同的 CPU 上执行, 会由于需要重新加载数据而很慢(好在硬件保证的缓存一致性可以保证正确执行). 因此多处理器调度应该考虑到这种缓存亲和性, 并尽可能将进程保持在同一个 CPU 上. 

### 10.4 单队列调度

现在来讨论如何设计一个多处理器系统的调度程序.

最基本的方式是简单地复用单处理器调度的基本架构, 将所有需要调度的工作放入一个单独的队列中, 我们称之为单队列多处理器调度(Single Queue Multiprocessor Scheduling, SQMS).
这个方法最大的优点是简单. 它不需要太多修改, 就可以将原有的策略用于多个 CPU, 选择最适合的工作来运行(例如，如果有两个 CPU，它可能选择两个最合适的工作).

然而, SQMS 有几个明显的短板:
第一个是缺乏可扩展性(scalability). 为了保证在多CPU上正常运行, 调度程序的开发者需要在代码中通过加锁(locking)来保证原子性. 在 SQMS 访问单队列时(如寻找下一个运行的工作), 锁确保得到正确的结果. 
但锁可能带来巨大的性能损失, 尤其是随着系统中的 CPU 数增加时. 随着这种单个锁的争用增加, 系统花费了越来越多的时间在锁的开销上, 较少的时间用于系统应该完成的工作.

第二个主要问题是缓存亲和性. 假设我们有 5 个工作(A、B、C、D、E)和 4 个处理器. 调度队列如下：
![](assets/Pasted%20image%2020230327205953.png)
一段时间后, 假设每个工作依次执行一个时间片, 然后选择另一个工作, 下面是每个CPU可能的调度序列：
![](assets/Pasted%20image%2020230327210027.png)
由于每个 CPU 都简单地从全局共享的队列中选取下一个工作执行，因此每个工作都不断在不同CPU 之间转移, 这与缓存亲和的目标背道而驰.
为了解决这个问题, 大多数SQMS调度程序都引入了一些亲和度机制, 尽可能让进程在同一个CPU 上运行. 保持一些工作的亲和度的同时, 可能需要牺牲其他工作的亲和度来实现负载均衡.
![](assets/Pasted%20image%2020230327210207.png)
我们看到, SQMS调度方式有优势也有不足. 优势是能够从单 CPU 调度程序很简单地发展而来, 根据定义, 它只有一个队列. 然而, 它的扩展性不好(由于同步开销有限), 并且不能很好地保证缓存亲和度. 

### 10.5 多队列调度

正是由于单队列调度程序的这些问题，有些系统使用了多队列的方案，比如每个 CPU一个队列。
我们称之为多队列多处理器调度（Multi-Queue Multiprocessor Scheduling，MQMS）.
在 MQMS 中，基本调度框架包含多个调度队列, 每个队列可以使用不同的调度规则, 比如轮转或其他任何可能的算法.
当一个工作进入系统后，系统会依照一些启发性规则（如随机或选择较空的队列）将其放入某个调度队列。这样一来，每个 CPU 调度之间相互独立，就避免了单队列的方式中由于数据共享及同步带来的问题。

例如，假设系统中有两个 CPU（CPU 0 和 CPU 1）。这时一些工作进入系统：A、B、C和 D。由于每个 CPU 都有自己的调度队列，操作系统需要决定每个工作放入哪个队列。可能像下面这样做：
![](assets/Pasted%20image%2020230327220929.png)
根据不同队列的调度策略，每个 CPU 从两个工作中选择，决定谁将运行。例如，利用轮转，调度结果可能如下所示：
![](assets/Pasted%20image%2020230327220949.png)
MQMS 比 SQMS 有明显的优势，它天生更具有可扩展性。
队列的数量会随着 CPU 的增加而增加，因此锁和缓存争用的开销不是大问题。此外，MQMS 天生具有良好的缓存亲和度。所有工作都保持在固定的 CPU 上，因而可以很好地利用缓存数据。
但是，如果稍加注意，你可能会发现有一个新问题(这在多队列的方法中是根本的), 即负载不均(load imbalance). 假定和上面设定一样(4 个工作，2 个 CPU), 但假设一个工作（如 C）这时执行完毕。现在调度队列如下：
![](assets/Pasted%20image%2020230327221635.png)
如果对系统中每个队列都执行轮转调度策略，会获得如下调度结果：
![](assets/Pasted%20image%2020230327221653.png)
从图中可以看出，A 获得了 B 和 D 两倍的 CPU 时间，这不是期望的结果。更糟的是，假设 A 和 C 都执行完毕，系统中只有 B 和 D。调度队列看起来如下：
![](assets/Pasted%20image%2020230327221713.png)
![](assets/Pasted%20image%2020230327221726.png)

关键问题：如何应对负载不均
多队列多处理器调度程序应该如何处理负载不均问题，从而更好地实现预期的调度目标？
最明显的答案是让工作移动，这种技术我们称为迁移（migration）。通过工作的跨 CPU迁移，可以真正实现负载均衡。
在这种情况下，期望的迁移很容易理解：操作系统应该将 B 或 D 迁移到 CPU0。这次工作迁移导致负载均衡，皆大欢喜。
更棘手的情况是前面的例子，A 独自留在 CPU 0 上，B 和 D 在 CPU 1 上交替运行。

在这种情况下，单次迁移并不能解决问题。应该怎么做呢？答案是不断地迁移一个或多个工作。
一种可能的解决方案是不断切换工作，如下面的时间线所示。可以看到，开始的时候 A 独享 CPU 0，B 和 D 在 CPU 1。一些时间片后，B 迁移到 CPU 0 与 A 竞争，D 则独享 CPU 1 一段时间。这样就实现了负载均衡。
![](assets/Pasted%20image%2020230327222013.png)

当然，还有其他不同的迁移模式。但现在是最棘手的部分：系统如何决定发起这样的迁移？

一个基本的方法是采用一种技术，名为工作窃取（work stealing）.通过这种方法，工作量较少的（源）队列不定期地“偷看”其他（目标）队列是不是比自己的工作多。如果目标队列比源队列（显著地）更满，就从目标队列“窃取”一个或多个工作，实现负载均衡。

当然，这种方法也有让人抓狂的地方——如果太频繁地检查其他队列，就会带来较高的开销，可扩展性不好，而这是多队列调度最初的全部目标！相反，如果检查间隔太长，又可能会带来严重的负载不均. 找到合适的阈值仍然是黑魔法, 这在系统策略设计中很常见。

### 10.6 Linux 多处理器调度

有趣的是，在构建多处理器调度程序方面，Linux 社区一直没有达成共识。
一直以来，存在 3 种不同的调度程序：O(1)调度程序、完全公平调度程序（CFS）以及 BF 调度程序（BFS）.
O(1) CFS 采用多队列，而 BFS 采用单队列，这说明两种方法都可以成功。当然它们之
间还有很多不同的细节。
例如，O(1)调度程序是基于优先级的（类似于之前介绍的 MLFQ），随时间推移改变进程的优先级，然后调度最高优先级进程，来实现各种调度目标。交互性得到了特别关注。与之不同，CFS 是确定的比例调度方法（类似之前介绍的步长调度）。BFS作为三个算法中唯一采用单队列的算法，也基于比例调度，但采用了更复杂的方案，称为最早最合适虚拟截止时间优先算法(EEVEF).

### 10.7 小结

本章介绍了多处理器调度的不同方法。其中单队列的方式（SQMS）比较容易构建，负载均衡较好，但在扩展性和缓存亲和度方面有着固有的缺陷。多队列的方式（MQMS）有很好的扩展性和缓存亲和度，但实现负载均衡却很困难，也更复杂。无论采用哪种方式，都没有简单的答案：构建一个通用的调度程序仍是一项令人生畏的任务，因为即使很小的代码变动，也有可能导致巨大的行为差异。除非很清楚自己在做什么，或者有人付你很多钱，否则别干这种事。