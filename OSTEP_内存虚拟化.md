用户程序生成的每个地址都是虚拟地址（every address generated by a user program is a virtual address）。操作系统只是为每个进程提供一个假象，具体来说，就是它拥有自己的大量私有内存。在一些硬件帮助下，操作系统会将这些假的虚拟地址变成真实的物理地址，从而能够找到想要的信息。

## Ch13 抽象: 地址空间

从早起的OS开始, 看这一路的演变.

### 13.1 早期系统

![](assets/Pasted%20image%2020230328150336.png)
从内存来看，早期的机器并没有给用户提供什么抽象。基本上，机器的物理内存看起来如图 13.1 所示。
操作系统曾经是一组函数（实际上是一个库），在内存中（在本例中，从物理地址 0 开始），然后有一个正在运行的程序（进程），目前在物理内存中（在本例中，从物理地址 64KB 开始），并使用剩余的内存。这里几乎没有抽象，用户对操作系统的要求也不多。
这个时候只能运行一个程序.

### 13.2 多道程序和时分共享

过了一段时间，由于机器昂贵，人们开始更有效地共享机器. 多道程序（multiprogramming）
系统时代开启. 其中多个进程在给定时间准备运行，比如当有一个进程在等待 I/O 操作的时候，
操作系统会切换这些进程，这样增加了 CPU 的有效利用率(utilization). 那时候，效率
(efficiency)的提高尤其重要.

但很快，人们开始对机器要求更多，分时系统的时代诞生了. 程序员厌倦了长时间的（因此也是低效率的）编程—调试循环, 交互性（interactivity）变得很重要，因为许多用户可能同时在使用机器，每个人都在等待（或希望）他们执行的任务及时响应.

一种实现时分共享的方法，是让一个进程单独占用全部内存运行一小段时间, 然后停止它，并将它所有的状态信息保存在磁盘上（包含所有的物理内存），加载其他进程的状态信息，再运行一段时间，这就实现了某种比较粗糙的机器共享.
这种方法有一个问题：太慢了，特别是当内存增长的时候。 在进程切换的时候，我们仍然将进程信息放在内存中(不在放到磁盘中)，这样操作系统可以更有效率地实现时分共享.

![](assets/Pasted%20image%2020230328151227.png)

随着时分共享变得更流行，人们对操作系统又有了新的要求。特别是多个程序同时驻留在内存中，使保护（protection）成为重要问题。人们不希望一个进程可以读取其他进程的内存，更别说修改了。

### 13.3 地址空间

操作系统需要提供一个易用（easy to use）的物理内存抽象。这个抽象叫作地址空间（address space），是运行的程序看到的系统中的内存.
理解这个基本的操作系统内存抽象，是了解内存虚拟化的关键。

一个进程的地址空间包含运行的程序的所有内存状态。比如：程序的`代码`（code，指令）必须在内存中，因此它们在地址空间里。当程序在运行的时候，利用`栈`（stack）来保存当前的函数调用信息，分配空间给局部变量，传递参数和函数返回值。最后，`堆`（heap）用于管理动态分配的、用户管理的内存，就像你从 C 语言中调用 malloc()或面向对象语言（如 C ++或 Java）中调用 new 获得内存。当然，还有其他的东西（例如，静态初始化的变量），但现在假设只有这 3 个部分：代码、栈和堆。
![](assets/Pasted%20image%2020230328151912.png)
代码区的大小不会变, 堆和栈在运行中, 是可以变大或变小的(内存的申请分配与释放).

当我们`描述地址空间时`，所描述的是操作系统提供给运行程序的`抽象`（abstract）。
`程序不在物理地址 0～16KB 的内存`中，而是加载在`任意的物理地址`。
回顾图 13.2 中的进程A、B 和 C，你可以看到每个进程如何加载到内存中的不同地址. ABC三个进程每个进程的内部结构, 就是图13.3的样子.

关键问题：如何虚拟化内存
操作系统如何在单一的物理内存上为多个运行的进程（所有进程共享内存）构建一个私有的、可能很大的地址空间的抽象？

当操作系统在做这个工作时，我们说操作系统在虚拟化内存（virtualizing memory), 因为每个运行着的程序都认为自己被加载到特定地址(例如 0)的内存中, 并且拥有整个内存地址空间(如32位或 64 位).  但实际上在物理内存中, 它只有一小块而已(结合图13.2和13.3).

例如，当图 13.2 中的进程 A 尝试在`地址 0`(称为`虚拟地址`, virtual address)执行加载操作时，然而操作系统在`硬件的支持`下，出于某种原因，必须确保不是加载到`物理地址 0`，而是物理地址 320KB（这是 A 载入实际内存的地址）。这是内存虚拟化的关键，这是世界上每一个现代计算机系统的基础。

>隔离是建立可靠系统的关键原则。如果两个实体相互隔离，这意味着一个实体的失败不会影响另一个实体。操作系统力求让进程彼此隔离，从而防止相互造成伤害。通过内存隔离，操作系统进一步确保运行程序不会影响底层操作系统的操作。
>微内核也是这种原则的产物. 一个内核模块崩溃, 系统整体不会崩溃.

### 13.4 目标

虚拟内存(VM)系统的一个主要目标是`透明(transparency)`. 
操作系统实现虚拟内存的方式，应该让运行的程序看不见。因此，程序不应该感知到内存被虚拟化的事实，相反，程序的行为就好像它拥有自己的私有物理内存。在幕后，操作系统（和硬件）完成了所有的工作，让不同的工作复用内存，从而实现这个假象。

虚拟内存的另一个目标是`效率(efficiency)`. 
操作系统应该追求虚拟化尽可能高效(efficient)，包括时间上（即不会使程序运行得更慢）和空间上（即不需要太多额外的内存来支持虚拟化）。在实现高效率虚拟化时，操作系统将不得不依靠硬件支持，包括 TLB 这样的硬件功能.


虚拟内存第三个目标是`保护(protection)`. 
操作系统应确保进程受到保护(protect), 不会受其他进程影响, 操作系统本身也不会受进程影响. 当一个进程执行加载、存储或指令提取时, 它不会以任何方式访问或影响任何其他进程或操作系统本身的内核内存(即在这个进程的地址空间之外的任何内容). 因此, 保护让我们能够在进程之间提供隔离(isolation)的特性, 每个进程都应该在自己的独立环境中运行, 避免其他出错或恶意进程的影响.

> 你看到的所有地址都不是真的, 你写的C程序里%p打印出来的都是虚拟地址. shell跑两个进程, 打印出来的地址可能是相同的. 而实际上在物理内存上两个进程的地址空间肯定不同.

实际上，作为用户级程序的程序员，可以看到的任何地址都是虚拟地址。只有操作系统，通过精妙的虚拟化内存技术，知道这些指令和数据所在的物理内存的位置。所以永远不要忘记：如果你在一个程序中打印出一个地址，那就是一个虚拟的地址。虚拟地址只是提供地址如何在内存中分布的假象，只有操作系统（和硬件）才知道物理地址。 
虚拟地址由操作系统和硬件翻译成物理地址，以便从真实的物理位置获取该地址的值。

### 13.5 小结

虚拟内存系统负责为程序提供一个巨大的、稀疏的、私有的地址空间的假象，其中保存了程序的所有指令和数据。操作系统在专门硬件的帮助下，通过每一个虚拟内存的索引，将其转换为物理地址，物理内存根据获得的物理地址但获取所需的信息。操作系统会同时对许多进程执行此操作，并且确保程序之间互相不会受到影响，也不会影响操作系统。整个方法需要大量的机制（很多底层机制）和一些关键的策略。


## Ch14 插叙: 内存操作API

介绍 UNIX 操作系统的内存分配接口. 关键问题：如何分配和管理内存
在 UNIX/C 程序中，理解如何分配和管理内存是构建健壮和可靠软件的重要基础。通常使用哪些接口？哪些错误需要避免?

### 14.1 内存类型

在运行一个 C 程序的时候, 会分配两种类型的内存. 第一种称为`栈内存`, 它的申请和释放操作是编译器来隐式管理的, 所以有时也称为`自动(automatic)内存`. 
你在函数内声明个变量, 编译器在你进入该函数时, 在栈上给你分配个空间. 函数运行结束, 这个栈空间就随着栈帧被释放掉了. 那如果你希望某些信息存在于函数调用之外，就不要放在栈上。

第二种类型的内存，即所谓的堆（heap）内存，其中所有的申请和释放操作都由程序员显式地完成。它不会被自动释放掉, 所以要注意.

### 14.2 malloc()调用

这个是用户态库函数. 在头文件 stdlib.h中有声明. 实际上, 甚至都不需这样做, 因为 C 库是 C 程序默认链接的, 其中就有`mallock()`的代码，加上这个头文件只是让编译器检查你是否正确调用了 malloc()（即传入参数的数目正确且类型正确）。
不建议直接传入一个数字作为参数, 可以使用sizeof或者宏. 这个大小, 编译时就已经知道了.
注意sizeof(一个指针变量名)的情况, 跟sizeof(一个数组变量名)的区别.
关于字符串, 有个习惯用法: malloc(strlen(s) + 1). 这个是跟sizeof(指针变量名)是有关的, 因为这样拿不到目标字符串的长度的. 而strlen却可以拿到除了`'\0'`的字符串长度.
malloc()返回一个指向 void 类型的指针, 这样做只是 C 中传回地址的方式，让程序员决定如何处理它. 程序员将进一步使用所谓的强制类型转换(cast).

### 14.3 free()调用

分配内存很简单. 难在知道何时、如何以及是否释放内存. 不释放就会内存泄露.

### 14.4 常见错误

面向对象语言比如java, 会有自己的内存管理, 会有垃圾收集器会帮你自动释放.

- 忘记分配内存

比如你要把字符串复制到一个指针指向的内存空间, 而你却忘了申请这个空间. 可以用 strdup()替你分配, 并完成复制操作咯.

- 没有分配足够的内存

没有分配足够的内存, 就会缓冲区溢出(buffer overflow).
溢出可能具有很大的危害，实际上是系统中许多安全漏洞的来源. 在有些情况下，malloc 库总是分配一些额外的空间，因此你的程序实际上溢出时不会踩到其他变量. 还有一些情况下，该程序确实会发生故障和崩溃.

- 忘记初始化分配的内存

读取未初始化的内存数据, 进行使用是很危险的.

- 忘记释放内存

虽然申请的内存是在进程内, 进程跑完了, 就会回收. 但这是个坏习惯. 程序跑着跑着, 怎么就没有内存了呢.

- 在用完之前释放内存

内存还在用, 就释放了. 基本会崩.

- 反复释放内存

重复释放内存(double free). 内存分配库可能会感到困惑，并且会做各种奇怪的事情，崩溃是常见的结果。

- free()参数错误

系统中实际存在两级内存管理, 第一级是由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出（或以其他方式结束）时将其回收。
第二级管理在每个进程中，例如在调用 malloc()和 free()时，在堆内管理。即使你没有调用 free()（并因此泄露了堆中的内存），操作系统也会在程序结束运行时，收回进程的所有
内存（包括用于代码、栈，以及相关堆的内存页）。无论地址空间中堆的状态如何，操作系统都会在进程终止时收回所有这些页面，从而确保即使没有释放内存，也不会丢失内存。

如果你的进程任务很短, 不free也会被OS回收. 但你的进程是常驻的进程, 那内存泄露可要了命了.

由于内存出错很常见，整个工具生态圈已经开发出来，可以帮助你在代码中找到这些问题。比如purify和valgrind. 这是两个很好用的内存问题排查的工具.

### 14.5 底层操作系统支持

malloc()和 free() 不是系统调用, 而是库调用. malloc 库管理虚拟地址空间内的空间，但是它本身是建立在一些系统调用之上的，这些系统调用会进入操作系统，来请求本多内存或者将一些内容释放回系统。

有一个系统调用叫 brk, 它被用来改变程序分断（break）的位置, 也就是堆尾(结束)的位置.
它需要一个参数(新break的地址), 从而根据新break是大于还是小于当前break, 来增加或减
小堆空间的大小. 另一个调用sbrk的参数是传入一个增量, 但目的是类似的.
一般写程序不会用这两个系统调用的.

还可以通过 mmap()调用从操作系统获取内存, 通过传入正确的参数，mmap()可以在程序中创建一个匿名（anonymous）内存区域——这个区域不与任何特定文件相关联，而是与交换空间（swap space）相关联，稍后我们将在虚拟内存中详细讨论。这种内存也可以像堆一样对待并管理。

### 14.6 其他调用

calloc: 自动初始化分配的内存.
realloc:  若创建一个新的更大的内存区域，则将旧区域复制到其中，并返回新区域的指针。

## Ch15 机制: 地址转换

为了实现高效的虚拟化，操作系统应该尽量让程序自己运行，同时通过在关键点的及时介入（interposing），来保持对硬件的控制。高效和控制是现代操作系统的两个主要目标。
高效决定了我们要利用硬件的支持, 这在开始的时候非常初级（如使用一些寄存器），但会变得相当复杂（比如我们会讲到的 TLB、页表等）。
控制意味着操作系统要确保应用程序只能访问它自己的内存空间. 因此，要保护应用程序不会相互影响，也不会影响操作系统，我们需要硬件的帮助。
最后，我们对虚拟内存还有一点要求，即灵活性.具体来说，我们希望程序能以任何方式访问它自己的地址空间，从而让系统更容易编程。

关键问题：如何高效、灵活地虚拟化内存
如何实现高效的内存虚拟化？如何提供应用程序所需的灵活性？如何保持控制应用程序可访问的内存位置，从而确保应用程序的内存访问受到合理的限制？如何高效地实现这一切？

这里会用一种通用技术, 有时被称为基于硬件的地址转换(hardware-based address translation), 简称为地址转换（address translation）。
它可以看成是`受限直接执行`这种一般方法的补充。
利用地址转换，硬件对每次内存访问进行处理（即指令获取、数据读取或写入），将指令中的虚拟（virtual）地址转换为数据实际存储的物理（physical）地址。
在每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中实际的位置。

仅仅依靠硬件不足以实现虚拟内存，因为它只是提供了底层机制来提高效率。操作系统必须在关键的位置介入，设置好硬件，以便完成正确的地址转换。因此它必须管理内存（manage memory），记录被占用和空闲的内存位置，并明智而谨慎地介入，保持对内存使用的控制。

虚拟现实的背后是丑陋的物理事实：许多程序其实是在同一时间共享着内存，就像 CPU（或多个 CPU）在不同的程序间切换运行。
通过虚拟化，操作系统（在硬件的帮助下）将丑陋的机器现实转化成一种有用的、强大的、易于使用的抽象。

### 15.1 假设

我们先假设用户的虚拟地址空间必须连续地放在物理内存中。同时，为了简单，我们假设虚拟地址空间不是很大，具体来说，小于物理内存的大小。最后，假设每个地址空间的大小完全一样。
后面会逐步打破这些假设.

### 15.2 一个例子

为了更好地理解实现地址转换需要什么，以及为什么需要，我们先来看一个简单的例子。
![](assets/Pasted%20image%2020230328172637.png)
设想一个进程的地址空间如图 15.1 所示。
这里我们要检查一小段代码，它从内存中加载一个值，对它加 3，然后将它存回内存。你可以设想，这段代码的 C 语言形式可能像这样：
```c
void func() {
	int x;
	x = x + 3; 
```
编译器将这行代码转化为汇编语句，可能像下面这样（x86 汇编）。我们可以用 Linux的 objdump 或者 Mac 的 otool 将它反汇编：
```asm
128: movl 0x0(%ebx), %eax ;load 0+ebx into eax
132: addl $0x03, %eax ;add 3 to eax register
135: movl %eax, 0x0(%ebx) ;store eax back to mem
```
这段代码相对简单，它假定 x 的地址已经存入寄存器 ebx，之后通过 movl 指令将这个地址的值加载到通用寄存器 eax（长字移动）。下一条指令对 eax 的内容加 3。最后一条指令将 eax 中的值写回到内存的同一位置。

> 介入是一种很常见又很有用的技术，计算机系统中使用介入常常能带来很好的效果。在虚拟内存中，硬件可以介入到每次内存访问中，将进程提供的虚拟地址转换为数据实际存储的物理地址。但是，一般化的介入技术有更广阔的应用空间，实际上几乎所有良好定义的接口都应该提供功能介入机制，以便增加功能或者在其他方面提升系统。这种方式最基本的优点是透明（transparency），介入完成时通常不需要改动接口的客户端，因此客户端不需要任何改动。

在图 15.1 中，可以看到代码和数据都位于进程的地址空间，3 条指令序列位于地址 128（靠近头部的代码段），变量 x 的值位于地址 15KB（在靠近底部的栈中）。如图 15.1 所示，x的初始值是 3000。

如果这 3 条指令执行，从进程的角度来看，发生了以下几次内存访问：
- 从地址 128 获取指令；
- 执行指令（从地址 15KB 加载数据）；
- 从地址 132 获取命令；
- 执行命令（没有内存访问）；
- 从地址 135 获取指令；
- 执行指令（新值存入地址 15KB）。

从`程序的角度`来看，它的地址空间（address space）从 0 开始到 16KB 结束。它包含的所有内存引用都应该在这个范围内。然而，对`虚拟内存`来说，操作系统希望将这个进程地址空间放在`物理内存的其他位置`，并不一定从地址 0 开始。
因此我们遇到了如下问题：怎样在内存中重定位这个进程，同时对该进程透(transparent)？怎么样提供一种虚拟地址空间从 0 开始的假象，而实际上地址空间位于另外某个物理地址？

![](assets/Pasted%20image%2020230328173557.png)
图15.2展示了一个例子, 说明这个进程的地址空间被放入物理内存后可能的样子. 从图15.2中可以看到, 操作系统将第一块物理内存留给了自己, 并将上述例子中的`进程地址空间重定位`到从32KB开始的物理内存地址. 剩下的两块内存空闲(16～32KB 和 48～64KB). 

### 15.3 动态(基于硬件)重定位

为了更好地理解`基于硬件的地址转换`, 先看看其第一次应用. 1950s后期, 首次出现, 思想就是: 基址加界限机制(base and bound). 又称为动态重定位(dynamic relocation).

具体来说，每个 CPU 需要两个硬件寄存器: 基址(base)寄存器和界限(bound)寄存器, 有时称为限制(limit)寄存器.
这组基址和界限寄存器，让我们能够将地址空间放在物理内存的任何位置，同时又能确保进程只能访问自己的地址空间.

采用这种方式, 在`编写和编译`程序时`假设地址空间从零开始`. 但是，当程序真正执行时，`操作系统会决定`其在`物理内存`中的`实际加载`地址，并将起始地址`记录`在`基址寄存器`中.
比如图15.2, 就可以把32K地址, 放到基址寄存器中, 就确定了进程的起始地址.

当进程运行时，有趣的事情发生了. 现在，该进程产生的所有内存引用，都会被处理器通过以下方式转换为物理地址: 
physical address = virtual address + base

进程中使用的内存引用都是虚拟地址(virtual address), `硬件`接下来将虚拟地址加上基址寄存器中的内容. 得到物理地址(physical address), 再通过地址总线发给内存系统. 

为了更好地理解，让我们追踪一条指令执行的情况。具体来看前面序列中的一条指令：
128: movl 0x0(%ebx), %eax

程序计数器(PC)首先被设置为128. 当硬件需要获取这条指令时, 它先将这个值加上基址寄存器中的 32KB(32768), 得到实际的物理地址32896, 然后硬件从这个物理地址获取指令.
取完指令, 指令译码，然后处理器开始执行该指令。这时，进程发起从虚拟地址15KB去取数据, 处理器同样将虚拟地址加上基址寄存器内容(32KB), 得到最终的物理地址47KB, 从而获得需要的数据. 

将`虚拟地址`转换为`物理地址`, 这正是所谓的`地址转换(address translation)技术`.
也就是说，硬件取得进程认为自己要访问的地址，将此地址转换成数据实际位于的物理地址。
由于这种重定位是在运行时发生的, 而且我们甚至可以在进程开始运行后改变其地址空间, 这种
技术一般被称为动态重定位(dynamic relocation).

> 在动态重定位的过程中，只有很少的硬件参与，但获得了很好的效果。一个基址寄存器将虚拟地址转换为物理地址，一个界限寄存器确保这个地址在进程地址空间的范围内。它们一起提供了既简单又高效的虚拟内存机制。

界限寄存器提供了访问保护. 图15.2的例子, 界限寄存器里的值就是16KB. 如果进程需要访问超过这个界限或者为负数的虚拟地址，CPU 将触发异常，进程最终可能被终止。
界限寄存器的用处在于, 它确保了进程产生的所有地址都在进程的地址“界限”中.

这种基址寄存器配合界限寄存器的硬件结构是`芯片`中的（每个 CPU 一对）。有时我们将CPU 的这个负责地址转换的部分统称为`内存管理单元`（Memory Management Unit，MMU）。随着我们开发更复杂的内存管理技术，MMU 也将有更复杂的电路和功能。

关于`界限寄存器`再补充一点, 它通常有两种使用方式. 
在一种方式中(像上面那样), 它记录地址空间的大小, 硬件在将虚拟地址与基址寄存器内容求和前, 就检查这个界限. 
另一种方式是界限寄存器中记录地址空间结束的物理地址, 硬件在转化虚拟地址到物理地址之后才去检查这个界限. 这两种方式在逻辑上是等价的. 简单起见, 我们这里假设采用第一种方式. 

- 转换示例

设想一个进程拥有 4KB 大小地址空间，它被加载到从 16KB 开始的物理内存中。一些地址转换结果见表 15.1。
![](assets/Pasted%20image%2020230328184231.png)
虚拟地址其实就是偏移量.

>补充：数据结构——空闲列表
>操作系统必须记录哪些空闲内存没有使用，以便能够为进程分配内存。很多不同的数据结构可以用于这项任务，其中最简单的（也是我们假定在这里采用的）是空闲列表（free list）。它就是一个列表，记录当前没有使用的物理内存的范围.

### 15.4 硬件支持: 总结

总结一下需要的硬件支持(见表 15.2).
首先, 正如在CPU虚拟化的章节中提到的, 我们需要两种CPU模式. 操作系统在特权模式(privileged mode，或内核模式，kernelmode), 可以访问整个机器资源.
应用程序在用户模式（user mode）运行，只能做有限的操作。只要一个位，也许保存在处理器状态字（processor status word）中，就能说明当前的CPU 运行模式。
在一些特殊的时刻（如系统调用、异常或中断），CPU 会切换状态。
![](assets/Pasted%20image%2020230328185845.png)
硬件还必须提供基址和界限寄存器(base and bounds register), 因此每个CPU的内存管理单元(Memory Management Unit，MMU)都需要这两个额外的寄存器.
用户程序的虚拟地址, 要转为物理地址, 硬件也必须能检查物理地址是否有效，通过界限寄存器和CPU 内的一些电路来实现。

硬件应该提供一些特殊的指令，用于修改基址寄存器和界限寄存器，允许操作系统在切换进程时改变它们。这些指令是特权（privileged）指令，只有在内核模式下，才能修改这些寄存器。

在用户程序尝试非法访问内存（越界访问）时，CPU必须能够产生异常（exception）。
在这种情况下，CPU 应该阻止用户程序的执行，并安排操作系统的“越界”异常处理程（exception handler）去处理。操作系统的处理程序会做出正确的响应，比如在这种情况下终止进程。类似地，如果用户程序尝试修改基址或者界限寄存器时，CPU 也应该产生异常.
CPU 还必须提供一种方法，来通知它这些处理程序的位置，因此又需要另一些特权指令。

### 15.5 操作系统的问题

为了支持动态重定位，硬件添加了新的功能，使得操作系统有了一些必须处理的新问题.
硬件支持和操作系统管理结合在一起，实现了一个简单的虚拟内存。具体来说，在一些关键的时刻操作系统需要介入，以实现基址和界限方式的虚拟内存.
![](assets/Pasted%20image%2020230328191038.png)
第一, 在进程创建时, 操作系统必须采取行动, 为进程的地址空间找到内存空间.
由于我们假设每个进程的地址空间小于物理内存的大小, 并且大小相同, 这对操作系统来说简单.
它可以把整个物理内存看作一组槽块, 标记了空闲或已用.
当新进程创建时，操作系统检索这个数据结构（常被称为空闲列表，free list），为新地址空间找到位置，并将其标记为已用。如果地址空间可变，那就复杂了，后续章节中讨论.

看一个例子, 在图15.2中, 操作系统将物理内存的第一个槽块分配给自己, 然后将例子中的进程重定位到物理内存地址32KB. 另两个槽块(16～32KB, 48～64KB)空闲, 因此空闲列表(free list)就包含这两个槽块.

第二, 在进程终止时(正常退出，或因行为不端被强制终止), 操作系统也必须做一些工作，回收它的所有内存, 给其他进程或者操作系统使用. 在进程终止时, 操作系统会将这些内存放回到空闲列表, 并根据需要清除相关的数据结构. 

第三，在上下文切换时，操作系统也必须执行一些额外的操作。
每个CPU毕竟只有一个基址寄存器和一个界限寄存器, 但对于每个运行的进程, 它们的值都不同, 因为每个程序被加载到内存中不同的物理地址.
因此, 在切换进程时, 操作系统必须保存和恢复基础和界限寄存器. 
具体来说, 当操作系统决定中止当前的运行进程时, 它必须将当前基址和界限寄存器中的内容保存在内存中, 放在某种每个进程都有的结构中, 如进程结构(process structure)或进程控制块(Process Control Block, PCB)中。
当操作系统恢复执行某个进程时(或第一次执行), 也必须给基址和界限寄存器设置正确的值.

注意, 当进程暂停时(即没有运行), 操作系统可以改变其地址空间的物理位置, 这很容易. 
要移动进程的地址空间, 操作系统首先让进程停止运行, 然后将地址空间拷贝到新位置, 最后更新保存的基址寄存器(在进程结构中), 指向新位置.
当该进程恢复执行时, 它的(新)基址寄存器会被恢复, 它再次开始运行, 显然它的指令和数据都在新的内存位置了.

第四, 操作系统必须提供异常处理程序(exception handler), 或要一些调用的函数, 像上面提到的那样。操作系统在启动时加载这些处理程序(通过特权命令). 
例如, 当一个进程试图越界访问内存时, CPU 会触发异常. 在这种异常产生时, 操作系统必须准备采取行动. 通常操作系统会做出充满敌意的反应: 终止错误进程.  

表 15.4 为按时间线展示了大多数硬件与操作系统的交互。
注意，地址转换过程完全由硬件处理，没有操作系统的介入。
在这个时候，发生时钟中断，操作系统切换到进程 B 运行，它执行了“错误的加载”（对一个非法内存地址），这时操作系统必须介入，终止该进程，清理并释放进程 B 占用的内存，将它从进程表中移除。
从表中可以看出，我们仍然遵循受限直接访问（limited direct execution）的基本方法，大多数情况下，操作系统正确设置硬件后，就任凭进程直接运行在 CPU 上，只有进程行为不端时才介入。
![](assets/Pasted%20image%2020230328195909.png)
![](assets/Pasted%20image%2020230328195921.png)

### 15.6 小结

本章通过虚拟内存使用的一种特殊机制，即地址转换（address translation），扩展了受限直接访问的概念。
利用地址转换，操作系统可以控制进程的所有内存访问，确保访问在地址空间的界限内.
这个技术高效的关键是硬件支持，硬件快速地将所有内存访问操作中的虚拟地址（进程自己看到的内存位置）转换为物理地址（实际位置）.
所有的这一切对进程来说都是透明的，进程并不知道自己使用的内存引用已经被重定位.

了解了一种特殊的虚拟化方式，称为基址加界限的动态重定位.
这种方式非常高效，因为只需要很少的硬件逻辑, 就可以将虚拟地址和基址寄存器加起来，并检查进程产生的地址没有越界。
基址加界限也提供了保护，操作系统和硬件的协作，确保没有进程能够访问其地址空间之外的内容。

遗憾的是，这个简单的动态重定位技术有效率低下的问题.
例如，从图 15.2 中可以看到，重定位的进程使用了从 32KB 到 48KB 的物理内存，但由于该进程的栈区和堆区并不很大，导致这块内存区域中大量的空间被浪费.
这种浪费通常称为内部碎片（internal fragmentation），指的是已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费。
(在我们当前的方式中，即使有足够的物理内存容纳更多进程，但我们目前要求将地址空间放在固定大小的槽块中，因此会出现内部碎片).
所以，我们需要更复杂的机制，以便更好地利用物理内存，避免内部碎片。

本章的第一次尝试是将基址加界限的概念稍稍泛化，得到`分段(segmentation)`的概念，我们接下来将讨论.

## Ch16 分段

到目前为止，我们都是假设将所有进程的地址空间完整地加载到内存中。利用基址和界限寄存器，操作系统很容易将不同进程`重定位`到不同的物理内存区域. 
但是，对于这些内存区域，你可能已经注意到：栈和堆之间，有一大块“空闲”空间。
![](assets/Pasted%20image%2020230329043554.png)
从图 16.1 中可知，如果我们将整个地址空间放入物理内存，那么栈和堆之间的空间并没有被进程使用，却依然占用了实际的物理内存。
因此, 简单的通过基址寄存器和界限寄存器实现的虚拟内存很浪费.
而且, 如果剩余物理内存无法提供连续区域来放置完整的地址空间，别的进程便无法运行.
这种基址加界限的方式看来并不像我们期望的那样灵活。

关键问题：怎样支持大地址空间
怎样支持大地址空间，同时栈和堆之间(可能)有大量空闲空间? 在之前的例子里，地址空间非常小，所以这种浪费并不明显。但设想一个 32 位(4GB)的地址空间，通常的程序只会使用几兆的内存，但需要整个地址空间都放在内存中。

### 16.1 分段：泛化的基址/界限

为了解决这个问题, 分段(segmentation)的概念应运而生. 
这个想法很简单, 在MMU中引入不止一对基址和界限寄存器, 而是给地址空间内的每个逻辑段(segment)分配一对.
一个段只是地址空间里的一个连续定长的区域, 在典型的地址空间里有3个逻辑不同的段: 代码, 栈和堆(还有个数据段). 
分段的机制使得操作系统能够将不同的段放到不同的物理内存区域, 从而避免了虚拟地址空间中的未使用部分占用物理内存. 

假设我们希望将图 16.1 中的地址空间放入物理内存。通过给每个段一对基址和界限寄存器，可以将每个段独立地放入物理内存。如图 16.2 所示，64KB 的物理内存中放置了 3 个段（为操作系统保留 16KB）。
从图中可以看到，只有已用的内存才在物理内存中分配空间，因此可以容纳巨大的地址空间，其中包含大量未使用的地址空间(有时又称为`稀疏地址空间`, sparse address spaces).

那就需要 MMU 中的硬件结构来支持分断：在这种情况下，需要一组3对基址和界限寄存器。表 16.1 展示了上面的例子中的寄存器值，每个界限寄存器记录了一个段的大小。 
![](assets/Pasted%20image%2020230329045743.png)

>补充：段错误
>段错误指的是在支持分段的机器上发生了非法的内存访问。有趣的是，即使在不支持分段的机器上这个术语依然保留。但如果你弄不清楚为什么代码老是出错，就没那么有趣了。

访问非法地址, 未分配给本进程的地址, 去访问就会报段错误.

### 16.2 我们引用哪个段

硬件在地址转换时使用`段寄存器`. 它如何知道段内的偏移量, 以及地址引用了`哪个段`?

一种常见的方式，有时称为`显式(explicit)方式`，就是用虚拟地址的开头几位来标识不同的段, VAX/VMS 系统使用了这种技术.
在我们之前的例子中, 有3个段, 因此需要两位来标识. 如果我们用 14 位虚拟地址的前两位来标识，那么虚拟地址如下所示：
![](assets/Pasted%20image%2020230329051039.png)
如果前两位是 00，硬件就知道这是属于代码段的地址，因此使用代码段的基址和界限来重定位到正确的物理地址。如果前两位是 01，则是堆地址，对应地，使用堆的基址和界限。

下面来看一个 4200 之上的堆虚拟地址，进行进制转换，确保弄清楚这些内容。虚拟地址 4200 的二进制形式如下：
![](assets/Pasted%20image%2020230329052238.png)
01表示是堆段, 剩下12位是段内偏移量,  34K+104 就是物理地址.
注意，偏移量也简化了对段边界的判断。我们只要检查偏移量是否小于界限，大于界限的为非法地址。
因此，如果基址和界限放在数组中（每个段一项），为了获得需要的物理地址，硬件会做下面这样的事：
```c
1 // get top 2 bits of 14-bit VA
2 Segment = (VirtualAddress & SEG_MASK) >> SEG_SHIFT
3 // now get offset
4 Offset = VirtualAddress & OFFSET_MASK
5 if (Offset >= Bounds[Segment])
6     RaiseException(PROTECTION_FAULT)
7 else
8     PhysAddr = Base[Segment] + Offset
9     Register = AccessMemory(PhysAddr)
```
在我们的例子中，可以为上面的常量填上值。具体来说，SEG_MASK 为 0x3000，SEG_SHIFT 为 12，OFFSET_MASK 为 0xFFF。

上面使用两位来区分段，但实际只有 3 个段（代码、堆、栈），因此有一个段的地址空间被浪费。因此有些系统中会将堆和栈当作同一个段，因此只需要一位来做标识.

硬件还有其他方法来决定特定地址在哪个段. 
在`隐式(implicit)方式`中，硬件通过地址产生的方式来确定段。
例如，如果地址由程序计数器产生(即它是指令获取), 那么地址在代码段. 如果基于栈或基址指针, 它一定在栈段. 其他地址则在堆段.

### 16.3 栈怎么办

到目前为止，我们一直没有讲地址空间中的一个重要部分：栈. 
在表 16.1 中，栈被重定位到物理地址 28KB。但有一点关键区别，它反向增长。在物理内存中，它始于 28KB，增长回到 26KB，相应虚拟地址从 16KB 到 14KB。地址转换必须有所不同。

首先，我们需要一点硬件支持. 除了基址和界限外，硬件还需要知道段的增长方向（用一位区分，比如 1 代表自小而大增长，0 反之）.
![](assets/Pasted%20image%2020230329053211.png)
硬件理解段可以反向增长后，这种虚拟地址的地址转换跟之前的不一样了. 举例:

假设要访问虚拟地址 15KB，它应该映射到物理地址 27KB。该虚拟地址的二进制形式是：111100 0000 0000（十六进制 0x3C00）。硬件利用前两位（11）来指定段，但然后我们要处理偏移量 3KB。为了得到正确的反向偏移，我们必须从 3KB 中减去最大的段地址：在这个例子中，段可以是 4KB，因此正确的偏移量是 3KB 减去 4KB，即−1KB。只要用这个反向偏移量（−1KB）加上基址（28KB），就得到了正确的物理地址 27KB。用户可以进行界限检查，确保反向偏移量的绝对值小于段的大小。

### 16.4 支持共享

随着分段机制的不断改进, 系统设计人员很快意识到, 再多一点的硬件支持, 就能实现新的效率提升. 具体来说，要节省内存，有时候可以在地址空间之间`共享(share)`某些内存段. 
代码共享很常见, 今天的系统仍然在使用.

为了支持共享, 需要一些额外的硬件支持, 这就是保护位(protection bit).
基本为每个段增加了几个位, 标识程序是否能够读写该段, 或执行其中的代码. 
通过将`代码段`标记为`只读`, 同样的代码可以被多个进程共享, 而不用担心破坏隔离. 
虽然每个进程都认为自己独占这块内存, 但操作系统秘密地共享了内存, 进程`不能修改`这些内存, 所以假象得以保持.

表 16.3 展示了一个例子，是硬件（和操作系统）记录的额外信息。可以看到，代码段的权限是可读和可执行，因此物理内存中的一个段可以映射到多个虚拟地址空间。
![](assets/Pasted%20image%2020230329054741.png)

有了保护位，前面描述的硬件算法也必须改变。除了检查虚拟地址是否`越界`，硬件还需要检查特定访问是否`允许`。如果用户进程试图写入只读段，或从非执行段执行指令，硬件会触发`异常`，让操作系统来处理出错进程。

### 16.5 细粒度与粗粒度的分段

到目前为止, 我们的例子大多针对只有很少的几个段的系统(即代码、栈、堆).
我们可以认为这种分段是`粗粒度的(coarse-grained)`, 因为它将地址空间分成较大的, 粗粒度的块.
而早期系统, 更灵活, 允许将地址空间划分为大量较小的段, 这被称为`细粒度(fine-grained)分段`.

支持许多段需要进一步的`硬件支持`, 并在`内存中`保存某种`段表(segment table)`.
这种段表通常支持创建非常多的段，因此系统使用段的方式，可以比之前讨论的方式更灵活。
有了操作系统和硬件的支持，编译器可以将代码段和数据段划分为许多不同的部分.
当时的考虑是，通过更细粒度的段，操作系统可以更好地了解哪些段在使用哪些没有，从而可以更高效地利用内存。

### 16.6 操作系统支持

系统运行时, 虚拟地址空间中的不同段被重定位到物理内存中. 
与最初介绍的整个进程地址空间只有一个基址/界限寄存器对的方式相比, 大量节省了物理内存.
具体来说，栈和堆之间没有使用的区域就不需要再分配物理内存，让我们能将更多地址空间放进物理内存。

然而, 分段也带来了一些新的问题. 先介绍必须关注的操作系统新问题. 
第一个是老问题：操作系统在上下文切换时应该做什么？
各个`段寄存器`中的内容必须`保存和恢复`。显然，每个进程都有自己独立的虚拟地址空间，操作系统必须在进程运行前，确保这些寄存器被正确地赋值。

第二个问题更重要，即管理`物理内存的空闲空间`. 
新的地址空间被创建时，操作系统需要在物理内存中为它的段找到空间。
每个进程都有一些段，每个段的大小也可能是不同的。怎么办?

一般会遇到的问题是, 物理内存很快充满了许多空闲空间的小洞, 不连续因而很难分配给新的段, 或扩大已有的段. 这种问题被称为`外部碎片(external fragmentation).` 如图 16.3（左边）所示。

![](assets/Pasted%20image%2020230329064214.png)

在这个例子中, 一个进程需要分配一个 20KB 的段. 当前有 24KB 空闲, 但并不连续(是3 个不连续的块). 因此, 操作系统无法满足这个 20KB 的请求.

该问题的一种解决方案是紧凑（compact）物理内存，重新安排原有的段。
例如，操作系统先终止运行的进程，将它们的数据复制到连续的内存区域中去，改变它们的段寄存器中的值，指向新的物理地址，从而得到了足够大的连续空闲空间。
然而内存紧凑成本很高，因为拷贝段是内存密集型的，一般会占用大量的处理器时间。图 16.3（右边）是紧凑后的物理内存。

一种更简单的做法是利用`空闲列表管理算法`，试图保留大的内存块用于分配。
相关的算法可能有成百上千种，包括传统的最优匹配（best-fit，从空闲链表中找最接近需要分配空间的空闲块返回）、最坏匹配（worst-fit）、首次匹配（first-fit）以及像`伙伴算法`（buddy algorithm）这样更复杂的算法.

然而, 无论算法多么精妙, 都无法完全消除外部碎片, 因此, 好的算法只是试图减小它.
存在这么多不同的算法来尝试减少外部碎片, 正说明没有最好的方案来解决这个问题. 因此只能找到一个合理的方案. 唯一真正的解决办法就是(会在后面看到), 完全避免这个问题, 永远不要分配不同大小的内存块.

### 16.7 小结

从将所有进程地址空间, 都整个地加载到内存, 用基址和界限方法造成大量内存浪费. 剩余地址不够新进程用的. 引出了问题, 怎么支持大地址空间.

从而进出分段的概念, 进程有多个段(代码, 数据, 堆, 栈), 那由原来的一组基址和界限寄存器, 扩展到每个段一对基址, 界限寄存器.  这就可以让不同的段, 加载到不同的物理内存. 从而避免了虚拟地址空间中的未使用部分占用物理内存. 

多个段引出了新问题, 系统怎么知道要访问的是哪个段呢.
显式方式, 用虚拟地址高位的n位来标识不同段, 剩下的数据位, 标识段内的偏移量.
隐式方式, 硬件通过地址产生的方式来确定段. 若地址由PC产生, 那地址是在代码段. 若基于栈或基址指针, 一定在栈段. 其他地址在堆栈.

由于栈比较独特, 增长方向跟别人相反. 引出一个硬件的寄存器数据位, 来区分正反向增长.

要想进一步提升效率, 需要更多的硬件支持. `地址空间共享内存段`, 就可以节省内存. 需要的硬件支持, 就是保护位. 每个段增加几个位, 作为保护位, 标识程序是否能够读写该段,  或执行其中的代码.
`代码段`被标记为`只读`, 同样的代码可以被多个进程共享. 而不用担心破坏隔离. 
物理内存中的代码段就可以映射到多个虚拟地址空间.

上面这种都是粗粒度的分段. 还有细粒度的分段. 实现细粒度分段, 需要进一步的硬件支持, 并在内存中保存段表.

分段后, 操作系统切换上下文的时候, 各个段寄存器要保存, 恢复. 
还有要管理物理内存的空闲空间. 问题在于分段, 会造成外部碎片, 使空闲的内存不连续, 从而无法分配给新进程.

解决方案是紧凑 物理内存, 重新安排原有的段. 这种方法开销很大.
另一种是用空闲列表管理算法. 试图保留大的内存块用于分配. 后面会介绍.
但, 无论算法多么精妙, 都无法完全消除外部碎片, 因此, 好的算法只是试图减小它。

> 分段解决了一些问题，帮助我们实现了更高效的虚拟内存。不只是动态重定位，通过避免地址空间的逻辑段之间的大量潜在的内存浪费，分段能更好地支持稀疏地址空间。它还很快，因为分段要求的算法很容易，很适合硬件完成，地址转换的开销极小。分段还有一个附加的好处：代码共享。如果代码放在独立的段中，这样的段就可能被多个运行的程序共享。

> 但我们已经知道，在内存中分配不同大小的段会导致一些问题，我们希望克服。首先，是我们上面讨论的外部碎片。由于段的大小不同，空闲内存被割裂成各种奇怪的大小，因此满足内存分配请求可能会很难。用户可以尝试采用聪明的算法，或定期紧凑内存，但问题很根本，难以避免。

> 第二个问题也许更重要，分段还是不足以支持更一般化的稀疏地址空间。例如，如果有一个很大但是稀疏的堆，都在一个逻辑段中，整个堆仍然必须完整地加载到内存中。换言之，如果使用地址空间的方式不能很好地匹配底层分段的设计目标，分段就不能很好地工作。因此我们需要找到新的解决方案。

## Ch17 空闲空间管理

前一章提到了, 内存碎片的问题. 暂且将对虚拟内存的讨论放在一边, 来讨论所有内存管理系统的一个基本方面，无论是 malloc 库(管理进程中堆的页)，还是操作系统本身(管理进程的地址空间). 具体来说，我们会讨论空闲空间管理(free-space management)的一些问题。

问题更明确一点. 管理空闲空间当然可以很容易, 我们会在讨论分页概念时看到. 如果需要管理的空间被划分为固定大小的单元, 就很容易. 在这种情况下, 只需要维护这些大小固定的单元的列表, 如果有请求, 就返回列表中的第一项.

如果要管理的空闲空间由`大小不同的单元`构成，管理就变得困难. 这种情况出现在用户级的内存分配库(如 malloc()和 free()), 或者操作系统用分段(segmentation)的方式实现虚拟内存. 
在这两种情况下, 出现了外部碎片(external fragmentation)的问题: 空闲空间被分割成不同大小的小块, 成为碎片, 后续的请求可能失败, 因为没有一块足够大的连续空闲空间, 即使这时总的空闲空间超出了请求的大小. 

关键问题：如何管理空闲空间
要满足变长的分配请求, 应该如何管理空闲空间? 什么策略可以让碎片最小化? 不同方法的时间和空间开销如何?

### 17.1 假设

本章的大多数讨论，将聚焦于`用户级内存分配库`中的分配程序.

`假定`基本的接口就像 malloc()和 free()提供的那样. 具体来说，void * malloc(size tsize)需要一个参数 size, 它是应用程序请求的字节数. 函数返回一个指针(没有具体的类型, 在 C 语言是void 类型), 指向这样大小(或较大一点)的一块空间.
对应的函数void free(void \*ptr)函数接受一个指针，释放对应的内存块。请注意该接口的隐含意义, 在释放空间时, 用户不需告知库这块空间的大小. 因此, 在只传入一个指针的情况下, 库必须能够弄清楚这块内存的大小. 

该库管理的空间由于历史原因被称为堆, 在堆上`管理空闲空间的数据结构`通常称为`空闲列表(free list)`. 该结构包含了管理内存区域中`所有空闲块的引用`. 当然, 该数据结构不一定真的是列表, 而只是`某种可以追踪空闲空间的数据结构`. 

进一步`假设`, 我们主要关心的是外部碎片(external fragmentation), 分配程序也可能有内部碎片(internal fragmentation)的问题.
如果`分配程序给出的内存块超出请求的大小`, 在这种块中超出请求的空间(因此而未使用)就被认为是`内部碎片`(因为浪费发生在已分配单元的内部, 这是另一种形式的空间浪费.)

我们还`假设`，内存一旦被分配给客户，就不可以被重定位到其他位置。
例如，一个程序调用 malloc()，并获得一个指向堆中一块空间的指针，这块区域就“属于”这个程序了，库不再能够移动，直到程序调用相应的 free()函数将它归还。
因此，不可能进行紧凑（compaction）空闲空间的操作，从而减少碎片. 但是，操作系统层在实现分段（segmentation）时，却可以通过紧凑来减少碎片.

最后我们`假设`，分配程序所管理的是`连续的一块字节区域`。 在一些情况下，分配程序可以要求这块区域增长。
例如，一个用户级的内存分配库在空间快用完时，可以向内核申请增加堆空间（通过 sbrk 这样的系统调用），但是，简单起见，我们`假设`这块区域在`整个生命周期内大小固定`。

### 17.2 底层机制

在深入策略细节之前，我们先来了解大多数`分配程序采用的通用机制`.
首先，探讨空间分割与合并的基本知识。
其次，看看如何快速并相对轻松地追踪已分配的空间。
最后，讨论如何利用空闲区域的内部空间维护一个简单的列表，来追踪空闲和已分配的空间。

#### 分割与合并

空闲列表包含一组元素，记录了堆中的哪些空间还没有分配。假设有下面的 30 字节的堆：
![](assets/Pasted%20image%2020230329184604.png)
这个堆对应的空闲列表会有两个元素，一个描述第一个 10 字节的空闲区域（字节 0～9），
一个描述另一个空闲区域（字节 20～29）：
![](assets/Pasted%20image%2020230329184642.png)
可以看出，任何大于10 字节的分配请求都会失败（返回 NULL）, 没有足够连续空间了.
如果申请小于 10 字节空间，会发生什么？

假设我们只申请一个字节的内存. 这种情况下, 分配程序会执行所谓的`分割(splitting)动作`: 
它找到一块可以满足请求的空闲空间，将其分割，第一块返回给用户，第二块留在空闲列表中.
在我们的例子中，假设这时遇到申请一个字节的请求，分配程序选择使用第二块空闲空间，对 malloc()的调用会返回 20（1 字节分配区域的地址），空闲列表会变成这样：
![](assets/Pasted%20image%2020230329185040.png)

除了第二个空闲区域的起始位置由20变成21, 长度由 10 变为 9 了, 其他没什么变化.
如果请求的空间大小小于某块空闲块，分配程序通常会进行`分割`。

许多分配程序中因此也有一种机制, 名为`合并(coalescing)`. 
还是前面的例子, 30个字节, 只有中间10个字节是used.

对于这个(小)堆, 如果应用程序调用free(10), `归还堆中间的空间`, 会发生什么?如果只是简单地将这块空闲空间加入空闲列表，不多想想，可能得到如下的结果：
![](assets/Pasted%20image%2020230329191929.png)
问题出现了：尽管整个堆现在完全空闲，但它似乎被分割成了 3 个 10 字节的区域。这时，如果用户请求 20 字节的空间，简单遍历空闲列表会找不到这样的空闲块，因此返回失败。

为了避免这个问题，分配程序会在`释放一块内存时合并可用空间`。
想法很简单：在归还一块空闲内存时，仔细查看`要归还的内存块的地址`以及`邻它的空闲空间块`。如果新归还的空间与一个原有空闲块相邻(或两个, 就像这个例子), 就将它们合并为一个较大的空闲块。通过合并，最后空闲列表应该像这样：
![](assets/Pasted%20image%2020230329192304.png)

实际上，这是堆的空闲列表最初的样子，在所有分配之前。通过合并，分配程序可以更好地确保大块的空闲空间能提供给应用程序。

#### 追踪已分配空间的大小

free(void \*ptr)接口没有块大小的参数, 因此它是假定，对于给定的指针，内存分配库可以很快`确定要释放空间的大小`, 从而将它放回空闲列表。

要完成这个任务，大多数分配程序都`会在头块(header)中保存一点额外的信息`，它在内存中，通常就`在返回的内存块`之前。

![](assets/Pasted%20image%2020230329192610.png)
看上面两个图, 设想用户调用了 malloc()并将结果保存在ptr 中：ptr = malloc(20). 实际上占用的不是20个字节, 而是20个字节加上头部信息. 是20多个字节. ptr保存可用堆内存的起始地址.
头块中, 保存了分配的size, 也可能包含一些额外的指针来加速空间释放，包含一个magic来提供完整性检查，以及其他信息。
假设一个简单的头块包含了分配空间的大小和一个幻数：
```c
typedef struct header_t {
    int size;
    int magic;
} header_t;
```
用户调用 free(ptr)时，库会通过简单的指针运算得到头块的位置：
```c
void free(void *ptr) {
	header_t *hptr = (void *)ptr - sizeof(header_t);
}
```
获得头块的指针后，库可以很容易地确定幻数是否符合预期的值, 作为正常性检查
`(assert(hptr->magic == 1234567))`, 并简单计算要释放的空间大小(即头块的大小加区域长度).
注意一个小但重要的细节：实际释放的是`头块大小`加上`分配给用户的空间的大小`.
因此，如果用户请求 N 字节的内存，库不是寻找大小为 N 的空闲块，而是寻找N 加上头块大小的空闲块。

#### 嵌入空闲列表

到目前为止, 我们这个简单的空闲列表还只是一个概念上的存在, 它就是一个列表, 描述了堆中的空闲内存块. 但如何在`空闲内存自己内部`建立这样一个列表呢? 

在更典型的列表中，如果要分配新节点，你会调用 malloc()来获取该节点所需的空间。
遗憾的是，在内存分配库内，你无法这么干！你需要在空闲空间本身中建立空闲空间列表。

假设我们需要管理一个 4096 字节的内存块（即堆是 4KB）。为了将它作为一个空闲空间列表来管理，首先要初始化这个列表。开始，列表中只有一个条目，记录了大小为4096的空间(减去头块的大小)。下面是该列表中一个节点描述：
```c
typedef struct node_t {
	int size;
	struct node_t *next;
} node_t;
```

现在来看一些代码，它们初始化堆，并将空闲列表的第一个元素放在该空间中。
假设堆构建在某块空闲空间上，这块空间通过系统调用 mmap()获得。这不是构建这种堆的唯一选择，但在这个例子中很合适。下面是代码：

```c
// mmap() returns a pointer to a chunk of free space
node_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_ANON|MAP_PRIVATE, -1, 0);
head->size = 4096 - sizeof(node_t);
head->next = NULL;
```
执行这段代码之后，列表的状态是它只有一个条目，记录大小为 4088。
这是一个小堆，但对我们是一个很好的例子。
head 指针指向这块区域的起始地址, 假设是16K(尽管任何虚拟地址都可以).
如图 17.3 所示:
![](assets/Pasted%20image%2020230329205721.png)

现在假设有一个100字节的内存请求, 为了满足这个请求，库首先要找到一个足够大小的块。因为只有一个 4088 字节的块，所以选中这个块。
然后, 这个块被分割(split)为两块: 一块足够满足请求(以及头块), 一块是剩余的空闲块.
假设记录头块为8个字节(一个整数记录大小, 一个整数记录magic)，堆中的空间如图 17.4 所示。
![](assets/Pasted%20image%2020230329210432.png)
对于 100 字节的请求，库从原有的一个空闲块中分配了 108 字节，返回指向它的一个指针(在上图中用 ptr 表示), 并在其之前连续的 8 字节中记录头块信息, 供未来的free()函数使用. 同时将列表中的空闲节点缩小为 3980 字节.

再申请两个100字节, 再来看该堆，其中有 3 个已分配区域，每个 100（加上头块是 108）。这个堆如图 17.5所示.
![](assets/Pasted%20image%2020230329211557.png)
堆的前 324 字节已经分配,  只有一个节点（由 head 指向），但在 3 次分割后，现在大小只有 3764 字节. 如果用户程序通过 free()归还一些内存，会发生什么？

在这个例子中，应用程序调用 free(16500)，归还了中间的一块已分配空间(内存块的起始地址 16K加上前一块的 108，和这一块的头块的 8 字节.) 这个值在前图中用 sptr 指向.

库马上弄清楚了这块要释放空间的大小，并将空闲块加回空闲列表。假设我们将它插入到空闲列表的头位置，该空间如图 17.6 所示。
![](assets/Pasted%20image%2020230329212038.png)

现在的空闲列表包括一个小空闲块（100 字节，由列表的头指向）和一个大空闲块（3764字节）。
列表终于有不止一个元素了，空闲空间被分割成了两段.

最后一个例子：现在假设剩余的两块已分配的空间也被释放。没有合并，空闲列表将非常破碎，如图 17.7 所示。
![](assets/Pasted%20image%2020230329212228.png)
虽然整个内存空间是空闲的，但却被分成了小段，因此形成了碎片化的内存空间。解决方案很简单：遍历列表，合并（merge）相邻块。完成之后，堆又成了一个整体。

#### 让堆增长

讨论最后一个很多内存分配库中都有的机制.
具体来说, 如果堆中的内存空间耗尽, 应该怎么办? 最简单的方式就是返回失败. 在某些情况下这是唯一的选择，因此返回 NULL 也是一种体面的方式.

大多数传统的分配程序会从很小的堆开始, 当空间耗尽时, 再向操作系统申请更大的空间. 通常, 这意味着它们进行了某种系统调用(例如, 大多数UNIX系统中的 `sbrk`), 让堆增长. 操作系统在执行 sbrk 系统调用时, 会找到空闲的物理内存页, 将它们映射到请求进程的地址空间中去, 并返回新的堆的末尾地址. 这时, 就有了更大的堆, 请求就可以成功满足. 

内存管理底层机制小结:

>如果申请比空间块小的内存, 就执行分割; 把已分配的空间释放时, 分配程序会进行检查和合并空闲内存的操作. 
>free() 只需要传入指针, 是因为可以通过这个指针地址, 找到这块内存的header信息.
>嵌入空闲列表, 这个数据结构可以帮助管理空闲内存, 但会占用一点空间. 所以4096的一块内存, 实际可用, 会少一点.
>内存耗尽就返回NULL, 没问题. 大多数传统分配程序, 会从小的堆内存空间开始分配, 小内存的单位耗尽, 就向OS申请大单位的空间. 比如类UNIX的sbrk系统调用, 可用让堆增长.(会找到空闲的物理内存页，将它们映射到请求进程的地址空间中去，并返回新的堆的末尾地址).

### 17.3 基本策略

有了上面的底层机制, 看看管理空闲空间的一些基本策略.(算法思想)
这些方法大多基于简单的策略.

理想的分配程序可以同时保证快速和碎片最小化. 
事实上，由于分配及释放的请求序列是任意的(毕竟, 它们由用户程序决定), 任何特定的策略在某种不匹配的输入下都会变得非常差. 所以不说“最好”的策略, 而是介绍一些基本的选择, 并讨论它们的优缺点. 

#### 最优匹配

最优匹配(best fit)策略非常简单: 首先遍历整个空闲列表，找到和请求大小一样或更大的空闲块，然后返回这组候选者中最小的一块。这就是所谓的最优匹配(也可以称为最小匹配). 只需要遍历一次空闲列表, 就足以找到正确的块并返回.

最优匹配背后的想法很简单：选择最接它用户请求大小的块，从而尽量避免空间浪费。
这种方法有系统开销. 简单的实现在遍历查找正确的空闲块时, 要付出较高的性能代价.

#### 最差匹配

最差匹配(worst fit)方法与最优匹配相反, 它尝试找最大的空闲块, 分割并满足用户需求后, 将剩余的块(很大)加入空闲列表. 最差匹配尝试在空闲列表中保留较大的块, 而不是向最优匹配那样可能剩下很多难以利用的小块. 
最差匹配同样需要遍历整个空闲列表. 而且, 大多数研究表明它的表现非常差, 会导致过量的碎片, 同时还有很高的开销. 

#### 首次匹配

首次匹配(first fit)策略就是找到第一个足够大的块，将请求的空间返回给用户。同样，剩余的空闲空间留给后续请求。
首次匹配有速度优势(不必全部遍历一遍), 但有时会让空闲列表开头的部分有很多小块。所以, 分配程序如何管理空闲列表的顺序就变得很重要.
一种方式是基于地址排序（address-based ordering）。通过保持空闲块按内存地址有序，合并操作会很容易，从而减少了内存碎片。

#### 下次匹配

不同于首次匹配每次都从列表的开头查找, 下次匹配(next fit)算法多维护一个指针, 指向上一次查找结束的位置. 
其想法是将对空闲空间的查找操作扩散到整个列表中去, 避免对列表开头频繁的分割. 这种策略的性能与首次匹配很接近, 同样避免了遍历查找. 

#### 例子

下面是上述策略的一些例子。设想一个空闲列表包含 3 个元素，长度依次为 10、30、20.
![](assets/Pasted%20image%2020230329224807.png)

假设有一个 15 字节的内存请求。最优匹配会遍历整个空闲列表，发现 20 字节是最优匹配，因为它是满足请求的最小空闲块。结果空闲列表变为：
![](assets/Pasted%20image%2020230329224825.png)
本例中发生的情况，在最优匹配中常常发生，现在留下了一个小空闲块。

最差匹配类似，但会选择最大的空闲块进行分割，在本例中是 30。结果空闲列表变为：
![](assets/Pasted%20image%2020230329224851.png)

在这个例子中，首次匹配会和最差匹配一样，也发现满足请求的第一个空闲块。
不同的是查找开销，最优匹配和最差匹配都需要遍历整个列表，而首次匹配只找到第一个满足需求的块即可，因此减少了查找开销。

### 17.4 其他方式

除了上述基本策略外, 人们还提出了许多技术和算法, 来改进内存分配. 这里我们列出一些来供你考虑(就是让你多一些思考, 不只局限于最优匹配). 

#### 分离空闲列表

#### 伙伴系统

#### 其他想法