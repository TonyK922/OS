# Ch26 并发:  介绍

操作系统本身是第一个并发程序.
目前为止, 我们已经看到了操作系统提供的基本抽象的发展.
看到了如何将一个物理CPU变成多个虚拟 CPU(virtual CPU). 从而支持多个程序同时运行的假象; 还看到了如何为每个进程创建巨大的. 私有的虚拟内存(virtual memory)的假象,  这种地址空间(address space)的抽象让每个程序好像拥有自己的内存,  而实际上操作系统秘密地让多个地址空间复用物理内存(或者磁盘).

本章将介绍为`单个运行进程`提供的新抽象:  线程(thread).
与经典观点的一个程序单点执行(一个程序计数器, 用来存放要执行的指令)不同,  多线程(multi-threaded)程序会有多个执行点(多个程序计数器,  每个都用于取指令和执行). 换一个角度来看,  每个线程类似于独立的进程,  只有一点区别:  它们共享同一个地址空间,  从而能够访问相同的数据.

因此一个单线程的状态跟进程的状态非常接近. 线程有一个程序计数器(PC), 记录程序
从哪里获取指令. 每个线程有自己私人的一组用于计算的寄存器. 因此 如果在一个单核处理器上运行两个线程,  那从一个线程(T1)切换到另一个线程(T2),  就会发生上下文切换.
线程间的上下文切换,  跟进程间的上下文切换是非常相似的,  因为T1的寄存器状态必须保存下来,  T2在运行之前,  它的寄存器状态先被恢复.
对进程而言,  我们把状态保存到进程控制块(PCB)中. 现在我们需要一个或多个线程控制块(TCBs)来保存一个进程中每个线程的状态(现场).
然而跟进程相比,  我们在进行线程间上下文切换时,  有个主要区别,  就是线程间切换的虚拟地址空间不变(换言之,  不必切换正在使用的页表.).

另一个进程与线程间的主要区别在于栈. 
在简单的传统进程地址空间模型(我们现在可以称之为单线程(single-threaded)的进程), 只有一个栈,  通常位于地址空间的底部.

![](assets/Pasted%20image%2020230404164519.png)

然而,  在一个多线程的进程中,  每个线程都独立运行,  当然可以调用各种例程来完成正在执
行的任何工作. 多线程就不是地址空间只有一个栈了,  而是每个线程都有自己的栈空间(当然还是在进程空间内).
假设我们有个多线程的进程,  其中有2个线程. 地址空间看起来就跟单线程不一样了.

上图,  可以看到多线程空间分布,  有两个栈在进程的地址空间. 因此,  任何在栈上的变量,  参数,  返回值和其他放在栈上的东西,  都将被放置在称为本地线程的存储空间,  也就是线程相关的栈.

以前, 堆和栈可以互不影响地增长, 直到空间耗尽. 多个栈就没有这么简单了. 所幸, 通常栈不会很大(除了大量使用递归的程序).

以上介绍了,  进程跟线程的区别. 进程是OS为任务分配资源的基本单位,  而线程是CPU调度的基本单位. 线程不能独立于进程而存在,  OS不会为线程单独分配资源,  线程寄生于进程内.

## 26.0 为啥要用线程

讨论线程的细节之前,  你可能在写多线程程序的时候有些疑问. 先解决个简单问题,  为什么要用线程.

主要是两个原因: 
第一个原因是,  并行. 比如你有一个很大的数组要处理,  跟另一个很大的数组相加,  或者是这个数组里的元素进行自加1. 如果是在单处理器上运行,  那就是普通的执行下去就行了. 但如果是在多处理器的机器上运行,  那就有加速运算的潜力了. 因为让每个处理器处理一部分工作,  多个处理器肯定比一个处理器工作快. 相当于一个人的活几个人同时干. 这就是并行. 
在现代硬件上,  每个CPU一个线程执行程序,  是很正常且典型地让程序运行更快的方式.

第二个原因,  是因为I/O操作很慢,  用线程可以避免阻塞程序进程.
幻想一下,  你在写一个要执行不同种类的I/O操作的程序,  为了完成一个显式硬盘I/O或者甚至完成(隐式)页错误处理,  需要等着去发送或接收信息. 你的程序可能希望去做其他的工作,  包括利用CPU去完成计算,  或者发另一个I/O请求,  而不是干等着. 
使用多线程就可以避免被停顿. 因为当一个线程等待的时候(就是因为等待I/O操作而被阻塞),  CPU调度算法就可以切到其他就绪的线程,  去做一些有用的事.
在单个程序内,  线程使I/O操作与其他活动重叠,  就像多程序处理跨程序一样;  因此,  许多现代基于服务器的应用程序(Web服务器、数据库管理系统等)在其实现中使用线程. 

当然,  上面提到的另一种情况,  你也可以使用多进程,  而不是多线程. 然而,  多线程共享一个地址空间,  所以多线程之间共享数据就很容易,  因此构建这类程序的时候,  多线程是自然选择.
多进程对逻辑上独立的任务是更可靠的选择,  他们共享的内存数据结构很少.

## 26.1 实例: 线程创建

假设我们想运行一个程序, 它创建两个线程, 每个线程都做了一些独立的工作, 在这例子中, 打印“A”或“B”. 代码如图 26.2 所示.
```c
1 #include <stdio.h>
2 #include <assert.h>
3 #include <pthread.h>
4
5 void *mythread(void *arg) {
6     printf("%s\n",  (char *) arg); 
7     return NULL; 
8 }
9
10 int
11 main(int argc,  char *argv[]) {
12     pthread_t p1,  p2; 
13     int rc; 
14     printf("main:  begin\n"); 
15     rc = pthread_create(&p1,  NULL,  mythread,  "A");  assert(rc == 0); 
16     rc = pthread_create(&p2,  NULL,  mythread,  "B");  assert(rc == 0); 
17     // join waits for the threads to finish
18     rc = pthread_join(p1,  NULL);  assert(rc == 0); 
19     rc = pthread_join(p2,  NULL);  assert(rc == 0); 
20     printf("main:  end\n"); 
21     return 0; 
22 }
```
图 26.2 简单线程创建代码

让我们来看看这个小程序的可能执行顺序. 在表 26.1 中, 向下方向表示时间增加, 每个列显示不同的线程(主线程、线程 1 或线程 2)何时运行. 

![](assets/Pasted%20image%2020230404184026.png)

但请注意, 这种排序不是唯一可能的顺序. 实际上, 给定一系列指令, 有很多可能的顺序, 这取决于调度程序决定在给定时刻运行哪个线程. 例如, 创建一个线程后, 它可能会立即运行, 这将导致表 26.2 中的执行顺序. 

![](assets/Pasted%20image%2020230404184115.png)

我们甚至可以在“A”之前看到“B”, 即使先前创建了线程 1, 如果调度程序决定先运行线程 2, 没有理由认为先创建的线程先运行. 表 26.3 展示了最终的执行顺序, 线程 2 在线程 1 之前先展示它的结果. 

![](assets/Pasted%20image%2020230404184600.png)

如你所见, 线程创建有点像进行函数调用. 然而, 并不是首先执行函数然后返回给调用者, 而是为被调用的例程创建一个新的执行线程, 它可以独立于调用者运行, 可能在从创建者返回之前运行, 但也许会晚得多. 

从这个例子中也可以看到, 线程让生活变得复杂: 已经很难说出什么时候会运行了！
没有并发, 计算机也很难理解. 有了并发,  程序运行更加复杂了.

## 26.2 为什么更糟糕: 共享数据

上面演示的简单线程示例非常有用, 它展示了线程如何创建, 根据调度程序的决定, 它们如何以不同顺序运行. 
但是, 它没有展示线程在访问共享数据时如何相互作用. 
设想一个简单的例子, 其中两个线程希望更新全局共享变量. 我们要研究的代码如图 26.3
所示. 
```c
1 #include <stdio.h>
2 #include <pthread.h>
3 #include "mythreads.h"
4
5 static volatile int counter = 0; 
6
7 //
8 // mythread()
9 //
10 // Simply adds 1 to counter repeatedly,  in a loop
11 // No,  this is not how you would add 10, 000, 000 to
12 // a counter,  but it shows the problem nicely.
13 //
14 void *
15 mythread(void *arg)
16 {
17     printf("%s:  begin\n",  (char *) arg); 
18     int i; 
19     for (i = 0;  i < 1e7;  i++) {
20         counter = counter + 1; 
21     }
22     printf("%s:  done\n",  (char *) arg); 
23     return NULL; 
24 }
25
26 //
27 // main()
28 //
29 // Just launches two threads (pthread_create)
30 // and then waits for them (pthread_join)
31 //
32 int
33 main(int argc,  char *argv[])
34 {
35     pthread_t p1,  p2; 
36     printf("main:  begin (counter = %d)\n",  counter); 
37     Pthread_create(&p1,  NULL,  mythread,  "A"); 
38     Pthread_create(&p2,  NULL,  mythread,  "B"); 
39
40 // join waits for the threads to finish
41     Pthread_join(p1,  NULL); 
42     Pthread_join(p2,  NULL); 
43     printf("main:  done with both (counter = %d)\n",  counter); 
44     return 0; 
45 }
```
图 26.3 共享数据

我们封装了线程创建和合并例程,  以便在失败时退出. Pthread_create()只需调用pthread_create(), 并确保返回码为 0. 如果不是, Pthread_create()就打印一条消息并退出. 

其次, 我们没有用两个独立的函数作为工作线程, 只使用了一段代码, 并向线程传入一个参数(在本例中是一个字符串), 这样就可以让每个线程在打印它的消息之前, 打印不同的字母. 

最后, 最重要的是, 我们现在可以看看每个工作线程正在尝试做什么: 向共享变量计数器添加一个数字, 并在循环中执行 1000 万(10^7)次. 因此, 预期的最终结果是: 2000 0000. 

然而事实是,  每次运行不但会产生错误, 而且得到不同的结果！有一个大问题: 为什么会发生这种情况? 

![](assets/Pasted%20image%2020230404203154.png)

![](assets/Pasted%20image%2020230404203203.png)


>反汇编程序(disassembler),  如objdump(Linux)来查看汇编代码.
>objdump 程序只是应该学习使用的许多工具之一. 像 gdb 这样的调试器, 像 valgrind或 purify 这样的内存分析器, 当然编译器本身也应该花时间去了解更多信息. 工具用得越好, 就可以建立更好的系统. 

## 26.3 核心问题: 不可控的调度

为了理解为什么会发生这种情况,  我们必须了解编译器为更新计数器生成的代码序列.
在这个例子中, 我们只是想给 counter 加上一个数字(1). 因此, 做这件事的代码序列可能
看起来像这样(在 x86 中): 
```asm
mov 0x8049a1c,  %eax
add $0x1,  %eax
mov %eax,  0x8049a1c
```
这个例子假定, 变量 counter 位于地址 0x8049a1c.
在这 3 条指令中, 先用 x86 的 mov指令, 从内存地址处取出值, 放入 eax. 然后, 给 eax 寄存器的值加 1(0x1). 最后, eax的值被存回内存中相同的地址. 

设想我们的两个线程之一(线程 1)进入这个代码区域,  并且因此将要增加一个计数器. 它将 counter 的值(假设它这时是 50)加载到它的寄存器 eax 中. 因此,  线程1的eax = 50. 然后它向寄存器加 1, 因此 eax = 51. 现在, 一件不幸的事情发生了: 时钟中断发生. 因此, 操作系统将当前正在运行的线程(它的程序计数器、寄存器, 包括 eax 等)的状态保存到线程的TCB. 

更糟的事发生了: 线程 2 被选中运行, 并进入同一段代码. 它也执行了第一条指令, 获取计数器的值并将其放入其 eax 中(运行时每个线程都有自己的专用寄存器. 上下文切换代码将寄存器虚拟化(virtualized),  保存并恢复它们的值). 此时 counter 的值仍为 50, 因此线程 2 的 eax = 50. 假设线程 2 执行接下来的两条指令, 将 eax 递增 1(因此 eax = 51), 然后将 eax 的内容保存到 counter(地址 0x8049a1c)中. 因此, 全局变量 counter 现在的值是 51. 

最后, 又发生一次上下文切换, 线程 1 恢复运行. 还记得它已经执行过 mov 和 add 指
令, 现在准备执行最后一条 mov 指令. 回忆一下, eax=51. 因此, 最后的 mov 指令执行, 
将值保存到内存, counter 再次被设置为 51.

总结一下,  就是本来counter应该被两个线程各加一次,  最终得到52. 但事实是,  线程1的寄存器中的结果还没写回内存,  就被时钟中断打断,  把CPU资源给了线程2.

为了更好地理解问题,  让我们追踪一下详细的执行. 假设在这个例子中,  上面的代码被加载到内存中的地址 100 上,  就像下面的序列一样(熟悉类似RISC指令集的人请注意:  x86 具有可变长度指令. 这个mov指令占用5个字节的内存,  add 只占用 3 个字节): 
```c
100 mov 0x8049a1c,  %eax
105 add $0x1,  %eax
108 mov %eax,  0x8049a1c
```

有了这些假设, 发生的情况如表 26.4 所示. 假设 counter 从 50 开始, 并追踪这个例子, 确保你明白发生了什么. 

![](assets/Pasted%20image%2020230404222853.png)

这里展示的情况称为`竞态条件(race condition)`: 结果`取决于代码的时间执行`. 
由于运气不好(即在执行过程中发生的上下文切换), 我们得到了错误的结果. 事实上, 可能每次
都会得到不同的结果. 因此, 我们称这个结果是不确定的(indeterminate), 而不是确定的
(deterministic)计算(我们习惯于从计算机中得到).
不确定的计算不知道输出的是什么, 它在不同运行中确实可能是不同的. 

由于`执行这段代码的多个线程`可能导致`竞争状态`, 因此我们将此段代码称为`临界区`(critical section). 
`临界区`是`访问共享变量`(或更一般地说, 共享资源)的`代码片段`, `一定不能由多个线程同时执行`. 
(临界区绝对不能够并行修改).

我们真正想要的代码就是所谓的`互斥(mutual exclusion)`. 这个属性保证了如果一个线程在临界区内执行, 其他线程将被阻止进入临界区. 

(事实上, 所有这些术语都是由 Edsger Dijkstra 创造的, 他是该领域的先驱, 并且因为这
项工作和其他工作而获得了图灵奖. )

## 26.4 原子性愿望

解决这个问题的一种途径是拥有更强大的指令, 单步就能完成要做的事, 从而消除不合时宜的中断的可能性. 比如, 如果有这样一条超级指令怎么样? 
`memory-add 0x8049a1c,  $0x1`
假设这条指令将一个值添加到内存位置, 并且硬件保证它以`原子`方式(atomically)执行. 
当指令执行时,  它会像期望那样执行更新变量在内存的值. 它不能在指令中间被中断打断, 因为这正是我们从硬件获得的保证: 发生中断时, 指令`要么还没有运行`,  要么就`运行完成`,  没有中间状态. 

在这里, `原子`方式的意思是“作为一个整体单元”,  有时我们说“1或0”. 我们希望以原子方式执行 3 个指令的序列: 
```
mov 0x8049a1c,  %eax
add $0x1,  %eax
mov %eax,  0x8049a1c
```
如果有一条指令来做到上面的活,  我们可以发出这条指令然后完事. 
但在一般情况下, 不会有这样的指令. 设想我们要构建一个并发的 B 树, 并希望更新它. 我们真的希望硬件支持“B 树的原子性更新”指令吗? 可能不会, 至少理智的指令集不会. 

因此, 我们要做的是要求硬件提供一些有用的指令, 可以在这些指令上构建一个通用的集合, 即所谓的`同步原语`(synchronization primitive).
通过使用这些硬件同步原语, 加上操作系统的一些帮助, 我们将能够构建多线程代码, 以`同步和受控`的方式`访问临界区`, 从而`可靠地产生正确的结果`—— 尽管有并发执行的挑战. 

补充: 关键并发术语
临界区、竞态条件、不确定性、互斥执行

临界区(critical section)是访问共享资源的一段代码, 资源通常是一个变量或数据结构. 
竞态条件(race condition)出现在多个执行线程大致同时进入临界区时, 它们都试图更新共享的数据结构, 导致了令人惊讶的(也许是不希望的)结果. 
不确定性(indeterminate)程序由一个或多个竞态条件组成, 程序的输出因运行而异, 具体取决于哪些线程在何时运行. 这导致结果不是确定的(deterministic), 而我们通常期望计算机系统给出确定的结果. 
为了避免这些问题, 线程应该使用某种互斥(mutual exclusion)原语. 这样做可以保证只有一个线程进入临界区, 从而避免出现竞态, 并产生确定的程序输出. 

这是一个精彩而困难的问题.

关键问题: 如何实现同步
为了构建有用的同步原语, 需要从硬件中获得哪些支持? 需要从操作系统中获得什么支持? 如何正确有效地构建这些原语? 程序如何使用它们来获得期望的结果? 

## 26.5 还有一个问题:  等待另一个线程

本章提出了并发问题, 就好像线程之间只有一种交互, 即访问共享变量, 因此需要为临界区支持原子性. 
事实上, 还有另一种常见的交互, 即一个线程在继续之前必须等待另一个线程完成某些操作. 
例如, 当进程执行磁盘 I/O 并进入睡眠状态时, 会产生这种交互. 当 I/O 完成时, 该进程需要从睡眠中唤醒, 以便继续进行. 

在接下来的章节中, 我们不仅要研究如何构建对`同步原语的支持`来支持`原子性`, 还要研究支持在多线程程序中常见的`睡眠/唤醒交互的机制`. 

## 26.6 小结: 为什么操作系统课要研究并发

为什么我们要在 OS 类中研究并发?  
因为操作系统就是第一个并发程序. 很多的技术被发明出来首先就是用在操作系统中的.
后来,  应用层程序员也必须考虑多线程的进程这些事.

例如,  设想有两个进程正在运行. 假设它们都调动write()写入文件,  且都希望把数据追加到文件中.(把数据添加到文件末尾). 为此,  两个进程都必须分配一个新块,  记录在该块所在文件的inode中,  并更改文件的大小以反映新的,  增加的大小. 因为中断可能随时发生,  所以更新这些共享结构的代码是临界区.
因此, 从引入中断的一开始, OS 设计人员就不得不担心操作系统如何更新内部结构. 不合时宜的中断会导致上述所有问题. 毫不奇怪, 页表、进程列表、文件系统结构以及几乎每个内核数据结构都必须小心地访问, 并使用正确的同步原语才能正常工作. 

>提示: 使用原子操作

原子操作是构建计算机系统的最强大的基础技术之一, 从计算机体系结构到并行代码,  文件系统,  数据库管理系统,  甚至分布式系统.

将一系列动作原子化(atomic)背后的想法可以简单用一个短语表达:  “全部或没有”. 看上去, 要么你希望组合在一起的所有活动都发生了,  要么它们都没有发生. 不会看到中间状态.
有时, 将许多行为组合为单个原子动作称为事务(transaction). 这是一个在数据库和事务处理世界中非常详细地发展的概念.

探讨并发的主题中,  我们将使用同步原语,  将指令的短序列变成原子性的执行块.
但是我们会看到,  原子性的想法远不止这些. 例如,  文件系统使用诸如日志记录或写入时复制等技术来自动转换其磁盘状态,  这对于在系统故障时正确运行至关重要.

# Ch27 插叙:  线程API

本章介绍了主要的线程 API. 后续章节也会进一步介绍如何使用 API. 
关键问题: 如何创建和控制线程? 
操作系统应该提供哪些创建和控制线程的接口? 这些接口如何设计得易用和实用? 

## 27.1 线程创建

编写多线程程序的第一步就是创建新线程, 因此必须存在某种线程创建接口. 在 POSIX中, 很简单: 

```c
#include <pthread.h>
int
pthread_create( pthread_t *            thread, 
                const pthread_attr_t * attr, 
                void * (*start_routine)(void*), 
                void * arg); 
```

该函数有 4 个参数: thread、attr、start_routine 和 arg. 
第一个参数 thread 是指向 pthread_t 结构类型的指针,   我们将利用这个结构与该线程交互, 因此需要将它传入pthread_create(),  以便将它初始化.

第二个参数 attr 用于指定该线程可能具有的任何属性. 比如:  设置栈大小,  或关于该线程调度优先级的信息. 一个属性通过单独调用 pthread_attr_init()来初始化. 详细信息, 请参阅手册. 但是, 在大多数情况下, 默认值就行. 在这个例子中, 我们只需传入 NULL. 

第三个参数最复杂, 但它实际上只是问: 这个线程应该在哪个函数中运行? 这个参数是函数指针. 存放的是函数的入口地址. 返回值是`void *`类型. 函数参数是`void *`类型.

第四个参数 arg 就是要传递给线程开始执行的函数的参数. 第三个参数是函数指针,  这第四个参数,  就是函数指针的参数.

下面来看图 27.1 中的例子. 这里我们只是创建了一个线程, 传入两个参数, 它们被打包成一个我们自己定义的类型(myarg_t). 该线程一旦创建, 可以简单地将其参数转换为它所期望的类型, 从而根据需要将参数解包. 

```c
#include <assert.h>
#include <stdio.h>
#include <pthread.h>

typedef struct {
    int a; 
    int b; 
} myarg_t; 

void *mythread(void *arg) {
    myarg_t *args = (myarg_t *) arg; 
    printf("%d %d\n",  args->a,  args->b); 
    return NULL; 
}

int main(int argc,  char *argv[]) {
    pthread_t p; 
    myarg_t args = { 10,  20 }; 

    int rc = pthread_create(&p,  NULL,  mythread,  &args); 
    assert(rc == 0); 
    (void) pthread_join(p,  NULL); 
    printf("done\n"); 
    return 0; 
}
```
图 27.1 创建线程

一旦你创建了一个线程, 你确实拥有了另一个活着的执行实体, 它有自己的调用栈, 与程序中所有当前存在的线程在相同的地址空间内运行. 好玩的事开始了！

## 27.2 线程完成

如果你想等待线程完成,  你需要做一些特别的事情来等待完成. 具体来说, 你必须调用函数 pthread_join(). 

该函数有两个参数. 第一个是 pthread_t 类型, 用于指定要等待的线程. 这个变量是由线程创建函数初始化的(当你将一个指针作为参数传递给 pthread_create()时). 如果你保留了它, 就可以用它来等待该线程终止.

第二个参数是一个指针,  指向你希望得到的返回值. 因为函数可以返回任何东西, 所以它被定义为返回一个指向 void 的指针. 因为 pthread_join()函数改变了传入参数的值, 所以你需要传入一个指向该值的指针, 而不只是该值本身. 

我们来看另一个例子(见图 27.2). 

```c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include "common_threads.h"

typedef struct {
    int a; 
    int b; 
} myarg_t; 

typedef struct {
    int x; 
    int y; 
} myret_t; 

void *mythread(void *arg) {
    myarg_t *args = (myarg_t *) arg; 
    printf("args %d %d\n",  args->a,  args->b); 
    myret_t *rvals = malloc(sizeof(myret_t)); 
    assert(rvals != NULL); 
    rvals->x = 1; 
    rvals->y = 2; 
    return (void *) rvals; 
}

int main(int argc,  char *argv[]) {
    pthread_t p; 
    myret_t *rvals; 
    myarg_t args = { 10,  20 }; 
    Pthread_create(&p,  NULL,  mythread,  &args); 
    Pthread_join(p,  (void **) &rvals); 
    printf("returned %d %d\n",  rvals->x,  rvals->y); 
    free(rvals); 
    return 0; 
}
```
图 27.2 等待线程完成

在代码中, 再次创建单个线程, 并通过 myarg_t 结构传递一些参数. 对于返回值, 使用 myret_t 型接收. 一旦线程运行完毕, 等待在`pthread_join()`例程中的主线程就会返回, 我们可以访问从线程返回的值, 即 `myret_t` 中的值. 

有几点需要说明. 首先,  我们常常打包,  解包参数. 如果我们不需要参数,  创建线程时传入NULL即可. 类似的,  如果不需要返回值,  那么 `pthread_join()`调用也可以传入NULL.

其次, 如果我们只传入一个值(例如, 一个 int), 也不必将它打包为一个参数. 图 27.3 展示了一个例子. 在这种情况下, 更简单一些, 因为我们不必在结构体中打包参数和返回值. 
```c
void *mythread(void *arg) {
    long long int m = (long long int) arg; 
    printf("%lld\n",  m); 
    return (void *) (m + 1); 
}
int main(int argc,  char *argv[]) {
    pthread_t p; 
    long long int m; 
    Pthread_create(&p,  NULL,  mythread,  (void *) 100); 
    Pthread_join(p,  (void **) &m); 
    printf("returned %d\n",  m); 
    return 0; 
}
```
图 27.3 较简单的向线程传递参数示例

我们要十分当心线程返回值的方式. 永远不要返回一个指针,  这个指针指向在线程调用栈里分配的东西. 如果你这么做了,  你觉得会发生什么?  给你个危险的代码看看. 

```c
1  void *mythread(void *arg) {
2      myarg_t *args = (myarg_t *) arg; 
3      printf("%d %d\n",  args->a,  args->b); 
4      myret_t oops;  // ALLOCATED ON STACK:  BAD!
5      oops.x = 1; 
6      oops.y = 2; 
7      return (void *) &oops; 
8  }
```

这个例子,  变量oops分配在mythread的栈上. 然而,  当函数运行完返回时,  这个变量已经被自动释放了. 所以,  传一个指向已经被释放的变量的指针出来,  会造成很多糟糕的结果.
当然,  当你打印那个你以为的返回值时,  你大概(但不一定)会吃惊.

最后, 你可能会注注到, 使用 pthread_create()创建线程, 然后立即调用 pthread_join(), 这是创建线程的一种非常奇怪的方式. 事实上, 有一个更简单的方法来完成这个任务. 这个方法成为过程调用(procedure call). 
显然,  我们通常会创建不止一个线程,  并等它完成. 否则用线程就没多大意义了.

我们需要指出,  并非所有多线程的代码都适用join函数. 比如,  一个多线程web服务器可能会创建很多工作线程,  然后使用主线程接受请求, 并将其无限期地传递给工作线程. 因此这样的长期程序可能不需要 join. 然而,  创建线程来(并行)执行一个特定的并行任务, 很可能就需要用join老确保在退出或进行下一阶段计算之前,  完成这些工作.

## 27.3 锁

除了线程创建和 join 之外,  POSIX 线程库提供的最有用的函数集,  可能是通过锁(lock)来提供互斥进入临界区的那些函数.
实现这方面目的,  最基本的一对函数是: 
`int pthread_mutex_lock(pthread_mutex_t *mutex); `
`int pthread_mutex_unlock(pthread_mutex_t *mutex); `
函数应该易于理解和使用. 如果你注识到有一段代码是一个临界区, 就需要通过锁来保护, 以便像需要的那样正确运行. 你大概可以想象代码的样子: 
```c
pthread_mutex_t lock; 
pthread_mutex_lock(&lock); 
x = x + 1;  // or whatever your critical section is
pthread_mutex_unlock(&lock); 
```
这段代码的意思是: 
如果在调用pthread_mutex_lock()时没有其他线程持有锁,  线程将获取该锁并进入临界区.
如果另一个线程已经持有该锁, 那么尝试获取该锁的线程将不会从该调用返回, 直到获得该锁(意味着持有该锁的线程通过unlock调用释放该锁). 
当然, 在给定的时间内, 许多线程可能会卡住, 在获取锁的函数内部等待. 然而只有持有锁的线程,  才应该调用unlock.

上面那段代码有两个重要的问题. 
第一个问题是,  没有正确的初始化(lack of proper initialization). 
所有的锁,  都必须正确初始化,  来保证他们开始时有正确的值. 并且在调用lock 和 unlock 的时候,  能够正常工作.

POSIX线程,  有两种方式初始化锁(initialize locks).
一种是利用 `PTHREAD_MUTEX_INITIALIZER` 这个常量宏直接赋值.
`pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; `
这么做给锁赋值为默认值,  让锁可用.

动态初始化(在运行时)的方法是,  调用`pthread_mutex_init()`: 
```c
int rc = pthread_mutex_init(&lock,  NULL); 
assert(rc == 0);  // always check success!
```

此函数的第一个参数是锁本身的地址, 而第二个参数是一组可选属性. 传入 NULL 就是使用默认值. 我们通常使用动态(后者)方法.
注意, 当你用完锁时, 还应该相应地调用` pthread_mutex_destroy()`.

第二个问题是在调用获取锁和释放锁时没有检查错误代码. 
就像你在UNIX系统中调用的任何库一样,  这些函数也可能失败. 如果你的代码没有正确检查错误代码,  错误就会悄无声息的产生,  这会导致多个线程进入到临界区.
至少,  要用包装的函数,  给函数成功加上断言.(如图27.4)

```c
// Use this to keep your code clean but check for failures
// Only use if exiting program is OK upon failure
void Pthread_mutex_lock(pthread_mutex_t *mutex) {
    int rc = pthread_mutex_lock(mutex); 
    assert(rc == 0); 
}
```
图 27.4 包注函数示例

更复杂的(非玩具)程序,  在出现问题时不能简单地退出, 应该检查失败并在获取锁或释放锁未成功时执行适当的操作. 

lock和unlock函数,  并不是pthreads库中,  唯一与锁交互的函数.  还有两个你可能感兴趣的函数: 
`int pthread_mutex_trylock(pthread_mutex_t *mutex); `
`int pthread_mutex_timedlock(pthread_mutex_t *mutex, struct timespec *abs_timeout); `

这俩函数用于获取锁. 如果锁已经被持有了,  trylock函数就返回失败. timedlock函数会在超时,  或者获取锁之后(以先发生的为准),  返回. 
所以,  超时时长为0的timedlock函数,  就会退化成trylock函数. 通常应该避免这俩函数. 然而有些情况下,  需要避免卡在(可能会无限期)获取锁的函数里,  这俩函数还是有用的.(死锁的章节里会看到)

## 27.4 条件变量

任何线程库都有的另一个主要部分,  当然POSIX线程也在内,  就是条件变量(condition variable).
当线程间必须产生某种信号时,  如果一个线程在可以继续之前,  一直在等另一个线程执行某些操作,  那条件变量就派上用场了.
程序使用两个主要函数,  以期能如上交互: 
```c
int pthread_cond_wait(pthread_cond_t *cond,  pthread_mutex_t *mutex); 
int pthread_cond_signal(pthread_cond_t *cond); 
```

为了使用条件变量,  必须要有一把与此条件有关的锁. 当调用上面任何一个函数时,  这把锁应该是被持有的.

第一个函数pthread_cond_wait(),  让主调线程进入休眠状态,  因此等待其他某个线程给它发信号,  通常是 当程序里发生了某些 现在正在休眠的线程可能会关心的 变化.
典型用法如下: 
```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; 
pthread_cond_t cond = PTHREAD_COND_INITIALIZER; 
Pthread_mutex_lock(&lock); 
while (ready == 0)
    Pthread_cond_wait(&cond,  &lock); 
Pthread_mutex_unlock(&lock); 
```

这段代码,  在初始化相关的锁和条件之后,  一个线程检查ready,  看变量ready是否已经被置为非0值.
如果ready依旧是0,  那就调用等待函数,  以休眠直到其他某个线程来唤醒它.

唤醒线程的代码运行在另外某个线程中, 像下面这样: 
```c
Pthread_mutex_lock(&lock); 
ready = 1; 
Pthread_cond_signal(&cond); 
Pthread_mutex_unlock(&lock); 
```

关于代码顺序有一些注意事项.
首先,  当发送信号时(还有当修改全局变量ready),  我们总要确保已经先持有锁. 这可以保证我们不会意外地引入竞态条件到我们的代码里.

其次,  你可能注意到了,  wait调用 把某个锁(lock)作为它的第二个参数. 而signal调用只有一个条件参数. 造成这个区别的原因是 wait调用,  除了把主调线程休眠意外,  还会在让调用者进入休眠时,  释放锁.
想象一下,  如果不是这样,  那别的线程如何能够获取锁,  并给它发信号唤醒它. 然而,  在被唤醒之后,  在返回之前,  pthread_cond_wait() 会重新获取锁,  从而确保`等待线程`运行 在等待序列开始时的锁获取和结束时的锁释放之间 ,  这期间任何时刻,  它都持有锁. 

最后一个注意点:  
等待线程在while循环里重复检查条件,  而不是简单的if语句. 后面学条件变量的时候再细聊. 但总体上用while简单且安全. 虽然它重新检查条件(可能增加点开销),  但有些pthread实现方式可能会错误地唤醒一个等待线程,  这种情况下,  若没有重新检查,  等待线程会继续认为条件改变了,  而实际上没变. 
因此将唤醒视为某物可能变了的暗示,  而非绝对的事实,  这样更安全.

注意, 有时候线程之间不用条件变量和锁, 用一个标记变量会看起来很简单.
例如, 我们可以重写上面的等待代码: 
```c
while (ready == 0)
      ;  // spin
```
相关的发信号代码看起来像这样: 
```c
ready = 1; 
```

千万别这么干,  原因有以下几点: 
首先,  许多场合下,  这种方法表现很差.(自旋很长时间只是浪费CPU时钟周期).  
其次,  很容易出错. 用flags(如上)来进行线程间同步非常容易出错.    
不要偷懒, 就算你觉得以不用条件变量,  也不行. 忘记那种flag的同步方法.   

## 27.5 编译和运行

本章所有代码很容易运行. 代码需要包括头文件 pthread.h 才能编译. 链接时需要 pthread库, 增加-pthread 标记. 
例如, 要编译一个简单的多线程程序, 只需像下面这样做: 
`gcc -o main main.c -Wall -pthread`
只要 main.c 包含 pthreads 头文件, 你就已经成功地编译了一个并发程序.

## 27.6 小结

我们介绍了基本的 pthread 库, 包括线程创建, 通过锁创建互斥执行, 通过条件变量的信号和等待. 要想写出健壮高效的多线程代码, 只需要耐心和万分小心！

本章结尾我们给出编写一些多线程代码的建议(参见补充内容). API 的其他方面也很有趣. 如果需要更多信息, 请在 Linux 系统上输入 man -k pthread, 查看构成整个接口的超过一百个 API. 但是, 这里讨论的基础知识应该让你能够构建复杂的(并且希望是正确的和高性能的)多线程程序. 线程难的部分不是 API, 而是如何构建并发程序的棘手逻辑. 请继续阅读以了解更多信息. 

>补充: 线程 API 指导

当你使用 POSIX 线程库(或者实际上, 任何线程库)来构建多线程程序时, 需要记住一些小而重要的事情: 

- 保持简洁. 最重要的一点, 线程之间的锁和信号的代码应该尽可能简洁. 复杂的线程交互容易产生缺陷. 
- 让线程交互减到最少. 尽量减少线程之间的交互. 每次交互都应该想清楚, 并用验证过的、正确的方法来实现(很多方法会在后续章节中学习). 
- 初始化锁和条件变量. 未初始化的代码有时工作正常, 有时失败, 会产生奇怪的结果. 
- 检查返回值. 当然, 任何 C 和 UNIX 的程序, 都应该检查返回值, 这里也是一样. 否则会导致古怪而难以理解的行为, 让你尖叫, 或者痛苦地揪自己的头发. 
- 注意传给线程的参数和返回值. 具体来说, 如果传递在栈上分配的变量的引用, 可能就是在犯错误. 
- 每个线程都有自己的栈. 类似于上一条, 记住每一个线程都有自己的栈. 因此, 线程局部变量应该是线程私有的, 其他线程不应该访问. 线程之间共享数据, 值要在堆(heap)或者其他全局可访问的位置. 
- 线程之间总是通过条件变量发送信号. 切记不要用标记变量来同步. 
- 多查手册. 尤其是 Linux 的 pthread 手册, 有更多的细节、更丰富的内容. 请仔细阅读！

# Ch28 锁

通过对并发的介绍, 我们看到了并发编程的一个最基本问题: 我们希望原子式执行一系列指令, 但由于单处理器上的中断(或者多个线程在多处理器上并发执行), 我们做不到. 
本章介绍了锁(lock), 直接解决这一问题. 程序员在源代码中加锁, 放在临界区周围, 保证`临界区`能够`像单条原子指令一样执行`. 

## 28.1 锁的基本思想

举个例子, 假设临界区像这样, 典型的更新共享变量: 
`balance = balance + 1; `

当然, 其他临界区也是可能的, 比如为链表增加一个元素, 或对共享结构的复杂更新操作. 为了使用锁, 我们给临界区增加了这样一些代码: 
```c
1 lock_t mutex;  // some globally-allocated lock 'mutex'
2 ...
3 lock(&mutex); 
4 balance = balance + 1; 
5 unlock(&mutex); 
```

一个锁就是一个变量,  因此你必须声明一个某种类型的锁变量(比如上面的互斥锁),  才能使用它.
这个锁变量(简称锁) 保存了锁在某一时刻的状态. 它要么是可获得的(available或unlocked或free),  表示没有线程持有锁,  要么是被占用的(acquired,  或locked, 或held),  表示已经有一个线程持有锁,  正处在临界区. 我们也可以在数据类型里保存其他信息,  比如是哪个线程在持有锁,  或者一个请求获取锁的队列. 但这些信息对锁使用者来说,  是隐藏的.

lock()和unlock()函数的语义很简单. 调用lock()尝试获取锁,  如果没有其他线程正持有锁(就是锁可获得),  那该线程就获取锁,  并进入临界区. 该线程有时也被称为锁的持有者.
然后,  如果其他线程以相同的锁变量来调用lock()(此例中的mutex),  因为锁已经被另一个线程持有了,  `调用就不会返回`. 这样一来,  当第一个持有锁的线程在临界区,  `其他线程就进不去临界区`了.

一旦锁的持有者调用unlock(),  锁就又可获取了. 假如没有其它线程在等待锁(没其他已经调用lock(),  卡在那的),  锁的状态就变为可用了.  如果有一些等待线程(卡在lock()中),  它们中的一个会(最终)注意(或者被通知)到这个锁的状态变化,  获取锁,  进入临界区.

`锁为程序员提供了最小程度的调度控制`. 总的来说,  我们把`线程看做是由程序员来创建的实体`,  但由OS来调度,  具体方式由OS来决定. 
锁让程序员获得一些控制权. 通过给临界区加锁,  程序员可以保证临界区内只有一个线程活跃. 

锁将原本由操作系统调度的混乱状态变得更为可控. 

## 28.2 Pthread 锁

`POSIX 库`将锁称为`互斥量(锁)`(mutex),  因为它被用来提供线程之间的互斥. 即当一个线程在临界区,  它能够`阻止其他线程`进入直到本线程离开临界区.
因此,  如果你看到下面的POSIX线程代码,  应该理解它和上面的代码段执行相同的任务(我们再次使用了包装函数来检查获取锁和释放锁时的错误): 
```c
1 pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; 
2
3 Pthread_mutex_lock(&lock);  // wrapper for pthread_mutex_lock()
4 balance = balance + 1; 
5 Pthread_mutex_unlock(&lock); 
```

你可能还会注意到, POSIX 的 lock 和 unlock 函数会传入一个变量, 因为我们可能用不同的锁来保护不同的变量. 这样可以增加并发: 
不同于任何临界区都使用同一个大锁(粗粒度的锁策略), 通常大家会用`不同的锁`保护不同的数据和数据结构, 从而允许更多的线程同时进入被锁的代码区(细粒度的方案).

## 28.3 实现一个锁

我们已经从程序员的角度,  对锁如何工作有了一定的理解. 
那如何`实现(造)`一个锁呢? 我们需要什么`硬件支持`? 需要什么`操作系统的支持`? 本章下面的内容将解答这些问题.

关键问题: 怎样实现一个锁
如何构建一个`高效`的锁? 高效的锁能够以低成本提供互斥, 同时能够实现一些特性, 我们下面会讨论. 需要什么硬件支持? 什么操作系统支持? 

我们需要硬件和操作系统的帮助来实现一个可用的锁. 近些年来, 各种计算机体系结构的指令集都增加了一些不同的`硬件原语`, 我们不研究这些指令是如何实现的(毕竟, 这是计算机体系结构课程的主题), 只研究如何使用它们来实现像锁这样的`互斥原语`. 我们也会研究操作系统如何发展完善, 支持实现成熟复杂的锁库. 

## 28.4 评估锁

在实现锁之前, 我们应该首先明确目标, 因此我们要问, 如何评估一种锁实现的效果.
为了评价锁是否能工作(并工作得好), 我们应该先设立一些标准. 
第一是锁是否能完成它的`基本任务`, 即提供`互斥(mutual exclusion)`. 最基本的, 锁是否有效, 能够阻止多个线程进入临界区? 

第二是`公平性(fairness)`. 当锁可用时, 是否`每一个竞争线程`有`公平的机会`抢到锁? 用另一个方式来看这个问题是检查更极端的情况: 是否有竞争锁的线程会`饿死(starve)`, 一直无法获得锁? 

最后是`性能(performance)`, 具体来说, 是使`用锁之后`增加的`时间开销`. 
有几种场景需要考虑. 一种是`没有竞争的情况`, 即只有一个线程抢锁、释放锁的开支如何? 另外一种是`一个CPU上多个线程竞争`, 性能如何? 最后一种是`多个CPU, 多个线程竞争时`的性能. 
通过比较不同的场景, 我们能够更好地理解不同的锁技术对性能的影响, 下面会进行介绍. 

## 28.5 控制中断

最早提供的互斥解决方案之一, 就是`在临界区关闭中断`. 这个解决方案是为`单处理器系统`开发的. 代码如下: 
```c
1 void lock() {
2     DisableInterrupts(); 
3 }
4 void unlock() {
5     EnableInterrupts(); 
6 }
```

假设我们运行在这样一个单处理器系统上. 通过在进入临界区之前关闭中断(使用特殊的硬件指令), 可以保证临界区的代码不会被中断, 从而像原子地执行. 
结束之后, 我们重新打开中断(同样通过硬件指令), 程序正常运行. 

这个方法的主要优点就是`简单`. 显然不需要费力思考就能弄清楚它为什么能工作. 没有中断, 线程可以确信它的代码会继续执行下去, 不会被其他线程干扰. 

不幸的是, 缺点很多. 
首先, 这种方法要求我们`允许所有主调线程`执行`特权操作`(打开关闭中断), 即信任这种机制不会被滥用. 众所周知, 如果我们必须信任任意一个程序, 可能就有麻烦了. 

看, 麻烦表现为多种形式: 
第一, 一个贪婪的程序可能在它开始时就调用 lock(), 从而独占处理器. 更糟的情况是, 恶意程序调用 lock()后, 一直死循环. 后一种情况, OS无法重新获得系统控制权, 只能重启系统. 关闭中断对应用要求太多信任, 不太适合作为通用的同步解决方案. 

第二, 这种方案不支持多处理器. 如果多个线程运行在不同的 CPU 上, 每个线程都试图进入同一个临界区, 关闭中断也没有作用. 线程可以运行在其他处理器上, 因此能够进入临界区. 多处理器已经很普遍了, 我们的通用解决方案需要更好一些. 

第三, 长时间关闭中断会导致中断丢失, 从而导致严重的系统问题. 假如磁盘设备完成了读取请求, 但 CPU 错失了这一事实, 那么, 操作系统如何知道去唤醒等待读取的进程? 

最后一个不太重要的原因就是效率低. 与正常指令执行相比, 现代 CPU 对于关闭和打开中断的代码执行得较慢. 

基于以上原因, 只在很有限的情况下用关闭中断来实现互斥原语.
例如, 在某些情况下操作系统本身会采用屏蔽中断的方式, 保证访问自己数据结构的原子性, 或至少避免某些复杂的中断处理情况. 这种用法是可行的, 因为在操作系统内部不存在信任问题, 它总是信任自己可以执行特权操作. 

## 28.6 一次失败的尝试: 只用loads/stores

为了比`基于中断的技术`更好, 我们必须依`CPU硬件`和它提供的`指令`来实现一个合适的锁.

我们先来尝试用`简单的flag变量`来实现一个简单的锁. 在这次失败的尝试中, 我们会看到一些实现锁需要的基本思想. 并且(希望)看到为何只用一个简单的变量, 并用普通的loads和stores来访问它是不够的.

在这个尝试中(图28.1),  想法很简单:  使用一个简单的变量(flag)来指明是否有线程已经持有锁.
第一个进入临界区的线程会调用lock(),  先检查flag是否等于1(这个情况下不是),  然后把flag置为1来表明线程现在持有了锁. 当完成临界区操作时, 线程调用unlock(), 清空flag, 表明锁不再被持有.

```c
1 typedef struct __lock_t { int flag;  } lock_t; 
2
3 void init(lock_t *mutex) {
4     // 0 -> lock is available,  1 -> held
5     mutex->flag = 0; 
6 }
7
8 void lock(lock_t *mutex) {
9     while (mutex->flag == 1) // TEST the flag
10        ;  // spin-wait (do nothing)
11    mutex->flag = 1;  // now SET it!
12 }
13
14 void unlock(lock_t *mutex) {
15     mutex->flag = 0; 
16 }
```
图28.1 初次尝试: 一个简单的flag

如果在第一个线程处在临界区时, 碰巧有另一个线程调用lock(), 第二个线程就会在while循环中, `自旋等待(spin-wait)`那个持有锁的线程调用unlock(), 清除flag. 一旦第一个线程如此做了, 等待线程就会离开while循环, 把flag置为1, 然后进入临界区.

不幸的是, 代码有两个问题, 一个是`正确性`, 一个是`性能`.
一旦你习惯思考并发编程 正确性问题显而易见. 想象一下 代码如图28.2一样交替执行. 假设开始的时候flag=0. 

![](assets/Pasted%20image%2020230406154532.png)

从这种交替执行可以看出, 通过适时的(不合时宜的)中断, 我们很容易构造出`两个线程都将标志设置为1`, 都能进入临界区的场景. 这种情况, 显然没有满足`最基本`的要求: `互斥`. 

`性能问题`(稍后会有更多讨论)主要是线程在等待已经被持有的锁时, 采用了`自旋等待(spin-waiting)的技术`, 就是不停地检查标志的值. 自旋等待在等待其他线程释放锁的时候会浪费时间. 尤其是在单处理器上, 一个等待线程等待的目标线程甚至无法运行(至少在上下文切换之前)! 我们要开发出更成熟的解决方案, 也应该考虑避免这种浪费. 

## 28.7 用Test-And-Set实现可用自旋锁

因为`关闭中断`的方法无法工作在多处理器上, 所以系统设计者开始让`硬件支持锁`. 最早的多处理器系统, 像20世纪60年代早期的Burroughs B5000, 已经有这些支持. 今天所有的系统都支持, 甚至包括单CPU的系统. 

一些系统提供了这一指令, 支持基于这种概念创建简单的锁.

最简单的`硬件支持`是`测试并设置指令`(`test-and-set` instruction), 也叫作`原子交换(atomic exchange)`. 我们通过以下C代码片段定义test-and-set指令的作用: 

```c
1 int TestAndSet(int *old_ptr,  int new) {
2     int old = *old_ptr;  // fetch old value at old_ptr
3     *old_ptr = new;  // store 'new' into old_ptr
4     return old;  // return the old value
5 }
```

测试并设置指令做了下述事情. 它返回old_ptr指向的旧值, 同时更新为new的新值. 当然, 关键是这些代码是`原子地(atomically)`执行. 因为`既可以测试旧值,又可以设置新值`, 所以我们把这条指令叫作“测试并设置”. 这一条指令完全可以实现一个简单的`自旋锁(spin lock)`.如图28.3所示, 或者你可以先尝试自己实现, 这样更好！

```c
1 typedef struct lock_t {
2     int flag; 
3 } lock_t; 
4
5 void init(lock_t *lock) {
6 // 0 indicates that lock is available,  1 that it is held
7     lock->flag = 0; 
8 }
9
10 void lock(lock_t *lock) {
11     while (TestAndSet(&lock->flag, 1) == 1)
12     ;  // spin-wait (do nothing)
13 }
14
15 void unlock(lock_t *lock) {
16     lock->flag = 0; 
17 }
```

我们来确保理解为什么这个锁能工作. 首先假设一个线程在运行, 调用 lock(), 目前没有其他线程持有锁, 所以flag是0. 当该线程调用TestAndSet(flag, 1), 函数返回flag的旧值, 为0. 因此主调函数不会进入while循环自旋, 而是会获取锁. 该线程还会`原子式地`把flag值置为1, 表示锁已被持有. 
当该线程完成临界区操作, 就会调用unlock()把flag置0.

第二种场景是, 当某一个线程已经持有锁(即flag为1). 
本线程调用lock(), 然后调用TestAndSet(flag, 1), 这一次返回1. 只要另一个线程一直持有锁, TestAndSet()会重复返回1, 本线程会一直自旋. 
当flag终于被其他某个线程改为0, 本线程会再次调用TestAndSet(), 返回0并且原子地设置为1, 从而获得锁, 进入临界区. 

将测试(test旧的锁值)和设置(set新的值)合并为一个`原子操作`之后, 我们保证了只有一个线程能获取锁. 这就实现了一个`有效的互斥原语`！

你现在可能也理解了为什么这种锁被称为`自旋锁(spin lock)`. 这是`最简单`的一种锁, 一直自旋, 利用CPU周期, 直到锁可用. 在单处理器上, `需要抢占式的调度器`(`preemptive scheduler`).

所谓抢占式调度器, 即不断通过`时钟中断`一个线程, 运行其他线程.

否则, 自旋锁在单CPU上无法使用, 因为一个自旋的线程永远不会放弃CPU. 

## 28.8 评价自旋锁

现在可以按照之前的标准来评价基本的自旋锁了.

锁最重要的一点是`正确性`(correctness):  能够互斥吗? 答案是可以的: 自旋锁一次只允许一个线程进入临界区. 因此, 这是正确的锁. 

下一个标准是`公平性(fairness)`. 自旋锁对于等待线程的公平性如何呢?  能够保证一个等待线程会进入临界区吗?  
答案是`自旋锁不提供任何公平性保证`. 实际上, 自旋的线程在竞争条件下可能会永远自旋. 自旋锁没有公平性, 可能会导致饿死. 

最后一个标准是`性能(performance)`. 使用自旋锁的成本是多少?为了更小心地分析, 我们建议考虑几种不同的情况. 首先, 考虑线程在`单处理器`上竞争锁的情况. 然后, 考虑这些线程跨`多个处理器`. 

对于自旋锁, 在`单CPU`的情况下, `性能开销相当大`. 假设一个线程持有锁进入临界区时被抢占. 调度器可能会运行其他每一个线程(假设有N-1个这种线程). 而其他线程都在竞争锁, 都会在放弃CPU之前, 自旋一个时间片, 浪费CPU周期.

但是, 在`多CPU上`, 自旋锁`性能不错`(如果线程数大致等于CPU数). 假设线程A在CPU1, 线程B在CPU2竞争同一个锁. 线程A(CPU 1)占有锁时, 线程B竞争锁就会自旋(在CPU 2上). 然而, 临界区一般都很短, 因此很快锁就可用, 然后线程 B获得锁. 自旋等待其他处理器上的锁, 并没有浪费很多CPU周期, 因此效果不错. 

> 自旋锁 正确性没问题, 公平性拉胯, 性能单CPU不行, 多CPU不错.

## 28.9 比较并交换

某些系统提供了另一个`硬件原语`, 即`比较并交换`指令. Compare-And-Swap. x86 系统是 compare-and-exchange. 图28.4是这条指令的C语言伪代码. 
```c
1 int CompareAndSwap(int *ptr,  int expected,  int new) {
2     int original = *ptr; 
3     if (original == expected)
4         *ptr = new; 
5     return original; 
6 }
```

比较并交换的`基本思路`是检测ptr指向的值是否和expected相等; 如果是, 更新ptr所指的值为新值. 否则, 什么也不做. 不论哪种情况, 都返回该内存地址的`原来值`, 让代码调用compare-and-swap能够知道执行是否成功.

有了比较并交换指令, 就可以实现一个锁, 类似于用测试并设置那样. 例如, 我们只要用下面的代码替换lock()函数: 
```c
1 void lock(lock_t *lock) {
2     while (CompareAndSwap(&lock->flag, 0, 1) == 1)
3     ;  // spin
4 }
```

其余代码和上面`测试并设置`的例子完全一样. 代码工作的方式很类似, 检查锁值是否为0, 如果是, 原子地交换为1, 从而获得锁. 锁被持有时, 尝试获取锁的线程会`自旋`直到锁被释放.(自旋锁的另一种实现).

如果你想看看如何创建C可调用的x86版本的比较并交换, 下面的代码段可能有用: 

```c
1 char CompareAndSwap(int *ptr, int old, int new) {
2 unsigned char ret; 
3
4 // Note that sete sets a 'byte' not the word
5 __asm__ __volatile__ (
6 " lock\n"
7 " cmpxchgl %2, %1\n"
8 " sete %0\n"
9 :  "=q" (ret),  "=m" (*ptr)
10 :  "r" (new),  "m" (*ptr),  "a" (old)
11 :  "memory"); 
12 return ret; 
13 }
```

最后, 你可能会发现, `比较并交换`指令比测试并设置`更强大`. 当我们在将来简单探讨无等待同步(wait-free synchronization)时, 会用到这条指令的强大之处. 然而, 如果只用它实现一个简单的自旋锁, 它的行为等价于上面分析的自旋锁.

## 28.10 链接的加载和条件式存储指令

一些平台提供了`实现临界区`的一对指令. 例如 MIPS 架构, 链接的加载(load-linked)和条件式存储(store-conditional)可以用来配合使用, 实现锁和其他并发结构. 

图28.4是这些指令的C语言伪代码. Alpha, PowerPC和ARM都提供类似的指令: 

```c
1 int LoadLinked(int *ptr) {
2     return *ptr; 
3 }
4
5 int StoreConditional(int *ptr,  int value) {
6     if (no one has updated *ptr since the LoadLinked to this address) {
7         *ptr = value; 
8         return 1;  // success!
9     } else {
10        return 0;  // failed to update
11    }
12 }
```
图 28.4 链接的加载和条件式存储

链接的加载指令和典型加载指令类似, 都是从内存中取出值存入一个寄存器.

关键的区别在于store-conditional, 只有在该地址没有发生干预存储时(并更新刚刚从中加载的地址上存储的值)才会成功. 成功时, 条件存储返回1, 并将ptr指的值更新为value. 失败时, 返回0, 并且不会更新值.

你可以挑战一下自己, 使用链接的加载和条件式存储来实现一个锁. 完成之后, 看看下面代码提供的简单解决方案. 试一下! 解决方案如图28.5所示.

```c
1 void lock(lock_t *lock) {
2     while (1) {
3         while (LoadLinked(&lock->flag) == 1)
4             ;  // spin until it's zero
5         if (StoreConditional(&lock->flag,  1) == 1)
6             return;  // if set-it-to-1 was a success:  all done
7                  // otherwise:  try it all over again
8      }
9  }
10
11 void unlock(lock_t *lock) {
12      lock->flag = 0; 
13 }
```
图 28.5 使用LL/SC实现锁

lock()代码是唯一有趣的代码. 首先, 一个线程`自旋等待`flag被设置为0(因此表明锁没有被持有). 一旦如此, 线程尝试通过`条件存储`获取锁. 如果成功, 则线程自动将flag值更改为1, 从而可以进入临界区. 

> 提示: 代码越少越好(劳尔定律)
> 应该以很少的代码实现给定的任务. 简洁的代码更易懂, 缺陷更少. 

请注意`条件式存储失败`是如何发生的. 一个线程调用lock(), 执行了链接的加载指令, 返回0, 意思是锁没有被持有. 在尝试执行条件式存储之前, `中断产生了`, 另一个线程进入lock代码, 也执行链接式加载指令,  同样返回0, 继续执行. 

这个时候, 两个线程各自执行了链接加载指令, 各自将尝试执行条件式存储. 这些指令的重点是这些线程只有一个线程能够成功更新flag为1, 从而获得锁; 第二个执行条件存储的线程会失败(因为另一个线程已经成功执行了条件更新), 必须重新尝试获取锁.

在几年前的课上, 一位本科生同学David Capel给出了一种更为简洁的实现, 献给那些喜欢布尔条件短路的人. 看看你是否能弄清楚为什么它是等价的. 当然它更短！

```c
1 void lock(lock_t *lock) {
2     while (LoadLinked(&lock->flag)||!StoreConditional(&lock->flag,  1))
3     ;  // spin
4 }
```

## 28.11 获取并增加

最后一个硬件原语是获取并增加(`fetch-and-add`)指令, 它能原子地返回特定地址的旧值, 并且让该值自增一. 

fetch-and-add的C语言伪代码如下: 
在这个例子中, 我们会用获取并增加指令, 实现一个更有趣的ticket锁. 
图28.6是lock和unlock的代码: 
```c
1 int FetchAndAdd(int *ptr) {
2     int old = *ptr; 
3     *ptr = old + 1; 
4     return old; 
5 }
1 typedef struct lock_t {
2     int ticket; 
3     int turn; 
4 } lock_t; 
5
6 void lock_init(lock_t *lock) {
7     lock->ticket = 0; 
8     lock->turn = 0; 
9 }
10
11 void lock(lock_t *lock) {
12     int myturn = FetchAndAdd(&lock->ticket); 
13     while (lock->turn != myturn)
14         ;  // spin
15 }
16
17 void unlock(lock_t *lock) {
18     FetchAndAdd(&lock->turn); 
19 }
```
图 28.6 ticket锁

不用一个简单的值, 这个方案使用 `一个ticket和turn变量的结构体` 来实现锁.

基本操作也很简单: 当线程希望获取锁时, 首先对一个ticket值执行一个`原子的fetch-and-add指令`. 这个值作为该线程的“turn”(顺位, 即myturn). 全局共享的lock->turn变量被用来决定是哪个线程的turn. 当某一个线程的`(myturn == turn`)时, 则轮到这个线程进入临界区.

unlock则是增加turn, 从而下一个等待线程(有的话)可以进入临界区. 

注意, 不同于之前的方法: 本方法能够保证`所有线程`都能抢到锁. 只要一个线程获得了ticket值, 它最终都会被调度(只要前面的都进入过临界区且释放锁). 之前的方法则不会保证. 比如基于测试并设置的方法, 一个线程有可能一直自旋, 即使其他线程在获取和释放锁. 

>用Fetch-And-Add原子指令实现的自旋锁, 可以兼顾正确性, 公平性, 性能.

## 28.12 自旋过多:  怎么办

基于硬件的锁`简单`(只有几行代码)而且`有效`, 这也是任何好的系统或者代码的两个特点.

然而, 某些情况下, 这些解决方案可能非常低效. 以两个运行在单处理器上的线程为例. 

线程0这个线程正在临界区, 所以已经持有锁了, 且不幸地被中断了. 线程1这时候尝试获取锁, 但发现锁已经被持有. 于是, 它开始自旋. 不停自旋. 
最终,  一个时钟中断产生, 线程0又执行, 释放锁. 最后(比如下次它运行时), 线程1不需要继续自旋了, 它获取了锁. 

因此, 类似地, 一个线程会一直自旋检查一个不会改变的值, 浪费掉整个时间片！如果有N个线程去竞争一个锁, 情况会更糟糕. 同样的场景下, 会浪费N−1个时间片, 只是自旋并等待一个线程释放该锁. 因此, 我们的下一个问题是: 

关键问题: 怎样避免自旋
如何让锁避免`不必要地自旋`, 浪费CPU时间? 

只有硬件支持是不够的. 我们还需要操作系统支持！接下来看一看怎么解决这一问题. 

> 自旋锁, 只需要硬件的支持即可. 而后面的互斥锁, 则需要OS内核调度的支持.

## 28.13 简单方法: 让度

硬件支持让我们有了很大的进展: 我们已经实现了有效, 公平(通过ticket锁)的自旋锁.

但是, 问题仍然存在: 如果`临界区的线程发生上下文切换`, 其他线程只能一直自旋, 等待被中断的(持有锁的)线程重新运行. 

第一种简单友好的方法就是, 在要`自旋的时候`, `让度CPU给其他线程`. 图28.7展示了这种方法. 

```c
1 void init() {
2     flag = 0; 
3 }
4
5 void lock() {
6     while (TestAndSet(&flag,  1) == 1)
7         yield();  // give up the CPU
8 }
9
10 void unlock() {
11     flag = 0; 
12 }
```
图 28.7 测试并设置和让度实现的锁

在这种方法中, 我们假定`OS提供原语yield()`, 线程可以调用它主动放弃CPU, 让其他线程运行. 线程有`三种状态(running, ready, blocked)`; yield是一个`系统调用`, 把主调线程从running状态, 变为ready状态, 因此把另外一个线程提升到running. 

因此, 让度线程, 本质上就是 取消调度(deschedule)自己.

考虑在`单CPU上`运行`两个线程`的例子. 在这个例子中, 基于yield的方法十分有效. 一个线程调用lock(), 发现锁被占用时, 让出CPU, 另外一个线程运行, 完成临界区. 在这个简单的例子中, yield方法工作得非常好.

现在来考虑许`多线程`(例如100个)反复竞争一把锁的情况. 

在这种情况下, 一个线程持有锁, 在释放锁之前被抢占, 其他99个线程分别调用lock(), 发现锁被抢占, 然后让出CPU. 假定采用`某种轮转调度程序`, 这99个线程会一直处于`run-and-yield`这种模式, 直到持有锁的线程再次运行.

虽然比原来的浪费99个时间片的自旋方案要好, 但这种方法仍然成本很高, `上下文切换的成本`是实实在在的, 因此浪费很大.

更糟的是, 我们还没有考虑`饿死的问题`. 一个线程可能一直处于yield的循环, 而其他线程反复进出临界区. 很显然, 我们需要一种方法来解决这个问题. 

## 28.14 使用队列: 休眠替代自旋

前面一些方法的真正问题是存在太多的偶然性. 调度程序决定下一个要运行的线程. 如果调度程序做了糟糕的选择, 线程就会要么一直自旋(第一种方法), 要么立刻让出CPU(第二种方法). 

无论哪种方式, 都有可能产生浪费, 而且无法防止饥饿.

因此, 我们必须`显式地施加某种控制`, 决定现在持有者释放锁时, 谁能抢到锁. 为了做到这一点, 我们需要OS的更多支持, 也需要一个队列来保存等待锁的线程. 

简单起见, 我们利用Solaris提供的支持, 它提供了`两个调用`: 
park()能够让调用线程休眠, unpark(threadID)则会唤醒threadID标识的线程. 

可以用这两个调用来实现锁, 让调用者在获取不到锁时睡眠, 在锁可用时被唤醒. 我们来看看图28.8中的代码, 理解这组原语的一种可能用法. 

```c
1 typedef struct lock_t {
2     int flag; 
3     int guard; 
4     queue_t *q; 
5 } lock_t; 
6
7 void lock_init(lock_t *m) {
8     m->flag = 0; 
9     m->guard = 0; 
10    queue_init(m->q); 
11 }
12
13 void lock(lock_t *m) {
14     while (TestAndSet(&m->guard, 1) == 1)
15         ;  //acquire guard lock by spinning
16     if (m->flag == 0) {
17         m->flag = 1;  // lock is acquired
18         m->guard = 0; 
19     } else {
20         queue_add(m->q, gettid()); 
21         m->guard = 0; 
22         park(); 
23     }
24 }
25
26 void unlock(lock_t *m) {
27     while (TestAndSet(&m->guard, 1) == 1)
28         ;  //acquire guard lock by spinning
29     if (queue_empty(m->q))
30         m->flag = 0;  // let go of lock; no one wants it
31     else
32         unpark(queue_remove(m->q));  //hold lock (for next thread!)
33     m->guard = 0; 
34 }
```
图 28.8 使用队列, 测试并设置, 让读和唤醒的锁

在这个例子中, 我们做了两件有趣的事. 

首先, 我们将之前的`测试并设置`和`等待队列`结合, 实现了一个更高性能的锁. 
其次, 我们通过队列来控制谁会获得锁, `避免饿死`. 

你可能注意到, `guard`基本上起到了`自旋锁`的作用, 围绕着flag和队列操作. 因此, 这个方法并没有完全避免自旋等待. 线程在获取锁或者释放锁时可能被中断, 从而导致其他线程自旋等待. 

但是, 这个自旋等待时间是很有限的(不是用户定义的临界区, 只是在lock和unlock代码中的几个指令),  因此, 这种方法也许是合理的. 

你可能也注意到在lock()函数中, 如果线程不能获取锁(它已被持有), 线程会把自己加入队列(通过调用gettid()获得当前的线程ID), 将guard设置为0, 然后让出CPU. 

如果我们在park()之后, 才把guard设置为0释放锁, 会发生什么呢? park()之后就运行另外一个线程了, guard=0就会等下一次轮到这个线程再执行了.

当要唤醒另一个线程时, flag并没有设置为0. 为什么呢? 其实这不是个错误, 而是必须的！线程被唤醒时, 就像是从park()调用返回. 但是, 在代码里此时它没有持有guard, 所以也不能将flag设置为 1. 因此, 我们就直接把锁从释放的线程传递给下一个获得锁的线程, 期间flag不必设置为0. 

最后, 你可能注意到解决方案中的竞争条件, 就在park()调用之前. 如果不凑巧,一个线程正要park, 假定它应该休眠到锁可用时. 这时切换到另一个线程(比如持有锁的线程), 这可能会导致麻烦. 

比如, 如果该线程随后释放了锁. 接下来第一个线程的park会永远睡下去(可能). 这种问题有时称为`唤醒/等待竞争`(wakeup/waiting race). 

为了避免这种情况, 我们需要额外的工作. (因为时间片轮转, A线程在尝试获取锁时下一步就要执行park了, 结果被时钟中断打断调度到B线程(持有锁的), B释放锁, A就park了.)

Solaris 通过增加了`第三个系统调用setpark()`来解决这一问题. 通过setpark(), 一个线程表明自己马上要park. 如果它在调用park之前碰巧被中断打断, 另一个线程被调度, 并且调用了unpark, 那么后续的park调用就会直接返回, 而不是一直睡眠. 

lock()调用可以做一点小修改: 
```c
1 queue_add(m->q, gettid()); 
2 setpark();  //new code
3 m->guard = 0; 
```

`另一个方案`是把guard传到内核里. 这样的话, 内核能采取预防措施, 保证原子地释放锁, 把运行线程移出队列. 

## 28.15 不同OS, 不同支持

目前我们看到, 为了在线程库构建更有效率的锁, 一个OS能提供的一种支持. 其他OS也提供了类似的支持, 但细节不同. 

例如, Linux提供了`futex`, 它类似于Solaris的接口, 但提供了更多`内核内的功能`. 

具体来说, `每个futex`都关联一个`特定的物理内存位置`, 也有一个事先建好的`内核队列`. 调用者通过futex调用(见下面的描述)来睡眠或者唤醒.

具体来说, 有两个调用.
- 调用futex_wait(address, expected)时, 如果address处的值等于expected, 就会让调线程睡眠. 否则, 调用立刻返回. 
- 调用futex_wake(address)唤醒等待队.

列中的一个线程. 图 28.9 是 Linux 环境下的例子.

```c
1 void mutex_lock (int *mutex) {
2     int v; 
3     /* Bit 31 was clear,  we got the mutex (this is the fastpath) */
4     if (atomic_bit_test_set (mutex, 31) == 0)
5         return; 
6     atomic_increment(mutex); 
7     while (1) {
8         if (atomic_bit_test_set (mutex, 31) == 0) {
9             atomic_decrement (mutex); 
10            return; 
11        }
12         /* We have to wait now. First make sure the futex value
13         we are monitoring is truly negative (i.e. locked). */
14        v = *mutex; 
15        if (v >= 0)
16           continue; 
17        futex_wait (mutex, v); 
18     }
19 }
20
21 void mutex_unlock (int *mutex) {
22 /* Adding 0x80000000 to the counter results in 0 if and only if
23 there are not other interested threads */
24 if (atomic_add_zero (mutex, 0x80000000))
25     return; 
26
27 /* There are other threads waiting for this mutex, 
28 wake one of them up. */
29    futex_wake (mutex); 
```
图 28.9 基于 Linux 的 futex 锁

这段代码来自nptl库(gnu libc库的一部分)中lowlevellock.h, 因为几个原因它很有趣. 

首先, 它利用一个整数, 同时记录锁是否被持有(整数的`最高位`), 以及这个`锁等待者的个数`(整数的其余所有位). 因此, 如果`锁是负的`, 它就`被持有`(因为最高位被设置, 该位决定了整数的符号). 

其次, 它展示了如何优化常见的情况, 即`当锁没有竞争时`: 只有一个线程获取和释放锁, 所做的工作很少(获取锁时test-and-set的原子位运算, 释放锁时原子的加法).你可以看看这个“真实世界”的锁的其余部分, 是否能理解其工作原理. 

## 28.16 两阶段锁

Two-Phase Locks. 
最后一点: Linux 采用的是一种古老的锁方案, 多年来不断被采用, 可以追溯到20世纪60年代早期的Dahm锁. 现在也称为两阶段锁(two-phase lock).

两阶段锁意识到`自旋`可能很有用, 尤其是在就要释放锁的场景. 因此, 两阶段锁的第一阶段会先自旋一段时间, 希望它可以获取锁. 

但是, 如果第一个自旋阶段没有获得锁, 第二阶段调用者会睡眠, 只有锁可用时才会被唤醒. 上文的 Linux锁就是这种锁, 不过只自旋一次; 更常见的方式是在使用futex睡眠之前, 在循环中自旋固定的次数.

两阶段锁是又一个混合(hybrid)方案的例子,  即结合两种好想法得到更好的想法. 当然, 硬件环境、线程数、其他负载等这些因素, 都会影响锁的效果. 事情总是这样, 让单个通用目标的锁, 在所有可能的场景下都很好, 这是巨大的挑战. 

## 28.17 小结

以上的方法展示了如今真实的锁是如何实现的: 一些硬件支持(更加强大的指令)和一些操作系统支持(例如 Solaris 的 park()和 unpark()原语, Linux 的 futex). 当然, 细节有所不同, 执行这些锁操作的代码通常是高度优化的. 读者可以查看 Solaris 或者 Linux 的代码以了解更多信息. David 等人关于现代多处理器的锁策略的对比也值得一看.

# Ch29 基于锁的并发数据结构

在结束锁的讨论之前,我们先讨论如何在常见数据结构中`使用锁`.`将锁添加到数据结构以使其可由线程使用, 这样可使结构线程安全(thread safe)`.当然, 具体如何加锁决定了该数据结构的正确性和效率. 因此, 我们的挑战是:

关键问题:如何把锁加到数据结构里？
对于特定数据结构,如何加锁才能让该结构功能正确？进一步,如何对该数据结构加锁,能够保证这个数据结构yield高性能,让许多线程`同时`访问该结构,即并发访问(concurrently)？

当然,我们很难介绍所有的数据结构,或实现并发的所有方法,因为这是一个研究多年的议题,已经发表了数以千计的相关论文.因此,我们希望能够提供这类思考方式的足够介绍,同时提供一些好的资料,供你自己进一步研究.我们发现,Moir 和 Shavit 的调查就是很好的资料.

## 29.1 并发计数器

计数器是最简单的一种数据结构, 使用广泛而且接口简单. 图 29.1 中定义了一个非并发的计数器.

```c
1 typedef struct counter_t {
2     int value;
3 } counter_t;
4
5 void init(counter_t *c) {
6     c->value = 0;
7 }
8
9 void increment(counter_t *c) {
10    c->value++;
11 }
12
13 void decrement(counter_t *c) {
14     c->value--;
15 }
16
17 int get(counter_t *c) {
18     return c->value;
19 }
```
图 29.1 无锁的计数器

### 简单但无法扩展

你可以看到,没有同步机制的计数器很简单,只需要很少代码就能实现, 只是尝试性的数据结构.
现在我们的下一个挑战是:如何让这段代码线程安全(thread safe)? 图 29.2 展示了我们的做法.
```c
1 typedef struct counter_t {
2     int value;
3     pthread_mutex_t lock;
4 } counter_t;
5
6 void init(counter_t *c) {
7     c->value = 0;
8     Pthread_mutex_init(&c->lock, NULL);
9 }
10
11 void increment(counter_t *c) {
12     Pthread_mutex_lock(&c->lock);
13     c->value++;
14     Pthread_mutex_unlock(&c->lock);
15 }
16
17 void decrement(counter_t *c) {
18     Pthread_mutex_lock(&c->lock);
19     c->value--;
20     Pthread_mutex_unlock(&c->lock);
21 }
22
23 int get(counter_t *c) {
24     Pthread_mutex_lock(&c->lock);
25     int rc = c->value;
26     Pthread_mutex_unlock(&c->lock);
27     return rc;
28 }
```
图 29.2 有锁的计数器

这个并发计数器简单、正确.实际上,它遵循了最简单、最基本的并发数据结构中常见的数据设计模式:它只是加了一把锁,在调用函数操作该数据结构时获取锁,从调用返回时释放锁.这种方式类似基于观察者(monitor)的数据结构,在调用、退出对象方法时,会自动获取锁、释放锁.

现在, 有了一个并发数据结构, 问题可能就是性能了. 如果这个结构导致运行速度太慢,那么除了简单加锁,还需要进行优化.如果需要这种优化,那么本章的余下部分将进行探讨.
请注意,如果数据结构导致的运行速度`不是太慢`,那就没事！如果简单的方案就能工作,就不需要精巧的设计.

为了理解简单方法的性能成本,我们运行一个基准测试,每个线程更新同一个共享计数器固定次数,然后我们改变线程数.
图 29.5 给出了运行 1 个线程到 4 个线程的总耗时,其中每个线程更新 100 万次计数器.本实验是在 4 核 Intel 2.7GHz i5 CPU 的 iMac 上运行.通过增加 CPU,我们希望单位时间能够完成更多的任务.

![](assets/Pasted%20image%2020230408132716.png)

从图 29.5 上方的曲线(标为“精确”)可以看出,同步的计数器扩展性不好.单线程完成 100 万次更新只需要很短的时间(大约 0.03s),而两个线程并发执行,每个更新 100 万次,性能下降很多(超过 5s！).线程更多时,性能更差.

理想情况下,你会看到多处理器上运行的多线程就像单线程一样快.达到这种状态称为完美扩展(perfect scaling).虽然总工作量增多,但是并行执行后,完成任务的时间并没有增加.

### 可扩展的计数

令人吃惊的是,关于如何实现`更可扩展`的计数器,研究人员已经研究了多年.更令人吃惊的是,最近的操作系统性能分析研究表明,可扩展的计数器很重要.没有可扩展的计数,一些运行在 Linux 上的工作在`多核机器`上将遇到严重的扩展性问题.

人们已经开发了多种技术来解决这一问题,我们将介绍一种特定的方法.这个方法是最近的研究提出的,称为近似计数器(approximate counter).

近似计数器通过`多个局部物理计数器`和`一个全局计数器`来实现一个`逻辑计数器`,其中每个
CPU 核心有一个局部计数器.具体来说,在 4 个 CPU 的机器上,有 4 个局部计数器和 1 个
全局计数器.除了这些计数器,还有锁:每个局部计数器有一个锁,全局计数器有一个.

近似计数器的基本思想是这样的.
如果一个核心上的线程想增加计数器,那就增加它的局部计数器,访问这个局部计数器是通过对应的局部锁同步的.因为每个 CPU 有自己的局部计数器,不同CPU上的线程不会竞争,所以计数器的更新操作可扩展性好.

但是,为了保持全局计数器是最新的(以防某个线程要读取该值),局部值会`定期`转移给全局计数器,方法是获取全局锁,让全局计数器加上局部计数器的值,然后将`局部计数器置零`.

这种局部转全局的频度,取决于一个阈值,这里称为 S. 
S 越小,则越像上面的非扩展的计数器.S 越大,扩展性越强,但是全局计数器与实际计数的偏差越大.我们可以抢占所有的局部锁和全局锁(以特定的顺序,避免死锁),以获得精确值,但这种方法没有扩展性.

为了弄清楚这一点,来看一个例子(如下图).在这个例子中,阈值 S 设置为 5,4个 CPU 上分别有一个线程来更新局部计数器 L1,…,L4.随着时间增加,全局计数器 G 的值也会记录下来.每一段时间,局部计数器可能会增加.如果局部计数值增加到阈值 S,就把局部值转移到全局计数器,局部计数器清零.

![](assets/Pasted%20image%2020230408132226.png)

图 29.5中下方的线,是阈值S为 1024 时近似计数器的性能.性能很高,4 个处理器更新 400 万次的时间和一个处理器更新 100 万次的几乎一样.

图 29.6 展示了阈值 S 的重要性,在 4 个 CPU 上的 4 个线程,分别增加计数器 100 万次.
如果 S 小,性能很差(但是全局计数器精确度高).如果 S 大,性能很好,但是全局计数器
会有延时.近似计数器就是在准确性和性能之间折中.

![](assets/Pasted%20image%2020230408133039.png)

图 29.4 是这种近似计数器的基本实现.阅读它,或者运行它,尝试一些例子,以便更好地理解它的原理.

```c
1 typedef struct counter_t {
2     int global; // global count
3     pthread_mutex_t glock; // global lock
4     int local[NUMCPUS]; // local count (per cpu)
5     pthread_mutex_t llock[NUMCPUS]; // ... and locks
6     int threshold; // update frequency
7 } counter_t;
8
9 // init: record threshold, init locks, init values
10 // of all local counts and global count
11 void init(counter_t *c, int threshold) {
12     c->threshold = threshold;
13
14     c->global = 0;
15     pthread_mutex_init(&c->glock, NULL);
16
17     int i;
18     for (i = 0; i < NUMCPUS; i++) {
19         c->local[i] = 0;
20         pthread_mutex_init(&c->llock[i], NULL);
21     }
22 }
23
24 // update: usually, just grab local lock and update local amount
25 // once local count has risen by 'threshold', grab global
26 // lock and transfer local values to it
27 void update(counter_t *c, int threadID, int amt) {
28     pthread_mutex_lock(&c->llock[threadID]);
29     c->local[threadID] += amt; // assumes amt > 0
30     if (c->local[threadID] >= c->threshold) { // transfer to global
31         pthread_mutex_lock(&c->glock);
32         c->global += c->local[threadID];
33         pthread_mutex_unlock(&c->glock);
34         c->local[threadID] = 0;
35     }
36     pthread_mutex_unlock(&c->llock[threadID]);
37 }
38
39 // get: just return global amount (which may not be perfect)
40 int get(counter_t *c) {
41     pthread_mutex_lock(&c->glock);
42     int val = c->global;
43     pthread_mutex_unlock(&c->glock);
44     return val; // only approximate!
45 }
```
Figure 29.4: Approximate Counter Implementation

## 29.2 并发链表

接下来看一个更复杂的数据结构,链表.同样,我们从一个基础实现开始.简单起见,我们只关注链表的插入操作,其他操作比如查找、删除等就交给读者了.图 29.7 展示了这个基本数据结构的代码.

```c
1 // basic node structure
2 typedef struct node_t {
3     int key;
4     struct node_t *next;
5 } node_t;
6
7 // basic list structure (one used per list)
8 typedef struct list_t {
9      node_t *head;
10     pthread_mutex_t lock;
11 } list_t;
12
13 void List_Init(list_t *L) {
14     L->head = NULL;
15     pthread_mutex_init(&L->lock, NULL);
16 }
17
18 int List_Insert(list_t *L, int key) {
19     pthread_mutex_lock(&L->lock);
20     node_t *new = malloc(sizeof(node_t));
21     if (new == NULL) {
22         perror("malloc");
23         pthread_mutex_unlock(&L->lock); // fail unlock
24         return -1; // fail
25     }
26     new->key = key;
27     new->next = L->head;
28     L->head = new;
29     pthread_mutex_unlock(&L->lock);
30     return 0; // success
31 }
32
33 int List_Lookup(list_t *L, int key) {
34     pthread_mutex_lock(&L->lock);
35     node_t *curr = L->head;
36     while (curr) {
37         if (curr->key == key) {
38            pthread_mutex_unlock(&L->lock);
39            return 0; // success
40         }
41        curr = curr->next;
42     }
43     pthread_mutex_unlock(&L->lock);
44     return -1; // failure
45 }
```
Figure 29.7: Concurrent Linked List

从代码中可以看出,代码插入函数入口处获取锁,结束时释放锁.如果 malloc 失败(在极少的时候),会有一点小问题,在这种情况下,代码在插入失败之前,必须释放锁.

事实表明, 这种异常控制流容易出错. 最近一个Linux内核补丁的研究发现, 在这种很少使用的代码路径上发现了大量的 bug (将近40%)(事实上,这一观察引发了我们自己的一些研究,我们从 Linux 文件系统中删除了所有的内存故障路径,结果系统更加健壮了).

因此,挑战来了:我们能够重写插入和查找函数,保持并发插入正确,但避免在失败情况下也需要调用释放锁吗？

在这个例子中,答案是可以.具体来说,我们调整代码,让获取锁和释放锁只环绕插入代码的真正临界区.前面的方法有效是因为部分工作实际上不需要锁,假定 malloc()是线程安全的,每个线程都可以调用它,不需要担心竞争条件和其他并发缺陷.只有在更新共享列表时需要持有锁.图 29.8 展示了这些修改的细节.
```c
13 void List_Init(list_t *L) {
14     L->head = NULL;
15     pthread_mutex_init(&L->lock, NULL);
16 }
17
18 void List_Insert(list_t *L, int key) {
19     // synchronization not needed
20     node_t *new = malloc(sizeof(node_t));
21     if (new == NULL) {
22         perror("malloc");
24         return; // fail
25     }
26     new->key = key;
       // just lock critical section
       pthread_mutex_lock(&L->lock);
27     new->next = L->head;
28     L->head = new;
29     pthread_mutex_unlock(&L->lock);
30   
31 }
32
33 int List_Lookup(list_t *L, int key) {
       int rv = -1;
34     pthread_mutex_lock(&L->lock);
35     node_t *curr = L->head;
36     while (curr) {
37         if (curr->key == key) {
38            rv = 0;
39            break; // do not return 
40         }
41        curr = curr->next;
42     }
43     pthread_mutex_unlock(&L->lock);
44     return rv; // now both success and failure
45 }
```
Figure 29.8: Concurrent Linked List: Rewritten

对于查找函数,进行了简单的代码调整,跳出主查找循环,到单一的返回路径.这样做减少了代码中需要获取锁、释放锁的地方,降低了代码中不小心引入缺陷(诸如在返回前忘记释放锁)的可能性. 

### 扩展链表

尽管我们有了基本的并发链表,但又遇到了这个链表扩展性不好的问题.研究人员发现的提升链表并发的技术中,有一种叫作过手锁(hand-over-hand locking,也叫作锁耦合,lock coupling).

原理也很简单.每个节点都有一个锁,替代之前整个链表一个锁.遍历链表的时候,首先抢占下一个节点的锁,然后释放当前节点的锁(过手锁名字的由来).

从概念上说,过手锁链表有点道理,它增加了链表操作的并发程度.但是实际上,在遍历的时候,每个节点获取锁、释放锁的开销巨大,很难比单锁的方法快.即使有大量的线程和很大的链表,这种并发的方案也不一定会比单锁的方案快.也许某种杂合的方案(一定数量的节点用一个锁)值得去研究.

> 提示: 更多并发不一定更快

如果方案带来了大量的开销(例如,频繁地获取锁、释放锁),那么高并发就没有什么意义.
如果简单的方案很少用到高开销的调用,通常会很有效.增加更多的锁和复杂性可能会适得其反.话虽如此,有一种办法可以获得真知:实现两种方案(简单但少一点并发,复杂但多一点并发),测试它们的表现.

> 提示:当心锁和控制流

有一个通用建议,对并发代码和其他代码都有用,即注意控制流的变化导致函数返回和退出,或其他错误情况导致函数停止执行.
因为很多函数开始就会获得锁,分配内存,或者进行其他一些改变状态的操作,如果错误发生,代码需要在返回前恢复各种状态,这容易出错.因此,最好组织好代码,减少这种模式.

## 29.3 并发队列

你现在知道了,总有一个标准的方法来创建一个并发数据结构:添加一把大锁.对于一个队列,我们将跳过这种方法,假定你能弄明白.

我们来看看 Michael 和 Scott设计的、更并发的队列.图 29.9 展示了用于该队列的数据结构和代码.

```c
1 typedef struct node_t {
2     int value;
3     struct node_t *next;
4 } node_t;
5
6 typedef struct queue_t {
7     node_t *head;
8     node_t *tail;
9     pthread_mutex_t headLock;
10    pthread_mutex_t tailLock;
11 } queue_t;
12
13 void Queue_Init(queue_t *q) {
14     node_t *tmp = malloc(sizeof(node_t));
15     tmp->next = NULL;
16     q->head = q->tail = tmp;
17     pthread_mutex_init(&q->headLock, NULL);
18     pthread_mutex_init(&q->tailLock, NULL);
19 }
20
21 void Queue_Enqueue(queue_t *q, int value) {
22     node_t *tmp = malloc(sizeof(node_t));
23     assert(tmp != NULL);
24     tmp->value = value;
25     tmp->next = NULL;
26
27     pthread_mutex_lock(&q->tailLock);
28     q->tail->next = tmp;
29     q->tail = tmp;
30     pthread_mutex_unlock(&q->tailLock);
31 }
32
33 int Queue_Dequeue(queue_t *q, int *value) {
34     pthread_mutex_lock(&q->headLock);
35     node_t *tmp = q->head;
36     node_t *newHead = tmp->next;
37     if (newHead == NULL) {
38         pthread_mutex_unlock(&q->headLock);
39         return -1; // queue was empty
40     }
41     *value = newHead->value;
42     q->head = newHead;
43     pthread_mutex_unlock(&q->headLock);
44     free(tmp);
45     return 0;
46 }
```
Figure 29.9: Michael and Scott Concurrent Queue

你会发现有两个锁,一个负责队列头,另一个负责队列尾.
这两个锁使得入队列操作和出队列操作可以并发执行,因为入队列只访问tail锁, 而出队列只访
问 head 锁.

Michael 和 Scott 使用了一个技巧,添加了一个假的节点(在队列初始化的代码里分配的).
该假节点分开了头和尾操作.

队列在多线程程序里广泛使用.然而,这里的队列(只是加了锁)通常不能完全满足这种程序的需求.更完善的有界队列,在队列空或者满时,能让线程等待.这是下一章探讨条件变量时集中研究的主题.

## 29.4 并发散列表

我们讨论最后一个应用广泛的并发数据结构,散列表(见图 29.10).我们只关注不需要调整大小的简单散列表.支持调整大小还需要一些工作,留给读者作为练习.

```c
1 #define BUCKETS (101)
2
3 typedef struct hash_t {
4     list_t lists[BUCKETS];
5 } hash_t;
6
7 void Hash_Init(hash_t *H) {
8     int i;
9     for (i = 0; i < BUCKETS; i++) {
10        List_Init(&H->lists[i]);
11    }
12 }
13
14 int Hash_Insert(hash_t *H, int key) {
15     int bucket = key % BUCKETS;
16     return List_Insert(&H->lists[bucket], key);
17 }
18
19 int Hash_Lookup(hash_t *H, int key) {
20     int bucket = key % BUCKETS;
21     return List_Lookup(&H->lists[bucket], key);
22 }
```
Figure 29.10: A Concurrent Hash Table

本例的散列表使用我们之前实现的并发链表,性能特别好.性能好的原因是, 每个散列桶(每个桶都是一个链表, 相同的键在同一个列表里)都有一个锁,而不是整个散列表只有一个锁,从而支持许多并发操作.(101个数组元素, 101个链表).

图 29.11 展示了并发更新下的散列表的性能(同样在 4 CPU 的 iMac,4 个线程,每个线程分别执行 1 万～5 万次并发更新).同时,作为比较,我们也展示了单锁链表的性能.可以看出,这个简单的并发散列表扩展性极好,而链表则相反.

![](assets/Pasted%20image%2020230408150311.png)

>建议:避免不成熟的优化(Knuth 定律)

实现并发数据结构时, 先从最简单的方案开始, 也就是加一把大锁来同步.
这样做,你很可能构建了正确的锁.如果发现性能问题,那么就改进方法,只要优化到满足需要即可.正如 Knuth 的著名说法“不成熟的优化是所有坏事的根源.”

许多操作系统,在最初过渡到多处理器时都是用一把大锁,包括 Sun 和 Linux.在 Linux 中,这个锁甚至有个名字,叫作 BKL(大内核锁,big kernel lock).

这个方案在很多年里都很有效,直到多 CPU系统普及,内核只允许一个线程活动成为性能瓶颈.终于到了为这些系统优化并发性能的时候了.Linux采用了简单的方案,把一个锁换成多个.Sun 则更为激进,实现了一个最开始就能并发的新系统,Solaris.

## 29.5 小结

我们已经介绍了一些并发数据结构,从计数器到链表队列,最后到大量使用的散列表.这些都是锁的使用案例. 如何让这些数据结构能并发使用.

同时,我们也学习到:控制流变化时注意获取锁和释放锁;增加并发不一定能提高性能;
有性能问题的时候再做优化.关于最后一点,避免不成熟的优化(premature optimization),对于所有关心性能的开发者都有用.我们让整个应用的某一小部分变快,却没有提高整体性能,其实没有价值.

当然,我们只触及了高性能数据结构的皮毛.
特别是,你可能会对其他结构感兴趣(比如 B 树),那么数据库课程会是一个不错的选择.
你也可能对根本不用传统锁的技术感兴趣.这种非阻塞数据结构是有意义的,在常见并发问题的章节中,我们会稍稍涉及.
但老实说这是一个广泛领域的知识,远非本书所能覆盖.感兴趣的读者可以自行研究.

# Ch30 条件变量

到目前为止, 我们已经形成了锁的概念, 看到了如何通过硬件和操作系统支持的正确组合来实现锁.  然而, 锁并不是并发程序设计所需的唯一原语.

具体来说, 在很多情况下, 线程需要检查某一条件(condition)满足之后, 才会继续运行. 例如, 父线程需要检查子线程是否执行完毕(这常被称为 join()). 这种等待如何实现呢? 我们来看如图30.1所示的代码.

```c
1 void *child(void *arg) {
2     printf("child\n");
3     // XXX how to indicate we are done?
4     return NULL;
5 }
6
7 int main(int argc, char *argv[]) {
8     printf("parent: begin\n");
9     pthread_t c;
10    Pthread_create(&c, NULL, child, NULL); // create child
11    // XXX how to wait for child?
12    printf("parent: end\n");
13    return 0;
14 }
```
图 30.1 父线程等待子线程

我们期望能看到这样的输出:
```
parent: begin
child
parent: end
```

我们可以尝试用一个共享变量, 如图30.2所示. 这种解决方案一般能工作, 但是效率低下, 因为主线程会自旋检查, 浪费CPU时间. 我们希望有某种方式让父线程休眠, 直到等待的条件满足(即子线程完成执行). 
```c
volatile int done = 0;

void *child(void *arg) {
    printf("child\n");
    done = 1;
    return NULL;
}
int main(int argc, char *argv[]) {
    printf("parent: begin\n");
    pthread_t p;
    Pthread_create(&p, NULL, child, NULL);
    while (done == 0) 
		; //spin
    printf("parent: end\n");
    return 0;
}
```
图 30.2 父线程等待子线程: 基于自旋的方案

关键问题: 如何等待一个条件？
多线程程序中, 一个线程等待某些条件是很常见的. 简单的方案是自旋直到条件满足,这是极其低效的, 浪费CPU时钟周期, 某些情况下甚至是错误的.那么,线程应该如何等待一个条件？

## 30.1 定义和函数

线程可以使用条件变量(condition variable), 来等待一个条件变成真. 

`条件变量是一个显式队列`, 当某些执行状态(即条件, condition)不满足时, 线程可以把自己加入队列, 等待(waiting)该条件. 
另外某个线程, 当它改变了上述状态时, 就可以唤醒一个或者多个等待线程(通过在该条件上发信号), 让它们继续执行. 

Dijkstra最早在“私有信号量”中提出这种思想. Hoare后来在关于观察者的工作中, 将类似的思想称为条件变量. 

要声明这样的条件变量, 只要像这样写: `pthread_cond_t c;`, 这里声明 c 是一个条件变量(注意:还需要适当的初始化). 条件变量有两种相关操作: `wait()和signal()`. 线程要睡眠的时候, 调用wait(). 当线程想唤醒等待在某个条件变量上的睡眠线程时, 调用signal(). 具体来说, POSIX 调用如图 30.3 所示. 

```c
pthread_cond_wait(pthread_cond_t *c, pthread_mutex_t *m);
pthread_cond_signal(pthread_cond_t *c);

pthread_cond_t  c = PTHREAD_COND_INITIALIZER;
pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;
int done = 0;

void thr_exit() {
    Pthread_mutex_lock(&m);
    done = 1;
    Pthread_cond_signal(&c);
    Pthread_mutex_unlock(&m);
}

void *child(void *arg) {
    printf("child\n");
    thr_exit();
    return NULL;
}
void thr_join() {
    Pthread_mutex_lock(&m);
    while (done == 0)
        Pthread_cond_wait(&c, &m);
    Pthread_mutex_unlock(&m);
}

int main(int argc, char *argv[]) {
    pthread_t p;
    printf("parent: begin\n");
    Pthread_create(&p, NULL, child, NULL);
    thr_join();
    printf("parent: end\n");
    return 0;
}
```
图 30.3 父线程等待子线程: 使用条件变量

我们常简称为 wait()和 signal().你可能注意到一点,wait()调用有一个参数,它是互斥量.它假定在 wait()调用时,这个互斥量是已上锁状态.wait()的职责是释放锁,并让调用线程休眠(原子地).当线程被唤醒时(在另外某个线程发信号给它后),它必须重新获取锁,再返回调用者.这样复杂的步骤也是为了避免在线程陷入休眠时,产生一些竞态条件.
我们观察一下图 30.3 中 join 问题的解决方法,以加深理解.

有两种情况需要考虑.
第一种情况是父线程创建出子线程,但自己继续运行(假设只有一个处理器),然后马上调用 thr_join()等待子线程.
在这种情况下,它会先获取锁,检查子进程是否完成(还没有完成),然后调用 wait(),让自己休眠.子线程最终得以运行,打印出“child”,并调用 thr_exit()函数唤醒父进程,这段代码会在获得锁后设置状态变量 done,然后向父线程发信号唤醒它.
最后,父线程会运行(从 wait()调用返回并持有锁),释放锁,打印出“parent:end”.

第二种情况是,子线程在创建后,立刻运行,设置变量 done 为 1,调用 signal 函数唤醒其他线程(这里没有其他线程),然后结束.父线程运行后,调用 thr_join()时,发现 done已经是 1 了,就直接返回.

最后一点说明:你可能看到父线程使用了一个 while 循环,而不是 if 语句来判断是否需要等待.虽然从逻辑上来说没有必要使用循环语句,但这样做总是好的(后面我们会加以说明).

为了确保理解 thr_exit()和 thr_join()中每个部分的重要性,我们来看一些其他的实现.
首先,你可能会怀疑状态变量 done 是否需要.代码像下面这样如何？正确吗？
```c
void thr_exit() {
    Pthread_mutex_lock(&m);
    Pthread_cond_signal(&c);
    Pthread_mutex_unlock(&m);
}

void thr_join() {
    Pthread_mutex_lock(&m);
    Pthread_cond_wait(&c, &m);
    Pthread_mutex_unlock(&m);
}
```
Figure 30.4: Parent Waiting: No State Variable

这段代码是有问题的.假设子线程立刻运行,并且调用 thr_exit().在这种情况下,子线程发送信号,但此时却没有在条件变量上睡眠等待的线程.父线程运行时,就会调用 wait并卡在那里,没有其他线程会唤醒它.通过这个例子,你应该认识到变量 done 的重要性,它记录了线程有兴趣知道的值.睡眠、唤醒和锁都离不开它.

下面是另一个糟糕的实现.在这个例子中,我们假设线程在发信号和等待时都不加锁.会发生什么问题？想想看！
```c
void thr_exit() {
    done = 1;
    Pthread_cond_signal(&c);;
}

void thr_join() {
    if ( 0 == done )
       Pthread_cond_wait(&c);

}
```
Figure 30.5: Parent Waiting: No Lock

这里的问题是一个微妙的竞态条件.具体来说,如果父线程调用 thr_join(),然后检查完done 的值为 0,然后试图睡眠.但在调用 wait 进入`睡眠之前`, `父线程被中断`.子线程修改变量done为 1,发出信号,同样没有等待线程.父线程再次运行时,就会长眠不醒,这就惨了.

希望通过这个简单的join示例, 你可以看到使用条件变量的一些基本要求. 为了确保你能理解, 我们现在来看一个更复杂的例子: 生产者/消费者(producer/consumer)或有界缓冲区(bounded-buffer)问题.

> 提示:发信号时总是持有锁

尽管并不是所有情况下都严格需要,但有效且简单的做法,还是在使用条件变量发送信号时持有锁.为了简单,请在调用 signal 时持有锁(hold the lock when calling signal).

调用 wait 时持有锁,不只是建议,而是 wait 的语义强制要求的. 因为 wait 调用总是假设你调用它时已经持有锁, 调用者睡眠之前会释放锁以及返回前重新持有锁.

总之, 调用 signal 和 wait 时要持有锁(hold the lock when calling signal or wait).

## 30.2 生产者/消费者(有界缓冲区)问题

下一个同步问题, 是生产者/消费者(producer/consumer)问题, 也叫作有界缓冲区(bounded buffer)问题. 这一问题最早由Dijkstra提出. 实际上也正是通过研究这一问题, Dijkstra 和他的同事发明了通用的信号量(它可用作锁或条件变量). 信号量稍后会讨论.

假设 有一个或多个生产者线程, 和一个或多个消费者线程. 生产者负责生产数据项, 并放到一个缓冲区. 消费者从缓冲区取走数据项, 以某种方式消费掉.

很多实际的系统中都会有这种场景. 例如, 在多线程的网络服务器中, 一个生产者将HTTP请求放入工作队列(即有界缓冲区), 消费线程从队列中取走请求并处理.

我们在使用`管道`连接不同程序的输出和输入时, 也会使用有界缓冲区, 例如`grep foo file.txt | wc -l`. 这个例子并发执行了两个进程, `grep进程`从file.txt中查找包括“foo”的行, 写到标准输出; UNIX shell把输出重定向到管道(通过`pipe系统调用`创建). 
管道的另一端是wc进程的标准输入, wc统计完行数后打印出结果. 因此, grep进程是生产者, wc是进程是消费者, 它们之间是内核中的有界缓冲区, 而你在这个例子里只是一个开心的用户.

因为`有界缓冲区`是`共享资源`, 所以我们必须通过`同步机制`来访问它, 以免产生竞态条件. 为了更好地理解这个问题, 我们来看一些实际的代码. 

首先, 需要一个共享缓冲区, 让生产者放入数据, 消费者取出数据. 简单起见, 我们就拿一个整数来做缓冲区(你当然可以想到用一个指向数据结构的指针来代替), 两个内部函数将值放入缓冲区, 从缓冲区取值. 图30.6为相关代码. 
```c
int buffer;
int count = 0; // initially, empty

void put(int value) {
	assert(count == 0);
	count = 1;
	buffer = value;
}
int get() {
	assert(count == 1);
    count = 0;
    return buffer;
}
```
Figure 30.6: The Put And Get Routines (v1)

put()函数会假设缓冲区是空的(assert来确认), 把一个值存在缓冲区, 然后把count设置为1表示缓冲区满了. get()函数刚好相反, 把缓冲区清空后(即将count设置为0), 并返回该值. 不用担心这个共享缓冲区只能存储一条数据, 稍后我们会一般化, 用队列保存更多数据项, 这会比听起来更有趣. 

现在我们需要编写一些函数, 知道何时可以访问缓冲区, 以便将数据放入缓冲区或从缓冲区取出数据.条件是显而易见的: 仅在 count 为 0 时(即缓冲器为空时), 才将数据放入缓冲器中. 仅在计数为 1 时(即缓冲器已满时), 才从缓冲器获得数据. 
如果我们编写同步代码, 让生产者将数据放入已满的缓冲区, 或消费者从空的数据获取数据, 就做错了(在这段代码中, 断言将触发). 

这项工作将由两种类型的线程完成, 其中一类我们称之为生产者(producer)线程, 另一类我们称之为消费者(consumer)线程. 图30.7展示了一个生产者的代码, 它将一个整数放入共享缓冲区loops次, 以及一个消费者, 它从该共享缓冲区中获取数据(永远不停), 每次打印出从共享缓冲区中提取的数据项.
```c
void *producer(void *arg) {
	int i;
	int loops = (int) arg;
	for (i = 0; i < loops; i++) {
		put(i);
	}
}

void *consumer(void *arg) {
	int i;
	while (1) {
		int tmp = get();
		printf("%d\n", tmp);
	}
}
```
Figure 30.7: Producer/Consumer Threads (v1)

### 有问题的方案

假设只有一个生产者和一个消费者. 
显然, put()和get()函数之中会有`临界区`, 因为put()更新缓冲区, get()读取缓冲区. 但是, 给代码加锁没有用, 我们还需别的东西. 不奇怪, 别的东西就是某些`条件变量`. 在这个(有问题的)首次尝试中(见图 30.8), 我们用了`条件变量cond`和相关的`锁mutex.`
```c
int loops; // must initialize somewhere...
cond_t cond;
mutex_t mutex;

void *producer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);           // p1
		if (count == 1)                       // p2
			Pthread_cond_wait(&cond, &mutex); // p3
		put(i);                               // p4
		Pthread_cond_signal(&cond);           // p5
		Pthread_mutex_unlock(&mutex);         // p6
	}
}

void *consumer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);           // c1
		if (count == 0)                       // c2
			Pthread_cond_wait(&cond, &mutex); // c3
		int tmp = get();                      // c4
		Pthread_cond_signal(&cond);           // c5
		Pthread_mutex_unlock(&mutex);         // c6
		printf("%d\n", tmp);
	}
}
```
Figure 30.8: Producer/Consumer: Single CV And If Statement

看看生产者和消费者之间的信号逻辑. 当生产者想要`填充缓冲区`时, 它等待缓冲区变空(p1～p3). 消费者具有完全相同的逻辑, 但等待不同的条件: 满了(c1～c3).

当只有一个生产者和一个消费者时, 图30.8中的代码能够正常运行. 但如果有超过一个线程(例如两个消费者), 这个方案会有两个严重的问题. 哪两个问题?

我们来理解`第一个问题`, 它`与等待之前的if语句`有关. 假设有`两个消费者(Tc1和Tc2)`, 一个生产者(Tp). 首先, 一个消费者(Tc1)先开始执行, 它获得锁(c1), 检查缓冲区是否可以消费 (c2), 若发现没有可消费的数据, 就等待(c3)(这会释放锁).

然后生产者线程(Tp)运行. 它获取锁(p1), 检查缓冲区是否满(p2), 发现没满就装填缓冲区(p4). 然后生产者发出信号, 说缓冲区已满(p5). 关键的是, 这让第一个消费者(Tc1)不再睡在条件变量上, 进入就绪队列. Tc1现在可以运行(但还未运行).  生产者继续执行, 直到发现缓冲区满后睡眠(p6, p1-p3). 

这时问题发生了: 另一个消费者(Tc2)抢先执行, 消费了缓冲区中的值(c1,c2,c4,c5,c6, 跳过了c3 的等待, 因为缓冲区是满的).

现在假设 Tc1 运行, 在从 wait 返回之前, 它获取了锁, 然后返回. 然后它调用了get() (p4), 但缓冲区已无法消费! 断言触发, 代码不能像预期那样工作. 显然, 我们应该设法`阻止Tc1去消费`, 因为Tc2插进来, 消费了缓冲区中之前生产的一个值. 

图30.9展示了每个线程的动作, 以及它的调度程序状态(就绪, 运行, 睡眠)随时间的变化. 

![](assets/Pasted%20image%2020230408184941.png)

问题产生的原因很简单: 在Tc1被生产者唤醒后, 但在它运行之前, 缓冲区的状态改变了(由于 Tc2). 发信号给线程只是唤醒它们, 暗示状态发生了变化(在这个例子中, 就是值已被放入缓冲区), 
但`并不会保证`在它运行之前状态一直是期望的情况(用的是if). 信号的这种释义常称为Mesa语义(Mesa semantic), 为了纪念以这种方式建立条件变量的首次研究. 

另一种释义是 Hoare 语义(Hoare semantic), 虽然实现难度大, 但是会保证被唤醒线程立刻执行. 实际上, 几乎所有系统都采用了 Mesa 语义. 

> 总而言之, 就是一个生产者, 两个消费者. 有一个消费者无法消费的问题.

### 较好但仍有问题的方案: 使用 While 语句替代 If

幸运的是, 修复这个问题很简单(见图 30.10): 把 if 语句改为while. 当消费者Tc1被唤醒后, 立刻再次检查共享变量(c2). 如果缓冲区此时为空, 消费者就会回去继续睡眠(c3). 生产者中相应的 if 也改为 while(p2). 
```c
int loops; // must initialize somewhere...
cond_t cond;
mutex_t mutex;

void *producer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);           // p1
		while (count == 1)                    // p2
			Pthread_cond_wait(&cond, &mutex); // p3
		put(i);                               // p4
		Pthread_cond_signal(&cond);           // p5
		Pthread_mutex_unlock(&mutex);         // p6
	}
}

void *consumer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);           // c1
		while (count == 0)                    // c2
			Pthread_cond_wait(&cond, &mutex); // c3
		int tmp = get();                      // c4
		Pthread_cond_signal(&cond);           // c5
		Pthread_mutex_unlock(&mutex);         // c6
		printf("%d\n", tmp);
	}
}
```
Figure 30.10: Producer/Consumer: Single CV And While

由于Mesa语义, 我们要记住一条关于条件变量的简单规则: 总是使用while循环(always use while loop). 虽然有时候不需要重新检查条件, 但这样做总是安全的.

但是, 这段代码仍然有一个问题, 也是上文提到的`第二个问题.` 你能想到吗? 它和我们`只用了一个条件变量`有关. 尝试弄清楚这个问题是什么. 

假设两个消费者(Tc1 和 Tc2)先运行,都睡眠了(c3).
生产者开始运行, 在缓冲区放入一个值, 唤醒了一个消费者(假定是 Tc1), 并开始睡眠. 现在是一个消费者马上要运行(Tc1), 两个线程(Tc2 和 Tp)都等待在同一个条件变量上. 问题马上就要出现了!

消费者Tc1醒过来并从wait()调用返回(c3), 重新检查条件(c2), 发现缓冲区是满的, 消费了这个值(c4). 这个消费者然后在该条件上发信号(c5), 唤醒一个在睡眠的线程. 但是, `应该唤醒哪个线程`呢? 

因为消费者已经清空了缓冲区, 很显然, 应该唤醒生产者. 但是, 如果它唤醒了 Tc2(这绝对是可能的, 取决于等待队列是如何管理的), 你只用了一个条件变量一个锁, 问题就出现了.

具体来说, 消费者 Tc2 会醒过来, 发现队列为空(c2), 又继续回去睡眠(c3). 生产者 Tp 刚才在缓冲区中放了一个值, 现在在睡眠. 另一个消费者线程 Tc1 也回去睡眠了. 3个线程都在睡眠, 显然是一个缺陷. 由图30.11可以看到这个可怕灾难的步骤.
> 本来应该唤醒生产者线程, 结果唤醒了另一个消费者线程. 结果三个线程都永远休眠了.

![](assets/Pasted%20image%2020230408193236.png)

显然我们需要信号, 但必须更有指向性. 消费者不应该唤醒消费者, 而应该只唤醒生产者, 反之亦然. 

### 单值缓冲区的生产者/消费者方案

解决方案也很简单: 使用两个条件变量, 而不是一个, 以便正确地发出信号, 在系统状态改变时, 哪类线程应该唤醒. 图 30.12 展示了最终的代码.
```c
int loops; // must initialize somewhere...
cond_t fill, empty;
mutex_t mutex;

void *producer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);           // p1
		while (count == 1)                    // p2
			Pthread_cond_wait(&empty, &mutex);// p3
		put(i);                               // p4
		Pthread_cond_signal(&fill);           // p5
		Pthread_mutex_unlock(&mutex);         // p6
	}
}

void *consumer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);           // c1
		while (count == 0)                    // c2
			Pthread_cond_wait(&fill, &mutex); // c3
		int tmp = get();                      // c4
		Pthread_cond_signal(&empty);          // c5
		Pthread_mutex_unlock(&mutex);         // c6
		printf("%d\n", tmp);
	}
}
```
Figure 30.12: Producer/Consumer: Two CVs And While

在上述代码中, 生产者线程等待条件变量 empty, 发信号给变量 fill. 相应地, 消费者线程等待 fill,发信号给 empty. 这样做, 从设计上避免了上述第二个问题: 消费者再也不会唤醒消费者, 生产者也不会唤醒生产者. 

### 最终正确的生产者/消费者方案

现在有了可用的生产者/消费者方案, 但不太通用. 最后的修改是`提高并发和效率`.
具体来说, 增加更多`缓冲区槽位`, 这样在睡眠之前, 可以生产多个值. 同样, 睡眠之前可以消费多个值. 单个生产者和消费者时,这种方案因为上下文切换少,提高了效率. 
多个生产者和消费者时, 它甚至支持并发生产和消费, 从而提高了并发.

第一处修改是`缓冲区结构本身`, 以及对应的 put()和 get()方法(见图 30.13). 
```c
int buffer[MAX];
int fill_ptr = 0;
int use_ptr = 0;
int count = 0;

void put(int value) {
	buffer[fill_ptr] = value;
	fill_ptr = (fill_ptr + 1) % MAX;
	count++;
}

int get() {
	int tmp = buffer[use_ptr];
	use_ptr = (use_ptr + 1) % MAX;
	count--;
	return tmp;
}
```
Figure 30.13: The Correct Put And Get Routines

图 30.14 展示了最终的等待和信号逻辑. 生产者只有在缓冲区满了的时候才会睡眠(p2), 消费者也只有在队列为空的时候睡眠(c2). 至此, 我们解决了生产者/消费者问题. 
```c
int loops; // must initialize somewhere...
cond_t fill, empty;
mutex_t mutex;

void *producer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);           // p1
		while (count == MAX)                  // p2
			Pthread_cond_wait(&empty, &mutex);// p3
		put(i);                               // p4
		Pthread_cond_signal(&fill);           // p5
		Pthread_mutex_unlock(&mutex);         // p6
	}
}

void *consumer(void *arg) {
	int i;
	for (i = 0; i < loops; i++) {
		Pthread_mutex_lock(&mutex);           // c1
		while (count == 0)                    // c2
			Pthread_cond_wait(&fill, &mutex); // c3
		int tmp = get();                      // c4
		Pthread_cond_signal(&empty);          // c5
		Pthread_mutex_unlock(&mutex);         // c6
		printf("%d\n", tmp);
	}
}
```
Figure 30.14: The Correct Producer/Consumer Synchronization

> 提示: 对条件变量使用 while(不用 if)
> 多线程程序在检查条件变量时, 使用while循环总是对的. if语句可能会对, 这取决于发信号的语义. 因此, 总是使用while, 代码就会符合预期. 
> 对条件变量使用 while 循环,这也解决了假唤醒(spurious wakeup)的情况. 某些线程库中,由于实现的细节, 有可能出现一个信号唤醒两个线程的情况. 假唤醒也是需要用while重新检查等待条件的一个原因.

## 30.3 覆盖条件

再来看条件变量的一个例子. 在这个例子中, 是一个简单的多线程内存分配库. 图30.15是展示这一问题的代码片段.

```c
// how many bytes of the heap are free?
int bytesLeft = MAX_HEAP_SIZE;

// need lock and condition too
cond_t c;
mutex_t m;

void *
allocate(int size) {
	Pthread_mutex_lock(&m);
	while (bytesLeft < size)
		Pthread_cond_wait(&c, &m);
	void *ptr = ...; // get mem from heap
	bytesLeft -= size;
	Pthread_mutex_unlock(&m);
	return ptr;
}

void free(void *ptr, int size) {
	Pthread_mutex_lock(&m);
	bytesLeft += size;
	Pthread_cond_signal(&c); // whom to signal??
	Pthread_mutex_unlock(&m);
}
```
Figure 30.15: Covering Conditions: An Example

从代码中可以看出, 当线程调用进入内存分配代码时, 它可能会因为内存不足而等待. 相应的, 线程释放内存时, 会发信号说有更多内存空闲. 但是, 代码中有一个问题: 应该唤醒哪个等待线程(可能有多个线程)? 

考虑以下场景. 假设目前没有空闲内存, 线程 Ta 调用 allocate(100), 接着线程 Tb 请求较少的内存, 调用 allocate(10). Ta 和 Tb 都等待在条件上并睡眠, 没有足够的空闲内存来满足它们的请求.

这时, 假定第三个线程Tc调用了free(50). 遗憾的是, 当它发信号唤醒等待线程时, 可能不会唤醒申请10字节的Tb线程.而Ta线程由于内存不够, 仍然等待. 因为不知道唤醒哪个(或哪些)线程, 所以图中代码无法正常工作.

解决方案也很直接: 用`pthread_cond_broadcast()`代替上述代码中的pthread_cond_signal(),唤醒所有的等待线程.这样做,确保了所有应该唤醒的线程都被唤醒.

当然, 不利的一面是可能会影响性能, 因为不必要地唤醒了其他许多等待的线程, 它们本来(还)不应该被唤醒. 这些线程被唤醒后, 重新检查条件, 马上再次睡眠.

这种条件变量叫作覆盖条件(covering condition), 因为它能覆盖所有需要唤醒线程的场景(保守策略). 成本如上所述, 就是太多线程被唤醒. 

## 30.4 小结

我们看到了引入`锁`之外的另一个重要`同步原语`: `条件变量`. 当某些程序状态不符合要求时, 通过允许线程进入休眠状态, 条件变量使我们能够漂亮地解决许多重要的同步问题, 包括著名的(仍然重要的)生产者/消费者问题, 以及`覆盖条件`. 

# Ch31 信号量

我们现在知道, 需要`锁`和`条件变量`来解决各种相关的, 有趣的`并发`问题.
事实上,Dijkstra及其同事发明了`信号量`, 所有与`同步`有关的一个`原语`.
你会看到, 可以使`用信号量作为锁和条件变量`.

关键问题:如何使用信号量？
如何使用信号量代替锁和条件变量？什么是信号量？什么是二值信号量？用锁和条件变量来实现
信号量是否简单？不用锁和条件变量, 如何实现信号量？

## 31.1 信号量的定义

信号量是一个有整数值的对象, 可以用两个函数来操作它. 在POSIX标准中, 是sem_wait()和 sem_post(). 因为信号量的`初始值`能够决定其行为, 所以首先要初始化信号量, 才能调用其他函数与之交互, 如图31.1所示.
> 历史上, `sem_wait()`开始被Dijkstra称为`P() `(代指荷兰语单词“to probe”), 而`sem_post()`被称为 `V()` (代指荷兰语单词“to test”).

```c
#include <semaphore.h>
sem_t s;
sem_init(&s, 0, 1);
```
Figure 31.1: Initializing A Semaphore

其中声明了一个信号量s, 通过第三个参数, 将它的值初始化为1. sem_init()的第二个参数, 在我们看到的所有例子中都设置为 0, 表示信号量是在同一进程的多个线程共享的.
读者可以参考手册, 了解信号量的其他用法(即如何用于跨不同进程的同步访问), 这要求第二个参数用不同的值.

信号量初始化之后, 我们可以调用 sem_wait()或 sem_post()与之交互. 图 31.2 展示了这
两个函数的不同行为.

我们暂时不关注这两个函数的实现, 这显然是需要注意的. 多个线程会调用sem_wait()和 sem_post(), 显然需要管理这些临界区. 我们首先关注如何使用这些原语, 稍后再讨论如何实现.
```c
int sem_wait(sem_t *s) {
	decrement the value of semaphore s by one
	wait if value of semaphore s is negative
}

int sem_post(sem_t *s) {
	increment the value of semaphore s by one
	if there are one or more threads waiting, wake one
}
```
Figure 31.2: Semaphore: Definitions Of Wait And Post

我们应该讨论这些接口的几个突出方面. 
首先, `sem_wait()`要么`立刻返回`(调用sem_wait()时, 信号量的值大于等于1), 要么会让`调用线程挂起`(调用wait前信号量小于等于0), 直到之后的一个post操作. 
当然, 也可能多个调用线程都调用sem_wait(), 因此都在队列中等待被唤醒.

其次, `sem_post()`并没有像sem wait()一样等待某些条件满足. 它直接增加信号量的值, 如果有等待线程, 唤醒其中一个. 

最后, 当信号量的值为`负数`时, 这个值就是`等待线程的个数`. 虽然这个值通常不会暴露给信号量的使用者, 但这个恒定的关系值得了解, 可能有助于记住信号量的工作原理. 

先(暂时)不用考虑信号量内的竞争条件, 假设这些操作都是原子的. 我们很快就会用锁和条件变量来实现.

## 31.2 二值信号量(锁)

现在我们要使用信号量了. 信号量的第一种用法是: 用信号量作为锁.
在图 31.3 所示的代码片段里, 我们直接把`临界区`用一对 sem_wait()/sem_post()环绕. 但是, 为了使这段代码正常工作, 信号量m的初始值(图中初始化为 X)是至关重要的. X 应该是多少呢? 
```c
sem_t m;
sem_init(&m, 0, X); // initialize semaphore to X; what should X be?
sem_wait(&m);
// critical section here
sem_post(&m);
```
Figure 31.3: A Binary Semaphore (That Is, A Lock)

回顾 sem_wait()和 sem_post()函数的定义, 我们发现初值应该是1.

为了说明清楚,我们假设有两个线程的场景.第一个线程(线程 0)调用了 sem_wait(),它把信号量的值减为 0.然后,`它只会在值小于 0 时等待`.因为值是 0,调用线程从函数返回并继续,线程 0 现在可以自由进入临界区.线程 0 在临界区中,如果没有其他线程尝试获取锁,当它调用 sem_post()时,会将信号量重置为1(因为没有等待线程,不会唤醒其他线程).图 31.4追踪了这一场景.

![](assets/Pasted%20image%2020230408222737.png)

如果线程0持有锁(即调用了sem_wait()之后, 调用sem_post()之前), 另一个线程(线程1)调用 sem_wait()尝试进入临界区, 那么更有趣的情况就发生了. 这种情况下, 线程1把信号量减为-1, 然后等待(自己睡眠, 放弃处理器). 
线程0再次运行,它最终调用sem_post(),将信号量的值增加到0, 唤醒等待的线程(线程 1), 然后线程1就可以获取锁. 线程1执行结束时, 再次增加信号量的值, 将它恢复为1. 

图31.5 追踪了这个例子. 除了线程的动作, 表中还显示了每一个线程的`调度程序状态`(scheduler state): 运行, 就绪(即可运行但没有运行)和睡眠. 特别要注意, 当线程1尝试获取已经被持有的锁时, 陷入睡眠. 只有线程0再次运行之后, 线程 1 才可能会唤醒并继续运行. 

![](assets/Pasted%20image%2020230408223204.png)

我们可以用信号量来实现锁了. 因为锁只有两个状态(持有和没持有), 所以这种用法有时也叫作二值信号量(binary semaphore). 事实上这种信号量也有一些更简单的实现, 我们这里使用了更为通用的信号量作为锁. 

> 信号量值初始化为1 时, 可以用作互斥锁.

## 31.3 信号量用作条件变量

信号量也可以用在一个线程暂停执行, 等待某一条件成立的场景. 例如, 一个线程要等待一个链表非空, 然后才能删除一个元素. 在这种场景下, 通常一个线程等待条件成立, 另外一个线程修改条件并发信号给等待线程, 从而唤醒等待线程. 因为等待线程在等待某些条件(condition)发生变化, 所以我们将信号量作为条件变量(condition variable). 

下面是一个简单例子.假设一个线程创建另外一线程,并且等待它结束(见图 31.6).
```c
sem_t s;

void *child(void *arg) {
	printf("child\n");
	sem_post(&s); // signal here: child is done
	return NULL;
}

int main(int argc, char *argv[]) {
	sem_init(&s, 0, X); // what should X be?
	printf("parent: begin\n");
	pthread_t c;
	Pthread_create(&c, NULL, child, NULL);
	sem_wait(&s); // wait here for child
	printf("parent: end\n");
	return 0;
}
```
Figure 31.6: A Parent Waiting For Its Child

该程序运行时,我们希望能看到这样的输出:
```
parent: begin
child
parent: end
```

然后问题就是如何用信号量来实现这种效果.结果表明,答案也很容易理解.从代码
中可知,父线程调用 sem_wait(), 子线程调用 sem_post(),父线程等待子线程执行完成.但
是,问题来了:信号量的初始值应该是多少?  答案是0. 

有两种情况需要考虑.
第一种,父线程创建了子线程, 但是子线程并没有运行(即子线程在就绪队列里). 这种情况下(见图 31.7), 父线程调用sem_wait()会先于子线程调用sem_post(). 我们希望父线程等待子线程运行. 为此, 唯一的办法是让信号量的值不大于0. 因此, 0为初值. 父线程运行, 将信号量减为-1, 然后睡眠等待; 子线程运行的时候, 调用sem_post(), 信号量增加为0, 唤醒父线程, 父线程然后从sem_wait()返回, 完成该程序. 

![](assets/Pasted%20image%2020230408225207.png)

第二种情况是子线程在父线程调用 sem_wait()之前就运行结束(见图 31.8). 在这种情况下, 子线程会先调用sem_post(), 将信号量从0增加到1. 然后当父线程有机会运行时, 会调用sem_wait(), 发现信号量的值为1. 于是父线程将信号量从1减为0, 没有等待, 直接从sem_wait()返回, 也达到了预期效果. 

![](assets/Pasted%20image%2020230408225412.png)

## 31.4 生产者/消费者(有界缓冲区)问题

我们这回用信号量来处理这个问题.

### 第一次尝试

第一次尝试解决该问题时,我们用两个信号量 empty 和 full 分别表示缓冲区空或者满.
图 31.9 是 put()和 get()函数,图 31.10 是我们尝试解决生产者/消费者问题的代码.

![](assets/Pasted%20image%2020230408230528.png)

![](assets/Pasted%20image%2020230408230544.png)

本例中,生产者等待缓冲区为空,然后加入数据.类似地,消费者等待缓冲区变成有数据的状态,然后取走数据.我们先假设 MAX=1(数组中只有一个缓冲区),验证程序是否有效.

假设有两个线程,一个生产者和一个消费者.我们来看在一个 CPU 上的具体场景.消费者先运行,执行到 C1 行,调用 sem_wait(&full).因为 full 初始值为 0,wait 调用会将 full减为-1,导致消费者睡眠,等待另一个线程调用 sem_post(&full),符合预期.

假设生产者然后运行.执行到 P1 行,调用 sem_wait(&empty).不像消费者,生产者将继续执行,因为 empty 被初始化为 MAX(在这里是 1).因此,empty 被减为 0,生产者向缓冲区中加入数据,然后执行 P3 行,调用 sem_post(&full),把 full 从−1 变成 0,唤醒消费者(即将它从阻塞变成就续).

假设生产者然后运行.执行到 P1 行,调用 sem_wait(&empty).不像消费者,生产者将继续执行,因为 empty 被初始化为 MAX(在这里是 1).因此,empty 被减为 0,生产者向缓冲区中加入数据,然后执行 P3 行,调用 sem_post(&full),把 full 从−1 变成 0,唤醒消费者(即将它从阻塞变成就续).

你可以用更多的线程来尝试这个例子(即多个生产者和多个消费者).它应该仍然正常运行.

我们现在假设 MAX 大于 1(比如 MAX=10).对于这个例子,假定有多个生产者,多个消费者.现在就有问题了:竞态条件.

假设两个生产者(Pa 和 Pb)`几乎同时`调用 put().当 Pa 先运行,在 f1 行先加入第一条数据(fill=0),假设Pa在将 fill 计数器更新为1之前`被中断`,Pb开始运行,也在 f1 行给缓冲区的 0 位置加入一条数据,这意味着那里的老数据被覆盖！这可不行,我们不能让生产者的数据丢失.

### 解决方案:增加互斥

你可以看到, 这里忘了互斥. 向缓冲区加入元素和增加`缓冲区的索引`是临界区, 需要小心保护起来. 所以, 我们使用二值信号量来增加锁.图 31.7是对应的代码.